<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 The Chapman-Kolmogorov equations | SCMA469 Actuarial Statistics</title>
  <meta name="description" content="Chapter 7 The Chapman-Kolmogorov equations | SCMA469 Actuarial Statistics" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 The Chapman-Kolmogorov equations | SCMA469 Actuarial Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 The Chapman-Kolmogorov equations | SCMA469 Actuarial Statistics" />
  
  
  

<meta name="author" content="Pairote Satiracoo" />


<meta name="date" content="2021-08-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="discrete-time-markov-chains.html"/>
<link rel="next" href="simulation.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SCMA469</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Down the rabbit-hole</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#datacamp-light"><i class="fa fa-check"></i><b>1.1</b> DataCamp Light</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#r-markdown"><i class="fa fa-check"></i><b>1.2</b> R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction to Stochastic Processes</a></li>
<li class="chapter" data-level="3" data-path="examples-of-real-world-processes.html"><a href="examples-of-real-world-processes.html"><i class="fa fa-check"></i><b>3</b> Examples of real world processes</a></li>
<li class="chapter" data-level="4" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html"><i class="fa fa-check"></i><b>4</b> Review of probability theory</a>
<ul>
<li class="chapter" data-level="4.1" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#random-variables"><i class="fa fa-check"></i><b>4.1</b> Random variables</a></li>
<li class="chapter" data-level="4.2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#probability-distribution"><i class="fa fa-check"></i><b>4.2</b> Probability distribution</a></li>
<li class="chapter" data-level="" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#examples-of-discrete-and-continuous-random-variables"><i class="fa fa-check"></i>Examples of discrete and continuous random variables</a></li>
<li class="chapter" data-level="4.3" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>4.3</b> Conditional probability</a></li>
<li class="chapter" data-level="" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#law-of-total-probability"><i class="fa fa-check"></i>Law of total probability</a></li>
<li class="chapter" data-level="4.4" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-distribution-and-conditional-expectation"><i class="fa fa-check"></i><b>4.4</b> Conditional distribution and conditional expectation</a></li>
<li class="chapter" data-level="4.5" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>4.5</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#central-limit-theorem-1"><i class="fa fa-check"></i>Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>5</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="5.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#classification-of-stochastic-processes"><i class="fa fa-check"></i><b>5.1</b> Classification of stochastic processes</a></li>
<li class="chapter" data-level="5.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html#random-walk-an-introductory-example"><i class="fa fa-check"></i><b>5.2</b> Random walk: an introductory example</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html"><i class="fa fa-check"></i><b>6</b> Discrete-time Markov chains</a>
<ul>
<li class="chapter" data-level="6.1" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#one-step-transition-probabilities"><i class="fa fa-check"></i><b>6.1</b> One-step transition probabilities</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html"><i class="fa fa-check"></i><b>7</b> The Chapman-Kolmogorov equations</a>
<ul>
<li class="chapter" data-level="7.1" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#the-chapman-kolmogorov-equations-and-n-step-transition-probabilities"><i class="fa fa-check"></i><b>7.1</b> The Chapman-Kolmogorov equations and <span class="math inline">\(n\)</span>-step transition probabilities</a></li>
<li class="chapter" data-level="7.2" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#distribution-of-x_n"><i class="fa fa-check"></i><b>7.2</b> Distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="7.3" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#joint-distribution"><i class="fa fa-check"></i><b>7.3</b> Joint Distribution</a></li>
<li class="chapter" data-level="7.4" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#random-walk-with-absorbing-and-reflecting-barriers"><i class="fa fa-check"></i><b>7.4</b> Random walk with absorbing and reflecting barrier(s)</a></li>
<li class="chapter" data-level="7.5" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#an-example-of-nonhomogeneous-markov-chain"><i class="fa fa-check"></i><b>7.5</b> An example of nonhomogeneous Markov chain</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>8</b> Simulation</a>
<ul>
<li class="chapter" data-level="8.1" data-path="simulation.html"><a href="simulation.html#monte-carlo-methods"><i class="fa fa-check"></i><b>8.1</b> Monte Carlo Methods</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="classification-of-states.html"><a href="classification-of-states.html"><i class="fa fa-check"></i><b>9</b> Classification of states</a></li>
<li class="chapter" data-level="10" data-path="absorption-probabilities-and-expected-time-to-absorption.html"><a href="absorption-probabilities-and-expected-time-to-absorption.html"><i class="fa fa-check"></i><b>10</b> Absorption probabilities and expected time to absorption</a>
<ul>
<li class="chapter" data-level="10.1" data-path="absorption-probabilities-and-expected-time-to-absorption.html"><a href="absorption-probabilities-and-expected-time-to-absorption.html#first-step-analysis"><i class="fa fa-check"></i><b>10.1</b> First step analysis</a></li>
<li class="chapter" data-level="10.2" data-path="absorption-probabilities-and-expected-time-to-absorption.html"><a href="absorption-probabilities-and-expected-time-to-absorption.html#the-expected-time-to-absorption"><i class="fa fa-check"></i><b>10.2</b> The expected time to absorption</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html"><i class="fa fa-check"></i><b>11</b> The long-term distribution of a Markov chain</a>
<ul>
<li class="chapter" data-level="11.1" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#stationary-and-limiting-distributions-for-a-single-closed-class"><i class="fa fa-check"></i><b>11.1</b> Stationary and limiting distributions for a single closed class</a>
<ul>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#stationary-distributions"><i class="fa fa-check"></i>Stationary distributions</a></li>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#proportion-of-time-in-each-state"><i class="fa fa-check"></i>Proportion of Time in Each State</a></li>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#the-method-of-finding-the-stationary-distribution"><i class="fa fa-check"></i>The method of finding the stationary distribution</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#sufficient-conditions-for-the-long-run-behaviour-of-a-markov-chain"><i class="fa fa-check"></i><b>11.2</b> Sufficient conditions for the long-run behaviour of a Markov chain</a></li>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#limiting-distributions"><i class="fa fa-check"></i>Limiting distributions</a></li>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#main-result"><i class="fa fa-check"></i>Main result</a>
<ul>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#applications-of-markov-chains-to-ncd-systems"><i class="fa fa-check"></i>Applications of Markov chains to NCD systems</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SCMA469 Actuarial Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-chapman-kolmogorov-equations" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> The Chapman-Kolmogorov equations</h1>
<div id="the-chapman-kolmogorov-equations-and-n-step-transition-probabilities" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> The Chapman-Kolmogorov equations and <span class="math inline">\(n\)</span>-step transition probabilities</h2>
<p>The <span class="math inline">\(n\)</span>-step transition probability denoted by <span class="math inline">\(p^{(n)}_{ij}\)</span> is the
probability that the process goes from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> in <span class="math inline">\(n\)</span>
transitions, i.e. <span class="math display">\[p^{(n)}_{ij} = \Pr(X_{m+n} = j | X_m = i ).\]</span> Note
that for homogeneous process, the left hand side of the above equation
does not depend on <span class="math inline">\(m\)</span>. Suppose that the transition from state <span class="math inline">\(i\)</span> at
time <span class="math inline">\(m\)</span> to state <span class="math inline">\(j\)</span> at time <span class="math inline">\(m+n\)</span> (i.e. in <span class="math inline">\(n\)</span> steps), going via state
<span class="math inline">\(k\)</span> in <span class="math inline">\(l\)</span> steps. One needs to examine all possible paths (from <span class="math inline">\(i\)</span> to
<span class="math inline">\(k\)</span> and then <span class="math inline">\(k\)</span> to <span class="math inline">\(j\)</span>) and hence the <span class="math inline">\(n\)</span>-step transition probability
<span class="math inline">\(p^{(n)}_{ij}\)</span> can be expressed as the sum of the product of the
transition probabilities <span class="math inline">\(p^{(l)}_{ik} \, p^{(n-l)}_{kj}\)</span>.
<span class="math display">\[\begin{aligned}
 \label{Chapman}
    p^{(n)}_{ij} = \sum_{k \in S}p^{(l)}_{ik} p^{(n-l)}_{kj}, \quad 0 &lt; l &lt; n  \end{aligned}\]</span>
To derive <a href="#Chapman" reference-type="eqref" reference="Chapman"><span class="math display">\[Chapman\]</span></a>, we proceed as follows: <span class="math display">\[\begin{aligned}
 \label{Chapman}
    p^{(n)}_{ij} &amp;= \Pr(X_n = j | X_0 = i) \\ 
    &amp;= \sum_{k \in S} \Pr(X_n = j , X_l = k | X_0 = i)    \\
    &amp;= \sum_{k \in S} \Pr(X_n = j | X_l = k , X_0 = i)  \cdot   \Pr(X_l = k |  X_0 = i) \\
    &amp;= \sum_{k \in S} \Pr(X_n = j | X_l = k )  \cdot   \Pr(X_l = k |  X_0 = i) \\
    &amp;= \sum_{k \in S}p^{(n-l)}_{kj} p^{(l)}_{ik} , = \sum_{k \in S}p^{(l)}_{ik} p^{(n-l)}_{kj}, \quad 0 &lt; l &lt; n . \end{aligned}\]</span></p>
<p>This result is known as the Chapman-Kolmogorov equation. This relation
can be expressed in terms of matrix multiplication as
<span class="math display">\[P^n  = P^l P^{n-l}.\]</span> The <span class="math inline">\(n\)</span>-<strong>step transition probabilities</strong>
<span class="math inline">\(p^{(n)}_{ij}\)</span> are the <span class="math inline">\(ij\)</span> elements of <span class="math inline">\(P^n\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-17" class="example"><strong>Example 7.1  </strong></span><strong>Example 7</strong>. <em>For the NCD system given in
Example <a href="#NCD" reference-type="ref" reference="NCD">Example 2</a>, suppose
that <span class="math inline">\(p = 3/4\)</span>, the probability of a claim-free year and the initial
discount level of a policyholder is 1 (with 20% discount).</em></p>
<ol style="list-style-type: decimal">
<li><p><em>Calculate the probability of starting with a discount level of 20%
and ending up 3 years later at the same level.</em></p></li>
<li><p><em>Calculate the policyholder’s expected level of discount after 3
years.</em></p></li>
</ol>
</div>
<p>The transition matrix is <span class="math display">\[P = \begin{bmatrix}
    1/4 &amp; 3/4 &amp; 0    \\
    1/4 &amp; 0 &amp; 3/4   \\
    0 &amp; 1/4 &amp; 3/4    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix},\]</span> and <span class="math display">\[P^3 = \begin{bmatrix}
    7/64 &amp; 21/64 &amp; 9/16    \\
    7/64 &amp; 3/16 &amp; 45/64   \\
    1/16 &amp; 15/64 &amp; 45/64    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>The probability of starting with a discount level of 20% and ending
up 3 years later at the same level is equal to
<span class="math inline">\(p_{11}^{(3)} = 3/16,\)</span> which is the element in the second row and
second column of the matrix <span class="math inline">\(P^3\)</span> (not to be confused with the
indices used) .</p></li>
<li><p>The policy’s expected level of discount after 3 years is
<span class="math display">\[\begin{aligned}
\mathrm{E}[X_3 | X_0 = 1] &amp;= \sum_{j=0}^{2} j \cdot  \Pr(X_3 = j | X_0 = 1) \\
&amp;= 0 \cdot (7/64) + 1 \cdot (3/16) + 2 \cdot (45/64)   \\
&amp;= 51/32 = 1.59375.\end{aligned}\]</span></p></li>
</ol>
</div>
<div id="distribution-of-x_n" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Distribution of <span class="math inline">\(X_n\)</span></h2>
<p>Let <span class="math inline">\(\boldsymbol{\mu}^{(n)}\)</span> be the vector of probability mass function
of <span class="math inline">\(X_n\)</span>, i.e. <span class="math display">\[\boldsymbol{\mu}^{(n)} = (\mu_1, \mu_2, \ldots ),\]</span>
where <span class="math inline">\(\mu_i = \Pr(X_n = i)\)</span>. It follows that
<span class="math display">\[\boldsymbol{\mu}^{(n+1)} = \boldsymbol{\mu}^{(n)} P\]</span> and, in general,
<span class="math display">\[\boldsymbol{\mu}^{(n+m)} = \boldsymbol{\mu}^{(n)} P^m.\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-18" class="example"><strong>Example 7.2  </strong></span><strong>Example 8</strong>.</p>
<ol style="list-style-type: decimal">
<li><p><em>Show that
<span class="math display">\[Pr(X_1 = i) = \sum_{k \in S} \mu_k p_{ki} = ( \boldsymbol{\mu} P)_i,\]</span>
which is the <span class="math inline">\(i\)</span>th element of the vector <span class="math inline">\(\boldsymbol{\mu} P.\)</span> Here
<span class="math inline">\(\boldsymbol{\mu} = \boldsymbol{\mu}^{0}\)</span> is the distribution of
initial random variable <span class="math inline">\(X_0\)</span> with <span class="math inline">\(\mu_i = \Pr(X_0 = i)\)</span>.</em></p></li>
<li><p><em>In general, show that the distribution of <span class="math inline">\(X_n\)</span> is given by
<span class="math display">\[Pr(X_n = i) =  ( \boldsymbol{\mu} P^n)_i.\]</span></em></p></li>
</ol>
</div>
<ol style="list-style-type: decimal">
<li><span class="math display">\[\begin{aligned}
    \Pr(X_1 = i) &amp;= \sum_{k \in S} \Pr(X_1 = i | X_0 = k) \cdot \Pr(X_0 = k) \\
    &amp;=  \sum_{k \in S} \mu_k \cdot p_{ki} \\
    &amp;= ( \boldsymbol{\mu} P)_i.\end{aligned}\]</span></li>
</ol>
<div class="example">
<p><span id="exm:weather" class="example"><strong>Example 7.3  </strong></span><strong>Example 9</strong>. <em>The simple weather pattern can be classified into three
types including rainy (<span class="math inline">\(R\)</span>), cloudy (<span class="math inline">\(C\)</span>) and sunny (<span class="math inline">\(S\)</span>). The weather
is observed daily. The following information is provided.</em></p>
<ul>
<li><p><em>On any given rainy day, the probability that it will rain the next
day is 0.7; the probability that it will be cloudy the next day
0.2.</em></p></li>
<li><p><em>On any given cloudy day, the probability that it will rain the next
day is 0.75; the probability that it will be sunny the next day
0.1.</em></p></li>
<li><p><em>On any given sunny day, the probability that it will rain the next
day is 0.2; the probability that it will be sunny the next day 0.4.</em></p></li>
</ul>
<p><em>The weather forecast for tomorrow shows that there is a 40% chance of
rain and a 60% chance of cloudy. Find the probability that it will sunny
2 days later.</em></p>
</div>
<p>As the ordered state of the chain is <span class="math inline">\(R, C, S\)</span>, the initial distribution
is <span class="math inline">\(\boldsymbol{\mu} = (0.4, 0.6, 0)\)</span>. The transition matrix <span class="math inline">\(P\)</span> is
given by <span class="math display">\[P = \begin{bmatrix}
    0.7 &amp; 0.2 &amp; 0.1    \\
    0.75 &amp; 0.15 &amp; 0.1   \\
    0.2 &amp; 0.4 &amp; 0.4   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix},\]</span> and <span class="math display">\[P^2 = \begin{bmatrix}
    0.66 &amp; 0.21 &amp; 0.13    \\
    0.6575 &amp; 0.2125 &amp; 0.13   \\
    0.52 &amp; 0.26 &amp; 0.22   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span> This gives
<span class="math display">\[\boldsymbol{\mu} \cdot P^2 = (0.6585,0.2115, 0.13).\]</span> Hence, the
desired probability of sunny is
<span class="math display">\[\Pr(X_2 = S) =( \boldsymbol{\mu} \cdot P^2 )_S  = (\boldsymbol{\mu} \cdot P^2 )_3 = 0.13.\]</span></p>
</div>
<div id="joint-distribution" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Joint Distribution</h2>
<p>Let <span class="math inline">\(X_0, X_1, \ldots\)</span> be a Markov chain with transition matrix <span class="math inline">\(P\)</span> and
initial distribution <span class="math inline">\(\boldsymbol{\mu}.\)</span> For all
<span class="math inline">\(0 \le n_1 \le n_2 &lt; \cdots &lt; n_{k-1} &lt; n_k\)</span> and states
<span class="math inline">\(i_1, i_2, \ldots , i_{k-1}, i_k,\)</span>
<span class="math display">\[P(X_{n_1} = i_1, X_{n_2} = i_2,\ldots, X_{n_k} = i_{k1}1, X_{n_k} = i_k)
= (\boldsymbol{\mu} P^{n_1} )_{i_1} (P^{n_2 - n_1} )_{i_1i_2} \cdots (P^{n_k - n_{k -1}} )_{i_{k-1}i_k}.\]</span>
From the above result, the joint probability is obtained from just the
initial distribution <span class="math inline">\(\boldsymbol{\mu}\)</span> and the transition matrix <span class="math inline">\(P\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-19" class="example"><strong>Example 7.4  </strong></span><strong>Example 10</strong>. <em>In Example <a href="#weather" reference-type="ref" reference="weather">Example 9</a>, on Sunday, the chances of rain, cloudy and sunny
have the same probabilities. Find the probability that it will be sunny
on the following Wednesday and Friday, and cloudy on Saturday.</em></p>
</div>
<p>We are given that <span class="math inline">\(\boldsymbol{\mu} = (1/3, 1/3, 1/3).\)</span> From
<span class="math display">\[P^3 = \begin{bmatrix}
    0.645500 &amp; 0.215500 &amp; 0.139   \\
    0.645625 &amp; 0.215375 &amp; 0.139  \\
    0.603000 &amp; 0.231000 &amp; 0.166   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix},\]</span> the required probability is <span class="math display">\[\begin{aligned}
 \Pr(X_3 = S, X_5 = S, X_6 = C) &amp;= (\boldsymbol{\mu}  \cdot P^3)_S \cdot  P^{2}_{SS} \cdot P_{SC} \\
&amp;= (\boldsymbol{\mu}  \cdot P^3)_3 \cdot P^{2}_{33} \cdot P_{32}  \\
&amp;= 0.148 \cdot  0.22 \cdot 0.4 = 0.013024.\end{aligned}\]</span></p>
</div>
<div id="random-walk-with-absorbing-and-reflecting-barriers" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Random walk with absorbing and reflecting barrier(s)</h2>
<div class="example">
<p><span id="exm:unlabeled-div-20" class="example"><strong>Example 7.5  </strong></span><strong>Example 11</strong>. <em>A one-dimensional random walk <span class="math inline">\(\{X_n\}\)</span> is defined on a
finite or infinite subset of integers in which the process in state <span class="math inline">\(i\)</span>
can either stay in <span class="math inline">\(i\)</span> or move to its neighbouring states <span class="math inline">\(i -1\)</span> and
<span class="math inline">\(i+1\)</span>. Suppose that given that <span class="math inline">\(X_n = i\)</span> at time <span class="math inline">\(n\)</span>,</em></p>
<ul>
<li><p><em>the probability of moving to state <span class="math inline">\(i+1\)</span> is <span class="math inline">\(p_i\)</span>,</em></p></li>
<li><p><em>the probability of remaining in state <span class="math inline">\(i\)</span> is <span class="math inline">\(r_i\)</span>, and</em></p></li>
<li><p><em>the probability of moving to state <span class="math inline">\(i-1\)</span> is <span class="math inline">\(q_i\)</span>,</em></p></li>
</ul>
<p><em>where <span class="math inline">\(p_i + q_i + r_i = 1\)</span> for all <span class="math inline">\(i\)</span>.</em></p>
<ol style="list-style-type: decimal">
<li><p><em>Write down the transition matrix.</em></p></li>
<li><p><em>Show that the random walk has Markov property.</em></p></li>
</ol>
</div>
<ol style="list-style-type: decimal">
<li><p>The transition diagram and the transition matrix are infinite:</p>
<p><span class="math display">\[P = \begin{bmatrix}
    \ddots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots  &amp; \cdots    \\
    \cdots &amp; q_{-1} &amp; r_{-1}  &amp; p_{-1}  &amp; \cdots &amp; \cdots  &amp; \cdots  \\
    \cdots &amp; \cdots &amp; q_{0} &amp; r_{0}  &amp; p_{0}  &amp; \cdots   &amp; \cdots  \\
    \cdots &amp; \cdots &amp; \cdots &amp; q_{1} &amp; r_{1}  &amp; p_{1}    &amp; \cdots    \\
    \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots  &amp; \cdots  &amp; \ddots   \\    
 %0 &amp; 0 &amp; 0 &amp; 1/2 &amp; 1/2     \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span></p></li>
<li><p>Clearly, the Markov property holds because <span class="math display">\[\begin{aligned}
    &amp;\Pr(X_{n+1} = k | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_0)  \\
    &amp;= \Pr(X_{n+1} = k | X_n = i) =
    \begin{cases}
               p_i,              &amp; k = i+1\\
               r_i,              &amp; k = i\\
               q_i,               &amp; k = i-1\\               
               0,       &amp; \text{otherwise}.
           \end{cases}\end{aligned}\]</span></p></li>
</ol>
<div class="example">
<p><span id="exm:simpleRW" class="example"><strong>Example 7.6  </strong></span><strong>Example 12</strong>. <em>The random walk can be used to model the fortune of a
gambler. The gambler bets per game and the probability of winning is <span class="math inline">\(p\)</span>
and the probability of losing is <span class="math inline">\(q\)</span> where <span class="math inline">\(p + q = 1\)</span>. In addition, the
gambler is ruined (or goes broke) if he reaches state 0, and also stops
the game if he reaches state <span class="math inline">\(N\)</span>. Therefore, the state space is
<span class="math inline">\(S = \{0, 1, \ldots, N\}\)</span>. Note that
<span class="math display">\[p_{00} = 1 \text { and } p_{NN} = 1.\]</span> The states <span class="math inline">\(0\)</span> and <span class="math inline">\(N\)</span> are
referred to as <strong>absorbing boundaries (absorbing states)</strong> and the
remaining states <span class="math inline">\(1,2,\ldots,N-1\)</span> are <strong>transient</strong>. Roughly speaking,
if a state is known as transient if there is a possibility of leaving
the state and never returning.</em></p>
</div>
<p>The transition diagram and the transition matrix of the simple random
walk with absorbing boundaries (states) are given as follows:</p>
<p><span class="math display">\[P = \begin{bmatrix}
    1&amp; 0 &amp; 0 &amp; 0&amp; \cdots &amp; 0&amp; 0  &amp; 0    \\
    q &amp; 0 &amp; p  &amp; 0&amp; \cdots &amp; 0&amp; 0  &amp; 0  \\
    0 &amp; q &amp; 0 &amp; p  &amp; \cdots &amp; 0&amp; 0 &amp; 0   \\
    \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp;  \ddots &amp; \vdots    &amp; \vdots &amp; \vdots   \\
    0 &amp; 0 &amp; 0 &amp; 0  &amp; \cdots &amp; q &amp; 0 &amp; p   \\
    0 &amp; 0 &amp; 0 &amp; 0  &amp; \cdots &amp; 0 &amp; 0 &amp; 1   \\
 %0 &amp; 0 &amp; 0 &amp; 1/2 &amp; 1/2     \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>In general, a state <span class="math inline">\(i\)</span> is called <strong>absorbing</strong> if <span class="math inline">\(p_{ii} = 1\)</span></p></li>
<li><p>The simple random walk as given in Example
<a href="#simpleRW" reference-type="ref" reference="simpleRW">Example 12</a>
can be modified so that whenever the process is in state 0 (or state
<span class="math inline">\(N\)</span>),</p>
<ul>
<li><p>the probability of remaining in state 0 is <span class="math inline">\(\alpha\)</span>, and</p></li>
<li><p>the probability of moving to state 1 is <span class="math inline">\(1 - \alpha\)</span>.</p></li>
</ul>
<p>In this case, the state 0 is referred to as a <strong>reflecting barrier</strong>
for the chain. The process might be used to model the fortune of an
individual when negative fortune is reset to zero.</p></li>
</ol>
</div>
<div id="an-example-of-nonhomogeneous-markov-chain" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> An example of nonhomogeneous Markov chain</h2>
<p>In this section, we give an example of a discrete-time nonhomogeneous
Markov chain. Again, without stated otherwise, we shall assume that the
discrete-time Markov chains are homogeneous.</p>
<div class="example">
<p><span id="exm:unlabeled-div-21" class="example"><strong>Example 7.7  </strong></span><strong>Example 13</strong>. <em>(Adapted from W.J.Stewart)
<span id="exampleStationary2" label="exampleStationary2"><span class="math display">\[exampleStationary2\]</span></span>
A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> consists of two states <span class="math inline">\(\{1,2\}\)</span>. At
time step <span class="math inline">\(n\)</span>, the probability that the Markov chain remains in its
current state is given by <span class="math display">\[p_{11}(n) = p_{22}(n) = 1/n,\]</span> while the
probability that it changes state is given by
<span class="math display">\[p_{12}(n) = p_{21}(n) = 1 - 1/n.\]</span></em></p>
<ol style="list-style-type: decimal">
<li><p><em>Draw a transition diagram of the Markov chain.</em></p></li>
<li><p><em>Write down the transition matrix.</em></p></li>
<li><p><em>Calculate <span class="math inline">\(\Pr(X_5 = 2, X_4 = 2, X_3 = 1, X_2 =1 | X_1 = 1)\)</span>.</em></p></li>
</ol>
</div>
<ol style="list-style-type: decimal">
<li><p>The transition diagram and the transition matrix are dependent of
the time step <span class="math inline">\(n\)</span>, and are given as follows:</p>
<p><span class="math display">\[P(n) = \begin{bmatrix}
    \frac{1}{n} &amp; \frac{n-1}{n}   \\
    \frac{(n-1)}{n} &amp; \frac{1}{n}   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span></p></li>
<li><p>The probability of taking a particular part can be calculated by
<span class="math display">\[\begin{aligned}
    \Pr(X_5 = 2, X_4 = 2, X_3 = 1, X_2 =1 | X_1 = 1)  &amp;= p_{11}(1) \cdot p_{11}(2) \cdot p_{12}(3) \cdot p_{22}(4) \\
        &amp;= 1 \cdot 1/2 \cdot 2/3 \cdot 1/4 = 1/12.\end{aligned}\]</span>
Other paths lead to state 2 after four transitions, and have
different probabilities according to the route they follow. What is
important is that, no matter which route is chosen, once the Markov
chain arrives in state 2 after four steps, the future evolution is
specified by <span class="math inline">\(P(5)\)</span>, and not any other <span class="math inline">\(P(i), i \le 4\)</span>.</p></li>
</ol>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="discrete-time-markov-chains.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="simulation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/pairote-sat/SCMA469/edit/master/03-race.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/pairote-sat/SCMA469/blob/master/03-race.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
