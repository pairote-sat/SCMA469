<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Stochastic processes | SCMA469 Actuarial Statistics</title>
  <meta name="description" content="Chapter 3 Stochastic processes | SCMA469 Actuarial Statistics" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Stochastic processes | SCMA469 Actuarial Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Stochastic processes | SCMA469 Actuarial Statistics" />
  
  
  

<meta name="author" content="Pairote Satiracoo" />


<meta name="date" content="2021-11-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="review-of-probability-theory.html"/>
<link rel="next" href="discrete-time-markov-chains.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SCMA469 Actuarial Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Stochastic Processes</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#examples-of-real-world-processes"><i class="fa fa-check"></i><b>1.1</b> Examples of real world processes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html"><i class="fa fa-check"></i><b>2</b> Review of probability theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#random-variables"><i class="fa fa-check"></i><b>2.1</b> Random variables</a></li>
<li class="chapter" data-level="2.2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#probability-distribution"><i class="fa fa-check"></i><b>2.2</b> Probability distribution</a></li>
<li class="chapter" data-level="2.3" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>2.3</b> Conditional probability</a></li>
<li class="chapter" data-level="2.4" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#law-of-total-probability"><i class="fa fa-check"></i><b>2.4</b> Law of total probability</a></li>
<li class="chapter" data-level="2.5" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-distribution-and-conditional-expectation"><i class="fa fa-check"></i><b>2.5</b> Conditional distribution and conditional expectation</a></li>
<li class="chapter" data-level="2.6" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.6</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>3</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#classification-of-stochastic-processes"><i class="fa fa-check"></i><b>3.1</b> Classification of stochastic processes</a></li>
<li class="chapter" data-level="3.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html#random-walk-an-introductory-example"><i class="fa fa-check"></i><b>3.2</b> Random walk: an introductory example</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html"><i class="fa fa-check"></i><b>4</b> Discrete-time Markov chains</a>
<ul>
<li class="chapter" data-level="4.1" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#one-step-transition-probabilities"><i class="fa fa-check"></i><b>4.1</b> One-step transition probabilities</a></li>
<li class="chapter" data-level="4.2" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-chapman-kolmogorov-equation-and-n-step-transition-probabilities"><i class="fa fa-check"></i><b>4.2</b> The Chapman-Kolmogorov equation and <span class="math inline">\(n\)</span>-step transition probabilities</a></li>
<li class="chapter" data-level="4.3" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#distribution-of-x_n"><i class="fa fa-check"></i><b>4.3</b> Distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="4.4" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#joint-distribution"><i class="fa fa-check"></i><b>4.4</b> Joint Distribution</a></li>
<li class="chapter" data-level="4.5" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#random-walk-with-absorbing-and-reflecting-barriers"><i class="fa fa-check"></i><b>4.5</b> Random walk with absorbing and reflecting barrier(s)</a></li>
<li class="chapter" data-level="4.6" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#an-example-of-nonhomogeneous-markov-chain"><i class="fa fa-check"></i><b>4.6</b> An example of nonhomogeneous Markov chain</a></li>
<li class="chapter" data-level="4.7" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#simulation"><i class="fa fa-check"></i><b>4.7</b> Simulation</a></li>
<li class="chapter" data-level="4.8" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#monte-carlo-methods"><i class="fa fa-check"></i><b>4.8</b> Monte Carlo Methods</a></li>
<li class="chapter" data-level="4.9" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#classification-of-states"><i class="fa fa-check"></i><b>4.9</b> Classification of states</a></li>
<li class="chapter" data-level="4.10" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#absorption-probabilities-and-expected-time-to-absorption"><i class="fa fa-check"></i><b>4.10</b> Absorption probabilities and expected time to absorption</a></li>
<li class="chapter" data-level="4.11" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#first-step-analysis"><i class="fa fa-check"></i><b>4.11</b> First step analysis</a></li>
<li class="chapter" data-level="4.12" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-expected-time-to-absorption"><i class="fa fa-check"></i><b>4.12</b> The expected time to absorption</a></li>
<li class="chapter" data-level="4.13" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-long-term-distribution-of-a-markov-chain"><i class="fa fa-check"></i><b>4.13</b> The long-term distribution of a Markov chain</a></li>
<li class="chapter" data-level="4.14" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#stationary-and-limiting-distributions-for-a-single-closed-class"><i class="fa fa-check"></i><b>4.14</b> Stationary and limiting distributions for a single closed class</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#stationary-distributions"><i class="fa fa-check"></i>Stationary distributions</a></li>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#proportion-of-time-in-each-state"><i class="fa fa-check"></i>Proportion of Time in Each State</a></li>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-method-of-finding-the-stationary-distribution"><i class="fa fa-check"></i>The method of finding the stationary distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#sufficient-conditions-for-the-long-run-behaviour-of-a-markov-chain"><i class="fa fa-check"></i><b>4.15</b> Sufficient conditions for the long-run behaviour of a Markov chain</a></li>
<li class="chapter" data-level="4.16" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#limiting-distributions"><i class="fa fa-check"></i><b>4.16</b> Limiting distributions</a></li>
<li class="chapter" data-level="4.17" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#main-result"><i class="fa fa-check"></i><b>4.17</b> Main result</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#applications-of-markov-chains-to-ncd-systems"><i class="fa fa-check"></i>Applications of Markov chains to NCD systems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="poisson-processes.html"><a href="poisson-processes.html"><i class="fa fa-check"></i><b>5</b> Poisson processes</a>
<ul>
<li class="chapter" data-level="5.1" data-path="poisson-processes.html"><a href="poisson-processes.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="poisson-processes.html"><a href="poisson-processes.html#poisson-process"><i class="fa fa-check"></i><b>5.2</b> Poisson process</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="poisson-processes.html"><a href="poisson-processes.html#counting-process"><i class="fa fa-check"></i><b>5.2.1</b> Counting Process</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="poisson-processes.html"><a href="poisson-processes.html#properties-of-poisson-processes"><i class="fa fa-check"></i><b>5.3</b> Properties of Poisson processes</a></li>
<li class="chapter" data-level="5.4" data-path="poisson-processes.html"><a href="poisson-processes.html#poisson-process-definition-2"><i class="fa fa-check"></i><b>5.4</b> Poisson process : Definition 2</a></li>
<li class="chapter" data-level="5.5" data-path="poisson-processes.html"><a href="poisson-processes.html#inter-arrival-times-inter-event-times-or-holding-times"><i class="fa fa-check"></i><b>5.5</b> Inter arrival times (Inter event times or holding times)</a></li>
<li class="chapter" data-level="" data-path="poisson-processes.html"><a href="poisson-processes.html#important-result"><i class="fa fa-check"></i>Important result</a></li>
<li class="chapter" data-level="5.6" data-path="poisson-processes.html"><a href="poisson-processes.html#superposition-and-thinning-properties"><i class="fa fa-check"></i><b>5.6</b> Superposition and thinning properties</a>
<ul>
<li class="chapter" data-level="" data-path="poisson-processes.html"><a href="poisson-processes.html#superposition-property"><i class="fa fa-check"></i>Superposition property</a></li>
<li class="chapter" data-level="" data-path="poisson-processes.html"><a href="poisson-processes.html#splitting-thinning-property"><i class="fa fa-check"></i>Splitting (Thinning) property</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="poisson-processes.html"><a href="poisson-processes.html#memorylessness"><i class="fa fa-check"></i><b>5.7</b> Memorylessness</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="tutorials.html"><a href="tutorials.html"><i class="fa fa-check"></i><b>6</b> Tutorials</a>
<ul>
<li class="chapter" data-level="6.1" data-path="tutorials.html"><a href="tutorials.html#tutorial-1"><i class="fa fa-check"></i><b>6.1</b> Tutorial 1</a></li>
<li class="chapter" data-level="6.2" data-path="tutorials.html"><a href="tutorials.html#tutorial-2"><i class="fa fa-check"></i><b>6.2</b> Tutorial 2</a></li>
<li class="chapter" data-level="6.3" data-path="tutorials.html"><a href="tutorials.html#tutorial-3"><i class="fa fa-check"></i><b>6.3</b> Tutorial 3</a></li>
<li class="chapter" data-level="6.4" data-path="tutorials.html"><a href="tutorials.html#tutorial-2-1"><i class="fa fa-check"></i><b>6.4</b> Tutorial 2</a></li>
<li class="chapter" data-level="6.5" data-path="tutorials.html"><a href="tutorials.html#tutorial-3-1"><i class="fa fa-check"></i><b>6.5</b> Tutorial 3</a></li>
<li class="chapter" data-level="6.6" data-path="tutorials.html"><a href="tutorials.html#tutorial-4"><i class="fa fa-check"></i><b>6.6</b> Tutorial 4</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>7</b> Applications</a>
<ul>
<li class="chapter" data-level="7.1" data-path="applications.html"><a href="applications.html#datacamp-light"><i class="fa fa-check"></i><b>7.1</b> DataCamp Light</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>8</b> Final words</a>
<ul>
<li class="chapter" data-level="8.1" data-path="final-words.html"><a href="final-words.html#datacamp-light-1"><i class="fa fa-check"></i><b>8.1</b> DataCamp Light</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SCMA469 Actuarial Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stochastic-processes" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Stochastic processes</h1>
<p>Evolution of a random process is at least partially random, and each run
the process leads to potentially a different outcome. It is of great
interest to understand or model the behaviour of a random process by
describing how different states, represented by random variables <span class="math inline">\(X\)</span>’s,
evolve in the system over time. Just as probability theory is considered
as the study of mathematical models of random phenomena, the theory of
stochastic processes plays an important role in the study of
time-dependent random phenomena. Stochastic processes can be used to
represent many different random phenomena from different fields such as
science, engineering, finance, and economics.</p>
<p>A <strong>stochastic process</strong> is a collection of random variables
<span class="math inline">\(\{ X_t : t \in T\}\)</span> defined on a common sample space, where</p>
<ul>
<li><p><span class="math inline">\(t\)</span> is a parameter running over some index set <span class="math inline">\(T\)</span>, called the
<strong>time domain</strong>.</p></li>
<li><p>The common sample space of the random variables (the range of
possible values for <span class="math inline">\(X_t\)</span>) denoted by <span class="math inline">\(S\)</span> is called the <strong>state
space</strong> of the process.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>The set of random variables may be dependent or need not be
identically distributed.</p></li>
<li><p>Techniques used to study stochastic processes depend on whether the
state space or the index set (the time domain) are discrete or
continuous.</p></li>
</ol>
<div id="classification-of-stochastic-processes" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Classification of stochastic processes</h2>
<p>Stochastic processes can be classified on the basis of the nature of
their state space and index set.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Discrete state space with discrete time changes</strong> : No claims
discount (NCD) policy: A car owner purchases a motor insurance
policy for which the premium charged depends on the claim record.
Let <span class="math inline">\(X_t\)</span> denote the discount status of a policyholder with three
levels of discount, i.e. <span class="math inline">\(S = \{0,1,2\}\)</span> corresponding to three
discount levels of 0%, 20% and 40% and the time set is
<span class="math inline">\(T = \{0,1,2,\ldots\}\)</span>. Both time and state space are discrete.</p></li>
<li><p><strong>Discrete state space with continuous time changes</strong> : In a health
insurance system, an insurance company may classify policyholders as
Healthy, Sick or Dead, i.e. <span class="math inline">\(S = \{H, S, D\}\)</span>. The time domain can
be taken as continuous, <span class="math inline">\(T = [0,\infty)\)</span>.</p></li>
<li><p><strong>Continuous state space with continuous time changes</strong> : Let <span class="math inline">\(S_t\)</span>
be the total amount claimed by time <span class="math inline">\(t \in T\)</span> where <span class="math inline">\(T = [0,\infty)\)</span>
and the state space is <span class="math inline">\(\mathbb{R}\)</span>. Both time and state space are
continuous. Some continuous time stochastic process taking value in
a continuous state space will be studied in Risk Analysis and
Credibility course.</p></li>
<li><p><strong>Continuous state space with discrete time changes</strong> : The outcomes
of the above claim process <span class="math inline">\(S_t\)</span> could be recorded continuously,
however, we may choose to model the values only at discrete time,
for e.g. the total claim amounts at the end of each day. This may
due to the limitation of the measurement process (for e.g. expensive
to measure). Hence, the time domain is discrete but the state space
is continuous.</p></li>
</ol>
<p>In case that claim amounts are recorded to the nearest baht or in
satang, i.e. discrete state space, we could also approximate or model
the process by using a discrete state space, rather than continuous.</p>
</div>
<div id="random-walk-an-introductory-example" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Random walk: an introductory example</h2>
<p>One of the simplest examples of a stochastic process is a simple random
walk. Consider a simple model of the price of a stock measured in
baht. For each trading day <span class="math inline">\(n = 0,1,2, \ldots\)</span>, the stock price
increases by 1 baht with probability <span class="math inline">\(p\)</span> or decreases by 1 baht with
probability <span class="math inline">\(q = 1-p\)</span>. Let <span class="math inline">\(X_n\)</span> denote the stock price at day <span class="math inline">\(n\)</span> and
<span class="math inline">\(X_0 = 100\)</span>. This simple model is called a simple random
walk.</p>
<p>In the simple random walk process, time is discrete (as observed at the
end of each day) and the state space is discrete. The stochastic model
has an infinite number of outcomes known as <strong>stochastic realisations or
sample paths</strong>. A <strong>sample path</strong> is then just the sequence of a
particular set of experiments. Graphs of some stochastic realisations of
the simple random walk with <span class="math inline">\(p = 0.5\)</span> and <span class="math inline">\(a = 100\)</span> are shown in Figure <a href="stochastic-processes.html#fig:FigRW">3.1</a>.</p>
<div class="figure"><span id="fig:FigRW"></span>
<img src="SCMA469Bookdownproj_files/figure-html/FigRW-1.png" alt="Some stochastic realisations of the simple random walk" width="672" />
<p class="caption">
Figure 3.1: Some stochastic realisations of the simple random walk
</p>
</div>
<p>We can use R to generate sample paths of this random walk.</p>
<script src=https://cdn.datacamp.com/datacamp-light-latest.min.js></script>
<div data-datacamp-exercise="" data-height="300" data-encoded="true">
eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHRpZHlyKVxuc2V0LnNlZWQoMSlcbnAgPC0gMC41XG5aPC0gc2FtcGxlKHggPSBjKDEsLTEpLCAxMCwgcmVwbGFjZSA9IFQsIHByb2IgPSBjKHAsIDEtIHApKVxuWlxuIyBwbG90KGMoMTAwLCAxMDAgKyBjdW1zdW0oWikpKVxuIyBxcXBsb3QoMDoxMCxjKDEwMCwgMTAwICsgY3Vtc3VtKFopKSlcblxueCA8LSAwOjEwXG55MSA8LSBjKDEwMCwgMTAwICsgY3Vtc3VtKFopKVxuZGF0IDwtIGRhdGEuZnJhbWUoeCA9IHgsIHkgPSB5MSlcbmRhdCAlPiUgZ2dwbG90KGFlcyh4ID0geCwgeSA9IHkxKSkgKyBcbiAgZ2VvbV9saW5lKGNvbCA9IFwiYmx1ZVwiKSArXG4gIGdndGl0bGUoXCJBIHNpbXBsZSByYW5kb20gd2Fsa1wiKSJ9
</div>
<p>A complete description of the simple random walk, observed as a
collection of <span class="math inline">\(n\)</span> random variables at time points
<span class="math inline">\(t_1, t_2, \ldots, t_n\)</span> can be specified by the joint distribution of
<span class="math inline">\(X_{t_1}, X_{t_2}, \ldots, X_{t_n}\)</span>, i.e.
<span class="math display">\[F(x_1, x_2, \ldots, x_n) = \Pr(X_{t_1} \le x_1, X_{t_2} \le x_2, \ldots, X_{t_n} \le x_n).\]</span>
However, the <strong>multidimensional distribution function cannot be easily
written in a closed form</strong> unless the random variables have a
multivariate normal distribution. In practice, it is more convenient to
deal with some stochastic processes via some simple <strong>intermediary
processes</strong> or under some addition assumptions.</p>
<p>In general, a simple random walk <span class="math inline">\(X_n\)</span> is a discrete-time stochastic
process defined by</p>
<ul>
<li><p><span class="math inline">\(X_0 = a\)</span> and</p></li>
<li><p>for <span class="math inline">\(n \ge1\)</span>,
<span class="math display">\[X_n = a + \sum_{i=1}^n  Z_i, \text{ where } Z_i = \begin{cases}
    1, &amp; \text{ with probability } p  \\
    -1, &amp; \text{ with probability } q =  1- p.  
 \end{cases}\]</span></p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>When <span class="math inline">\(p = 1/2\)</span>, the value of the process increases or decreases
randomly by 1 unit with equal probability. In this case, the process
is known as a <strong>symmetric</strong> random walk.</p></li>
<li><p>The (intermediary) process <span class="math inline">\(\{ Z_i : i \in \mathbb{N}\}\)</span> is a
sequence of independent identically distributed (i.i.d.) random
variables. The process <span class="math inline">\(X_t\)</span> themselves are neither independent nor
identically distributed. This process <span class="math inline">\(Z_i\)</span> is also known as <strong>white
noise process</strong>.</p></li>
</ol>
<div class="example">
<p><span id="exm:unlabeled-div-9" class="example"><strong>Example 3.1  </strong></span><em>Explain why the simple random process <span class="math inline">\(X_n\)</span> is neither
independent nor identically distributed.</em></p>
</div>
<p><strong>Solution:</strong>
Suppose that <span class="math inline">\(X_0 = 100\)</span>. Firstly, we will show that <span class="math inline">\(X_n\)</span> is not
independent. From definition, the process <span class="math inline">\(X_n\)</span> can be written as
<span class="math display">\[X_n = X_{n-1} + Z_n.\]</span> That is, the value of <span class="math inline">\(X_n\)</span> is the previous
value plus a random change of 1 or <span class="math inline">\(-1\)</span>. Therefore, the value of the
process depends on the previous value and they are not independent. For
e.g.,
<span class="math display">\[\Pr(X_2 = 102) &gt; 0 \quad \text{ but } \quad  \Pr(X_2 = 102 | X_1 = 99) = 0.\]</span></p>
<p>The process <span class="math inline">\(X_n\)</span> cannot be identically distributed. For e.g. <span class="math inline">\(X_1\)</span> can
take the values of 99 and 101, while <span class="math inline">\(X_2\)</span> can take three different
values of 98, 100 and 102.</p>
<div class="example">
<p><span id="exm:unlabeled-div-10" class="example"><strong>Example 3.2  </strong></span><em>Let <span class="math display">\[\begin{aligned}
    \mu &amp;= \mathrm{E}[Z_i] \\
    \sigma^2 &amp;= \mathrm{Var}[Z_i] \end{aligned}\]</span> Calculate the
expectation (<span class="math inline">\(\mu\)</span>) and variance (<span class="math inline">\(\sigma^2\)</span>) of the random variable
<span class="math inline">\(Z_i\)</span>.</em></p>
</div>
<p><strong>Solution:</strong>
<span class="math display">\[\begin{aligned}
    \mu &amp;= \mathrm{E}[Z_i] = 1\cdot p + (-1) \cdot q = p - q.\\\end{aligned}\]</span>
<span class="math display">\[\begin{aligned}
    \sigma^2 &amp;= \mathrm{Var}[Z_i] \\
            &amp;=\mathrm{E}[Z_i^2] - (\mathrm{E}[Z_i] )^2 \\
            &amp;= 1 - (p-q)^2  = (p+q)^2 - (p-q)^2\\
            &amp;= 4pq. \end{aligned}\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-11" class="example"><strong>Example 3.3  </strong></span><em>Calculate the expectation and variance of the process
<span class="math inline">\(X_n\)</span> at time <span class="math inline">\(n\)</span>.</em></p>
</div>
<p><strong>Solution:</strong>
<span class="math display">\[\begin{aligned}
     \mathrm{E}[X_n] &amp;=  \mathrm{E}[a + \sum_{i=1}^n Z_i] = a + n\mu.\end{aligned}\]</span>
<span class="math display">\[\begin{aligned}
    \mathrm{Var}[X_n]&amp;= \mathrm{Var}[a + \sum_{i=1}^n Z_i]  = n \sigma^2.\end{aligned}\]</span>
It should be noted that the variance of <span class="math inline">\(X_n\)</span> increases with time.</p>
<div class="example">
<p><span id="exm:unlabeled-div-12" class="example"><strong>Example 3.4  </strong></span><em>For the random process, calculate
<span class="math display">\[\Pr(X_2 = 98, X_5 = 99 | X_0 = 100).\]</span></em></p>
</div>
<p><strong>Solution:</strong>
The process <span class="math inline">\(X_n\)</span> must decrease on the first two days, which happens
with probability <span class="math inline">\((1-p)^2\)</span>. Independently, it must then increases on
another two days and decrease on one day (not necessarily in that
order), giving three different possibilities. Each of these has
probability <span class="math inline">\(p^2(1-p)\)</span>. So
<span class="math display">\[\Pr(X_2 = 98, X_5 = 99 | X_0 = 100) = (1-p)^2 \cdot 3 p^2(1-p) = 3p^2(1-p)^3.\]</span></p>
<p>In what follows, we will see that exact calculations are possible for
the simple random walk process. Note also that it is sufficient to
understand the behaviour of the random walk when it starts at <span class="math inline">\(X_0 = 0\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-13" class="example"><strong>Example 3.5  </strong></span><em>For the random process with <span class="math inline">\(X_0 = 0\)</span>, <span class="math inline">\(X_{2n}\)</span> is
always even and <span class="math inline">\(X_{2n+1}\)</span> is always odd. Based on the binomial
distribution, show that <span class="math display">\[\begin{aligned}
    \Pr(X_{2n} = 2m) &amp;= {2n \choose n+m} p^{n+m} q^{n-m}, \quad   -n \le m \le n \\
    \Pr(X_{2n+1} = 2m+1) &amp;= {2n + 1 \choose n+m+1} p^{n+m+1} q^{n-m}, \quad   -n-1 \le m \le n.\end{aligned}\]</span></em></p>
</div>
<p><strong>Solution:</strong></p>
<p>Let <span class="math inline">\(A\)</span> denote the number of <span class="math inline">\(+1\)</span> and <span class="math inline">\(B\)</span> denote the number of <span class="math inline">\(-1\)</span>.
Then <span class="math inline">\(A + B = 2n\)</span> and <span class="math inline">\(X_{2n} = A - B\)</span> (i.e. the position at time <span class="math inline">\(2n\)</span>).
Hence, <span class="math display">\[\begin{aligned}
    \Pr(X_{2n} = 2m) &amp;= \Pr( A - B = 2m) \\
    &amp;= \Pr( A - (2n - A) = 2m)  =   \Pr( 2A - 2n  = 2m) =   \Pr( A   = m + n)\\
    &amp;= {2n \choose n+m} p^{n+m} q^{2n-(n+m)}, \quad   -n \le m \le n \\
    &amp;= {2n \choose n+m} p^{n+m} q^{n-m}, \quad   -n \le m \le n.\end{aligned}\]</span></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="review-of-probability-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="discrete-time-markov-chains.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-stochastic-processes.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/pairote-sat/SCMA469/blob/master/02-stochastic-processes.Rmd",
"text": null
},
"download": ["SCMA469Bookdownproj.pdf", "SCMA469Bookdownproj.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
