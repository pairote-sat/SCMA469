<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Review of probability theory | SCMA469 Actuarial Statistics</title>
  <meta name="description" content="Chapter 2 Review of probability theory | SCMA469 Actuarial Statistics" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Review of probability theory | SCMA469 Actuarial Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Review of probability theory | SCMA469 Actuarial Statistics" />
  
  
  

<meta name="author" content="Pairote Satiracoo" />


<meta name="date" content="2021-11-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="stochastic-processes.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SCMA469 Actuarial Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Stochastic Processes</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#examples-of-real-world-processes"><i class="fa fa-check"></i><b>1.1</b> Examples of real world processes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html"><i class="fa fa-check"></i><b>2</b> Review of probability theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#random-variables"><i class="fa fa-check"></i><b>2.1</b> Random variables</a></li>
<li class="chapter" data-level="2.2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#probability-distribution"><i class="fa fa-check"></i><b>2.2</b> Probability distribution</a></li>
<li class="chapter" data-level="2.3" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>2.3</b> Conditional probability</a></li>
<li class="chapter" data-level="2.4" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#law-of-total-probability"><i class="fa fa-check"></i><b>2.4</b> Law of total probability</a></li>
<li class="chapter" data-level="2.5" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-distribution-and-conditional-expectation"><i class="fa fa-check"></i><b>2.5</b> Conditional distribution and conditional expectation</a></li>
<li class="chapter" data-level="2.6" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.6</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>3</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#classification-of-stochastic-processes"><i class="fa fa-check"></i><b>3.1</b> Classification of stochastic processes</a></li>
<li class="chapter" data-level="3.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html#random-walk-an-introductory-example"><i class="fa fa-check"></i><b>3.2</b> Random walk: an introductory example</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html"><i class="fa fa-check"></i><b>4</b> Discrete-time Markov chains</a>
<ul>
<li class="chapter" data-level="4.1" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#one-step-transition-probabilities"><i class="fa fa-check"></i><b>4.1</b> One-step transition probabilities</a></li>
<li class="chapter" data-level="4.2" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-chapman-kolmogorov-equation-and-n-step-transition-probabilities"><i class="fa fa-check"></i><b>4.2</b> The Chapman-Kolmogorov equation and <span class="math inline">\(n\)</span>-step transition probabilities</a></li>
<li class="chapter" data-level="4.3" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#distribution-of-x_n"><i class="fa fa-check"></i><b>4.3</b> Distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="4.4" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#joint-distribution"><i class="fa fa-check"></i><b>4.4</b> Joint Distribution</a></li>
<li class="chapter" data-level="4.5" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#random-walk-with-absorbing-and-reflecting-barriers"><i class="fa fa-check"></i><b>4.5</b> Random walk with absorbing and reflecting barrier(s)</a></li>
<li class="chapter" data-level="4.6" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#an-example-of-nonhomogeneous-markov-chain"><i class="fa fa-check"></i><b>4.6</b> An example of nonhomogeneous Markov chain</a></li>
<li class="chapter" data-level="4.7" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#simulation"><i class="fa fa-check"></i><b>4.7</b> Simulation</a></li>
<li class="chapter" data-level="4.8" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#monte-carlo-methods"><i class="fa fa-check"></i><b>4.8</b> Monte Carlo Methods</a></li>
<li class="chapter" data-level="4.9" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#classification-of-states"><i class="fa fa-check"></i><b>4.9</b> Classification of states</a></li>
<li class="chapter" data-level="4.10" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#absorption-probabilities-and-expected-time-to-absorption"><i class="fa fa-check"></i><b>4.10</b> Absorption probabilities and expected time to absorption</a></li>
<li class="chapter" data-level="4.11" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#first-step-analysis"><i class="fa fa-check"></i><b>4.11</b> First step analysis</a></li>
<li class="chapter" data-level="4.12" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-expected-time-to-absorption"><i class="fa fa-check"></i><b>4.12</b> The expected time to absorption</a></li>
<li class="chapter" data-level="4.13" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-long-term-distribution-of-a-markov-chain"><i class="fa fa-check"></i><b>4.13</b> The long-term distribution of a Markov chain</a></li>
<li class="chapter" data-level="4.14" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#stationary-and-limiting-distributions-for-a-single-closed-class"><i class="fa fa-check"></i><b>4.14</b> Stationary and limiting distributions for a single closed class</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#stationary-distributions"><i class="fa fa-check"></i>Stationary distributions</a></li>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#proportion-of-time-in-each-state"><i class="fa fa-check"></i>Proportion of Time in Each State</a></li>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-method-of-finding-the-stationary-distribution"><i class="fa fa-check"></i>The method of finding the stationary distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#sufficient-conditions-for-the-long-run-behaviour-of-a-markov-chain"><i class="fa fa-check"></i><b>4.15</b> Sufficient conditions for the long-run behaviour of a Markov chain</a></li>
<li class="chapter" data-level="4.16" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#limiting-distributions"><i class="fa fa-check"></i><b>4.16</b> Limiting distributions</a></li>
<li class="chapter" data-level="4.17" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#main-result"><i class="fa fa-check"></i><b>4.17</b> Main result</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#applications-of-markov-chains-to-ncd-systems"><i class="fa fa-check"></i>Applications of Markov chains to NCD systems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="poisson-processes.html"><a href="poisson-processes.html"><i class="fa fa-check"></i><b>5</b> Poisson processes</a>
<ul>
<li class="chapter" data-level="5.1" data-path="poisson-processes.html"><a href="poisson-processes.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="poisson-processes.html"><a href="poisson-processes.html#poisson-process"><i class="fa fa-check"></i><b>5.2</b> Poisson process</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="poisson-processes.html"><a href="poisson-processes.html#counting-process"><i class="fa fa-check"></i><b>5.2.1</b> Counting Process</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="poisson-processes.html"><a href="poisson-processes.html#properties-of-poisson-processes"><i class="fa fa-check"></i><b>5.3</b> Properties of Poisson processes</a></li>
<li class="chapter" data-level="5.4" data-path="poisson-processes.html"><a href="poisson-processes.html#poisson-process-definition-2"><i class="fa fa-check"></i><b>5.4</b> Poisson process : Definition 2</a></li>
<li class="chapter" data-level="5.5" data-path="poisson-processes.html"><a href="poisson-processes.html#inter-arrival-times-inter-event-times-or-holding-times"><i class="fa fa-check"></i><b>5.5</b> Inter arrival times (Inter event times or holding times)</a></li>
<li class="chapter" data-level="" data-path="poisson-processes.html"><a href="poisson-processes.html#important-result"><i class="fa fa-check"></i>Important result</a></li>
<li class="chapter" data-level="5.6" data-path="poisson-processes.html"><a href="poisson-processes.html#superposition-and-thinning-properties"><i class="fa fa-check"></i><b>5.6</b> Superposition and thinning properties</a>
<ul>
<li class="chapter" data-level="" data-path="poisson-processes.html"><a href="poisson-processes.html#superposition-property"><i class="fa fa-check"></i>Superposition property</a></li>
<li class="chapter" data-level="" data-path="poisson-processes.html"><a href="poisson-processes.html#splitting-thinning-property"><i class="fa fa-check"></i>Splitting (Thinning) property</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="poisson-processes.html"><a href="poisson-processes.html#memorylessness"><i class="fa fa-check"></i><b>5.7</b> Memorylessness</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="tutorials.html"><a href="tutorials.html"><i class="fa fa-check"></i><b>6</b> Tutorials</a>
<ul>
<li class="chapter" data-level="6.1" data-path="tutorials.html"><a href="tutorials.html#tutorial-1"><i class="fa fa-check"></i><b>6.1</b> Tutorial 1</a></li>
<li class="chapter" data-level="6.2" data-path="tutorials.html"><a href="tutorials.html#tutorial-2"><i class="fa fa-check"></i><b>6.2</b> Tutorial 2</a></li>
<li class="chapter" data-level="6.3" data-path="tutorials.html"><a href="tutorials.html#tutorial-3"><i class="fa fa-check"></i><b>6.3</b> Tutorial 3</a></li>
<li class="chapter" data-level="6.4" data-path="tutorials.html"><a href="tutorials.html#tutorial-2-1"><i class="fa fa-check"></i><b>6.4</b> Tutorial 2</a></li>
<li class="chapter" data-level="6.5" data-path="tutorials.html"><a href="tutorials.html#tutorial-3-1"><i class="fa fa-check"></i><b>6.5</b> Tutorial 3</a></li>
<li class="chapter" data-level="6.6" data-path="tutorials.html"><a href="tutorials.html#tutorial-4"><i class="fa fa-check"></i><b>6.6</b> Tutorial 4</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>7</b> Applications</a>
<ul>
<li class="chapter" data-level="7.1" data-path="applications.html"><a href="applications.html#datacamp-light"><i class="fa fa-check"></i><b>7.1</b> DataCamp Light</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>8</b> Final words</a>
<ul>
<li class="chapter" data-level="8.1" data-path="final-words.html"><a href="final-words.html#datacamp-light-1"><i class="fa fa-check"></i><b>8.1</b> DataCamp Light</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SCMA469 Actuarial Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="review-of-probability-theory" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Review of probability theory</h1>
<div id="random-variables" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Random variables</h2>
<p>The dynamics of a stochastic process are describes by random variables
and probability distributions. This section provides a brief discussion
of the properties of random variables.</p>
<p>The probability theory is about random variables. Roughly speaking, a
random variable can be regarded as an uncertain, numerical quantity
(i.e. the value in <span class="math inline">\(\mathbb{R}\)</span>) whose possible values depend on the
outcomes of a certain random phenomenon. The random variable is usually
denoted by a capital letter <span class="math inline">\(X, Y, \ldots,\)</span> etc..</p>
<p>More precisely, let <span class="math inline">\(S\)</span> be a sample space. A <strong>random variable</strong> <span class="math inline">\(X\)</span> is
a real-valued function defined on the sample space <span class="math inline">\(S\)</span>,
<span class="math display">\[X : S \rightarrow \mathbb{R}.\]</span> Hence, the random variable <span class="math inline">\(X\)</span> is a
function that maps outcomes to real values.</p>
<div class="example">
<p><span id="exm:unlabeled-div-4" class="example"><strong>Example 2.1  </strong></span>*Two coins are tossed simultaneously and the outcomes are
<span class="math inline">\(HH, HT, TH\)</span> and <span class="math inline">\(TT\)</span>. We can associate the outcomes of this experiment
with the set <span class="math inline">\(A = \{1,2,3,4 \}\)</span>, where <span class="math inline">\(X(HH) = 1, X(HT) = 2, X(TH) = 3\)</span>
and <span class="math inline">\(X(TT) = 4\)</span>. Assume each of the outcomes has an equal probability of
1/4. Here, we can associate a function <span class="math inline">\(P\)</span> (known as a probability
measure) defined on <span class="math inline">\(S = \{HH, HT, TH, TT \}\)</span> by</p>
<p><span class="math display">\[P(HH) = 1/4,  P(HT) = 1/4,  P(TH) = 1/4,  P(TT) = 1/4.\]</span></p>
</div>
<p>A probability measure <span class="math inline">\(P : \mathcal{A} \rightarrow [0,1]\)</span>, where
<span class="math inline">\(\mathcal{A}\)</span> is a collection of subsets of <span class="math inline">\(S\)</span>, has the following
properties</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(0 \le P(A), \quad A \subset S\)</span>.</p></li>
<li><p><span class="math inline">\(P(S) = 1\)</span>.</p></li>
<li><p>If <span class="math inline">\(A_i \cap A_j = \emptyset\)</span> for <span class="math inline">\(i,j = 1,2, \ldots\)</span>, and
<span class="math inline">\(i \neq j\)</span> where <span class="math inline">\(A_j \subset S\)</span>, then
<span class="math display">\[P(\cup^\infty_{i=1} A_i)  = \sum^\infty_{i=1} P(A_i).\]</span></p></li>
</ol>
<p>Random variables can be discrete or continuous. If the range of a random
variable is finite or countably infinite, then the random variable is a
<strong>discrete random variable</strong>. Otherwise, if its range is an uncountable
set, then it is a <strong>continuous random variable</strong>.</p>
</div>
<div id="probability-distribution" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Probability distribution</h2>
<p>The probability distribution of a random variable <span class="math inline">\(X\)</span> is a function
describing all possible values of <span class="math inline">\(X\)</span> and their corresponding
probabilities or the likelihood of obtaining those values of <span class="math inline">\(X\)</span>.
Functions that define the probability measure for a discrete or a
continuous random variable are the <strong>probability mass function (pmf)</strong>
and the <strong>probability density function (pdf)</strong>, respectively.</p>
<p>Suppose <span class="math inline">\(X\)</span> is a discrete random variable. Then the function
<span class="math display">\[f(x) = P(X = x)\]</span> that is defined for each <span class="math inline">\(x\)</span> in the range of <span class="math inline">\(X\)</span> is
called the <strong>probability mass function</strong> (p.m.f) of a random variable
<span class="math inline">\(X\)</span>.</p>
<p>Suppose <span class="math inline">\(X\)</span> is a continuous random variable with c.d.f <span class="math inline">\(F\)</span> and there
exists a nonnegative, integrable function <span class="math inline">\(f\)</span>,
<span class="math inline">\(f: \mathbb{R} \rightarrow [0, \infty)\)</span> such that
<span class="math display">\[F(x) = \int_{-\infty}^x f(y)\, dy\]</span> Then the function <span class="math inline">\(f\)</span> is called
the <strong>probability density function</strong> (p.d.f) of a random variable <span class="math inline">\(X\)</span>.</p>
<div id="examples-of-discrete-and-continuous-random-variables" class="section level4 unnumbered">
<h4>Examples of discrete and continuous random variables</h4>
<p>The main quantities of interest in a portfolio of motor insurance are
the number of claims arriving in a fixed time period and the sizes of
those claims. Clearly, the number of claims can be describe by a
discrete random variable, whose range is finite or countably infinite.
On the other hand, the claim sizes can be describe by a continuous
random variable defined over continuous sample spaces.</p>
<div class="example">
<p><span id="exm:unlabeled-div-5" class="example"><strong>Example 2.2  </strong></span><em>Let <span class="math inline">\(N\)</span> denote the number of claims which arise up to a
given time. The range of all possible values <span class="math inline">\(N\)</span> is
<span class="math inline">\(\mathbf{N} \cup \{0\}\)</span>. Here <span class="math inline">\(N\)</span> is an example of discrete random
variable. We could model the number of claims by the Poisson family of
distributions. Recall that a random variable <span class="math inline">\(N\)</span> has a Poisson
distribution with the parameter <span class="math inline">\(\lambda\)</span> if its probability
distribution is given by
<span class="math display">\[f(n) = e^{- \lambda} \frac{\lambda^n}{n !}, \quad \text{ for } n = 0,1,\ldots.\]</span></em></p>
<p><em>Now suppose further that the number of claims <span class="math inline">\(N\)</span> which arise on a
portfolio in a week has a <span class="math inline">\(\text{Poisson}(\lambda)\)</span> where <span class="math inline">\(\lambda = 5\)</span>.
Calculate the following quantities:</em></p>
<ol style="list-style-type: decimal">
<li><p><em><span class="math inline">\(\Pr(N \ge 6)\)</span>.</em></p></li>
<li><p><em><span class="math inline">\(\mathrm{E}[N]\)</span>.</em></p></li>
</ol>
</div>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\Pr(N \ge 6) = 1 - \Pr(N \le 5) = 1 - \sum_{n=0}^5 f(n) = 0.3840393.\)</span></p></li>
<li><p>Clearly, <span class="math inline">\(\mathrm{E}[N] = \lambda = 5\)</span>.</p></li>
</ol>
<p>In R, density, distribution function, for the Poisson distribution with parameter <span class="math inline">\(\lambda\)</span> is shown as follows:</p>
<table>
<colgroup>
<col width="21%" />
<col width="38%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th>Distribution</th>
<th>Density function: <span class="math inline">\(P(X = x)\)</span></th>
<th>Distribution function: <span class="math inline">\(P(X ≤ x)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Poisson</td>
<td><code>dpois(x, lambda, log = FALSE)</code></td>
<td><code>ppois(q, lambda, lower.tail = TRUE, log.p = FALSE)</code></td>
</tr>
</tbody>
</table>
<p>When lower.tail is set to be TRUE (or default), probabilities are <span class="math inline">\(P(X ≤ x)\)</span>, otherwise, <span class="math inline">\(P(X &gt; x)\)</span>.</p>
<script src=https://cdn.datacamp.com/datacamp-light-latest.min.js></script>
<div data-datacamp-exercise="" data-height="300" data-encoded="true">
eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJwcG9pcyg1LCBsYW1iZGEgPSA1LCBsb3dlci50YWlsID0gRkFMU0UpIn0=
</div>
<div class="example">
<p><span id="exm:unlabeled-div-6" class="example"><strong>Example 2.3  </strong></span><em>Let <span class="math inline">\(X\)</span> denote the claim sizes in a given time period.
The range of all possible values <span class="math inline">\(X\)</span> is the set of all non-negative
numbers. Here <span class="math inline">\(X\)</span> is an example of a continuous random variable.
Suitable families of distributions which could be used to modelled claim
sizes are "fat tails" distribution. They allow for possibilities of
large claim sizes.</em></p>
<p><em>Examples of fat-tailed distributions include</em></p>
<ul>
<li><p><em>the Pareto distribution,</em></p></li>
<li><p><em>the Log-normal distribution,</em></p></li>
<li><p><em>the Weibull distribution with shape parameter greater than 0 but
less than 1, and</em></p></li>
<li><p><em>the Burr distribution.</em></p></li>
</ul>
<script src=https://cdn.datacamp.com/datacamp-light-latest.min.js></script>
<div data-datacamp-exercise="" data-height="300" data-encoded="true">
eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KGdncGxvdDIpXG5kZiA8LSBkYXRhLmZyYW1lKHg9c2VxKDAsMTAsYnk9MC4xKSlcbmdncGxvdChkZikgKyBcbiAgICBzdGF0X2Z1bmN0aW9uKGFlcyh4KSxmdW49ZHdlaWJ1bGwsYXJncyA9IGxpc3Qoc2hhcGUgPSAxLCBzY2FsZSA9IDEpKSAgKyBcbiAgICBsYWJzKHggPSBcInhcIiwgeSA9IFwiZih4KVwiLCBcbiAgICAgICB0aXRsZSA9IFwiV2VpYnVsbCBEaXN0cmlidXRpb24gV2l0aCBTaGFwZSAmIFNjYWxlIFBhcmFtZXRlcnMgPSAxXCIpICJ9
</div>
<p>See <a href="https://dk81.github.io/dkmathstats_site/rvisual-cont-prob-dists.html" class="uri">https://dk81.github.io/dkmathstats_site/rvisual-cont-prob-dists.html</a> for more details.</p>
</div>
<p>The course "SCMA 470 Risk Analysis and Credibility" provides more
details about the loss distribution.</p>
</div>
</div>
<div id="conditional-probability" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Conditional probability</h2>
<p>A stochastic process can be defined as a collection or sequence of
random variables. The concept of <strong>conditional probability</strong> plays an
important role to analyse dependency between random variables in the
process. Roughly speaking, conditional probability is the probability of
seeing some event knowing that some other event has actually occurred.</p>
<p>Let <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> be two events (elements of <span class="math inline">\(\mathcal{A}\)</span>). The
conditional probability of event <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span> denoted by <span class="math inline">\(P(A | B)\)</span> is
defined as <span class="math display">\[P(A|B) =  \frac{P(A \cap B)}{P(B)}.\]</span> Note that
<span class="math inline">\(P(A \cap B)\)</span> is often called the joint probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, and
<span class="math inline">\(P(A)\)</span> and <span class="math inline">\(P(B)\)</span> are often called the marginal probabilities of <span class="math inline">\(A\)</span> and
<span class="math inline">\(B\)</span>, respectively.</p>
<p>The events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if the occurrence of either one
of the events does not affect the probability of occurrence of the
other. More precisely, the events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if
<span class="math display">\[P(A \cap B) = P(A)P(B),\]</span> or equivalently, <span class="math display">\[P(A|B) =  P(A).\]</span></p>
</div>
<div id="law-of-total-probability" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Law of total probability</h2>
<p>Suppose there are three events: <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span>. Events <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>
are distinct from each other while event <span class="math inline">\(A\)</span> intersects with both
events. We do not know the probability of event <span class="math inline">\(A\)</span>. However, partial
information and dependencies between events can be used to calculate the
probability of event <span class="math inline">\(A\)</span>, i.e. we know the probability of event A under
condition B and the probability of event A under condition C.</p>
<p>The total probability rule states that by using the two conditional
probabilities, we can find the probability of event A, which is
<span class="math display">\[P(A) = P(A \cap B) + P(A \cap C).\]</span> In general, suppose
<span class="math inline">\(B_1, B_2, \ldots B_n\)</span> be a collection of events that partition the
sample space. Then for any event <span class="math inline">\(A\)</span>,
<span class="math display">\[P(A) = \sum_{i = 1}^n   P(A \cap B_i )  = \sum_{i = 1}^n   P(A | B_i ) P(B_i) .\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-7" class="example"><strong>Example 2.4  </strong></span><em>Suppose in a particular study area, the vaccination rate
for the yearly flu virus is 70%. Suppose of those vaccinated, 10% of the
residents still get the flu that year. Calculate the conditional
probability of someone getting the flu in this area given that the
person was vaccinated.</em></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-8" class="example"><strong>Example 2.5  </strong></span><em>You are an invester buying shares of a company. You have
discovered that the company is planning to introduce a new project that
is likely to affect the company’s stock price. You have determined the
following probabilities:</em></p>
<ul>
<li><p><em>There is a 80% probability that the new project will be launched.</em></p></li>
<li><p><em>If a company launches the project, there is a 85% probability that
the company’s stock price will increase.</em></p></li>
<li><p><em>If a company does not launch the project, there is a 30%
probability that the company’s stock price will increase.</em></p></li>
</ul>
</div>
<p>Calculate the probability that the company’s stock price will increase.</p>
</div>
<div id="conditional-distribution-and-conditional-expectation" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Conditional distribution and conditional expectation</h2>
<p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be two discrete random variables with joint probability
mass function <span class="math display">\[f(x,y) = P(X = x, Y = y).\]</span> If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are
continuous random variables, the joint probability density function
<span class="math inline">\(f (x, y)\)</span> satisfies
<span class="math display">\[P( X \le x, Y \le y) = \int_{-\infty}^x \int_{-\infty}^y f(u,v) \, du\, dv.\]</span></p>
<p>When no information is given about the value of <span class="math inline">\(Y\)</span>, the marginal
probability density function of <span class="math inline">\(X\)</span>, <span class="math inline">\(f_X(x)\)</span> is used to calculate the
probabilities of events concerning <span class="math inline">\(X\)</span>. However, when the value of <span class="math inline">\(Y\)</span>
is known, to find such probabilities, <span class="math inline">\(f_{X|Y} (x|y)\)</span>, the conditional
probability density function of <span class="math inline">\(X\)</span> given that <span class="math inline">\(Y = y\)</span> is used and is
defined as follows: <span class="math display">\[f_{X|Y} (x|y)  = \frac{f(x,y)}{f_Y(y)}\]</span> provided
that <span class="math inline">\(f_Y (y) &gt; 0\)</span>. The conditional mass function of <span class="math inline">\(X\)</span> is defined in a
similar manner. <span class="math display">\[P(X = x | Y = y) = \frac{P(X = x, Y = y)}{P(X = x)}.\]</span></p>
<p>Note also that the conditional probability density function of <span class="math inline">\(X\)</span> given
that <span class="math inline">\(Y = y\)</span> is itself a probability density function, i.e.
<span class="math display">\[\int_{-\infty}^\infty f_{X|Y}(x|y)\, dx  =  1.\]</span></p>
<p>Note that the conditional probability distribution function of <span class="math inline">\(X\)</span> given
that <span class="math inline">\(Y = y\)</span>, the conditional expectation of <span class="math inline">\(X\)</span> given that <span class="math inline">\(Y = y\)</span> can
be as follows:
<span class="math display">\[F_{Y|X}(x|y) = P(X \le x | Y = y) = \int_ {-\infty}^x f_{X|Y}(t|y) \, dt\]</span>
and
<span class="math display">\[\mathrm{E}(X|Y = y) =  \int_{-\infty}^{\infty} x  f_{X|Y}(x|y) \, dx,\]</span>
where <span class="math inline">\(f_Y(y) &gt; 0\)</span>.</p>
<p>Note that if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, then <span class="math inline">\(f_{X|Y}\)</span> coincides with
<span class="math inline">\(f_X\)</span> because
<span class="math display">\[f_{X|Y}(x|y) = \frac{f(x,y)}{f_Y(y)} =\frac{f_X(x)f_Y(y)}{f_Y(y)} = f_X(x).\]</span></p>
</div>
<div id="central-limit-theorem" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> Central Limit Theorem</h2>
<p>This section introduces the Central Limit Theorem, which is an important
theorem in probability theory. It states that the mean of <span class="math inline">\(n\)</span>
independent and identically distributed random variables has an
approximate normal distribution given a sufficiently large <span class="math inline">\(n\)</span>. This
applies to a collection of random variables from any distribution with a
finite mean and variance. In summary we can use the Central Limit
Theorem to extract probabilistic information about the sums of
independent and identical random variables.</p>
<!-- Central Limit Theorem {#central-limit-theorem-1 .unnumbered} -->
<!-- --------------------- -->
<p>Let <span class="math inline">\(X_1, X_2, \ldots\)</span> be a sequence of i.i.d. random variables with a
finite mean <span class="math inline">\(\mathrm{E}[X_i] = \mu\)</span> and finite variance
<span class="math inline">\(\mathrm{Var}[X_i] = \sigma^2\)</span>. Let <span class="math inline">\(Z_n\)</span> be the normalised average of
the first <span class="math inline">\(n\)</span> random variables <span class="math display">\[\begin{aligned}
        Z_n &amp;= \frac{\sum_{i=1}^n X_i/n  - \mu}{\sigma/\sqrt{n}} \\
               &amp;= \frac{X_1 + X_2 + \ldots + X_n  - n\mu}{\sigma \sqrt{n}}.
    \end{aligned}\]</span> Then <span class="math inline">\(Z_n\)</span> converges in distribution to a standard
normal distribution.</p>
<!-- # Introduction to Stochastic Processes {#intro} -->
<!-- You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods). -->
<!-- Figures and tables with captions will be placed in `figure` and `table` environments, respectively. -->
<!-- ```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'} -->
<!-- par(mar = c(4, 4, .1, .1)) -->
<!-- plot(pressure, type = 'b', pch = 19) -->
<!-- ``` -->
<!-- Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab). -->
<!-- ```{r nice-tab, tidy=FALSE} -->
<!-- knitr::kable( -->
<!--   head(iris, 20), caption = 'Here is a nice table!', -->
<!--   booktabs = TRUE -->
<!-- ) -->
<!-- ``` -->
<!-- You can write citations, too. For example, we are using the **bookdown** package [@R-bookdown] in this sample book, which was built on top of R Markdown and **knitr** [@xie2015]. -->
<!-- The course will cover the probabilistic framework for stochastic models -->
<!-- of real-world applications with emphasis on actuarial work. We will -->
<!-- illustrate some practical actuarial problems for which we will develop -->
<!-- mathematical models, tools and techniques for analysing and quantifying -->
<!-- the uncertainty of the problems. -->
<!-- Here are some of the examples which will be covered later in the course. -->
<!-- Examples of real world processes -->
<!-- ================================ -->
<!-- ::: {.example} -->
<!-- **Example 1**. *(**No claims discount systems (NCD)**) A well-known -->
<!-- model widely used by auto insurance companies is the **no claims -->
<!-- discount system**, in which an insured receives a discount for a claim -->
<!-- free year, while the insured is penalised by an additional premium when -->
<!-- one or more accidents occur.* -->
<!-- *An example of the NCD system in UK may be structured as follows:* -->
<!--     *Level*     *7*      *6*     *5*     *4*     *3*     *2*     *1* -->
<!--   ----------- -------- ------- ------- ------- ------- ------- ------- -->
<!--    *Premium*   *100%*   *75%*   *65%*   *55%*   *45%*   *40%*   *33%* -->
<!-- *The rules for moving between these levels are as follows:* -->
<!-- -   *For a claim-free year, a policyholder moves down 1 level.* -->
<!-- -   *Levels 4$-$7:* -->
<!--     -   *For every one claim, the policyholder moves up 1 level or -->
<!--         remains at level 7.* -->
<!--     -   *For every two or more claims, move to, or remains at, level 7.* -->
<!-- -   *Levels 2$-$3:* -->
<!--     -   *For every one claim, move up 2 levels.* -->
<!--     -   *For every two claims, move up 4 levels.* -->
<!--     -   *For every three or more claims, move to level 7.* -->
<!-- -   *Level 1:* -->
<!--     -   *For every one claim, move to level 4.* -->
<!--     -   *For every two claims, move to level 6.* -->
<!--     -   *For every three or more claims, move to level 7.* -->
<!-- *The no claims discount system is a form of experience rating consisting -->
<!-- of a finite number of levels (or classes), each with its own premium. -->
<!-- The 7 levels are experience-rated as described above.* -->
<!-- *For the NCD model, questions of interest may include:* -->
<!-- 1.  *For 10,000 policyholders at level 7, estimate the *expected -->
<!--     numbers* at each discount level at a given time, or once stability -->
<!--     has been achieved.* -->
<!-- 2.  *What is the *probability* that a policyholder who is at a specific -->
<!--     discount level (i.e. one of the levels 1-6) has no discount after 2 -->
<!--     years?* -->
<!-- 3.  *What is the *distribution* of being in one of the levels at time 5 -->
<!--     years?* -->
<!-- 4.  *Suppose a large number of people having the same claim -->
<!--     probabilities take out policies at the same time. What is the -->
<!--     proportion would you expect to be in each discount level in the long -->
<!--     run?* -->
<!-- *What would be a suitable model to study the NCD system? As opposed to a -->
<!-- **deterministic model** for which its outcomes are fixed, the outcomes -->
<!-- of the NCD model are uncertain. It turns out that the NCD system can be -->
<!-- studied within the framework of Markov chains, which are examples of -->
<!-- stochastic processes. The use of matrix algebra provides a powerful tool -->
<!-- to understand and analyse the processes.* -->
<!-- *The evolution of the states or levels can be described the random -->
<!-- variables $X_0, X_1,X_2, \ldots$ and probability distributions, where -->
<!-- $X_n$ is the level of the policyholder at time $n$. In this example, the -->
<!-- set of all states called the state space is discrete, which consists of -->
<!-- seven levels, and the time variable is also discrete. This is an example -->
<!-- of a **discrete time, discrete state space stochastic process**.* -->
<!-- ::: -->
<!-- ::: {.example} -->
<!-- **Example 2**. *(**Poisson processes**) Consider the number of claims -->
<!-- that occur up to time $t$ (denoted by $N_t$) from a portfolio of health -->
<!-- insurance policies (or other types of insurance products). Suppose that -->
<!-- the average rate of occurrence of claims per time unit (e.g. day or week -->
<!-- ) is given by $\lambda$.* -->
<!-- *Here are some questions of interest:* -->
<!-- 1.  *On average, 20 claims arrive every day, what is the probability -->
<!--     that more than 100 claims arrive within a week?* -->
<!-- 2.  *What is the expected time until the next claim?* -->
<!-- *In this example, the state space consists of all whole numbers -->
<!-- $\{0, 1, 2, \ldots\}$, while the time variable is continuous. The -->
<!-- process is a **continuous-time stochastic process with discrete state -->
<!-- space**. The model used to model the insurance claims is an example of -->
<!-- **Poisson processes**. The Poisson process is one of the most -->
<!-- widely-used counting processes. Even thought we know that claims occur -->
<!-- at a certain rate, but completely at random. Moreover, the timing -->
<!-- between claims seem to be completely random.* -->
<!-- *Later, we will see that there are several ways to describe this -->
<!-- process. One can focus on the number of claims that occur up to time $t$ -->
<!-- or the times between those claims when they occur. Many important -->
<!-- properties of Poisson processes will be discussed.* -->
<!-- ::: -->
<!-- ::: {.example} -->
<!-- **Example 3**. *(**Markov processes**) Suppose that we observe a total -->
<!-- of $n$ independent lives all aged between $x$ and $x + 1$. For life $i$, -->
<!-- we define the following terms:* -->
<!-- -   *$x+ a_i$ is the age at which observation -->
<!--     begins,$\quad 0 \le a_i < 1$.* -->
<!-- -   *$x+ b_i$ is the age at which observation ends, if life does not -->
<!--     die, $\quad 0 \le b_i < 1$.* -->
<!-- -   *$x+ t_i$ is the age at which observation stops, by death or -->
<!--     censoring.* -->
<!-- -   *$d_i = 1$, if life $i$ dies, otherwise $d_i = 0$, if life $i$ -->
<!--     censored.* -->
<!-- *For example, consider the following mortality data on eight lives all -->
<!-- aged between $70$ and $71$.* -->
<!--    *Life*   *$a_i$*   *$b_i$*   *$d_i$*   *$t_i$* -->
<!--   -------- --------- --------- --------- --------- -->
<!--     *1*       *0*       *1*       *1*     *0.25* -->
<!--     *2*       *0*       *1*       *1*     *0.75* -->
<!--     *3*       *0*       *1*       *0*       *1* -->
<!--     *4*      *0.1*     *0.6*      *1*      *0.5* -->
<!--     *5*      *0.2*     *0.7*      *1*      *0.6* -->
<!--     *6*      *0.2*     *0.4*      *0*      *0.4* -->
<!--     *7*      *0.5*      *1*       *1*     *0.75* -->
<!--     *8*      *0.5*    *0.75*      *0*     *0.75* -->
<!-- *How would one use this dataset to estimate the probability that a life -->
<!-- aged 70 dies before age $70 + t$ or survives to at least age $70 + t$, -->
<!-- for $t \in [0,1)$?* -->
<!-- *In this example, we can represent the process by $\{X_t\}_{t \ge 0}$ -->
<!-- with two possible states (alive or dead). This model is also an example -->
<!-- of a **continuous-time stochastic process with discrete state space**.* -->
<!-- *Here, we illustrate three actuarial applications which can be modelled -->
<!-- by some **stochastic processes**. We should also emphasis that the -->
<!-- outcome of one of the above processes is not fixed or uncertain. The -->
<!-- course will provide important tools and techniques to analyse the -->
<!-- problems with the goal of quantifying the uncertainty in the system.* -->
<!-- ::: -->
<!-- Review of probability theory -->
<!-- ============================ -->
<!-- Random variables -->
<!-- ---------------- -->
<!-- The dynamics of a stochastic process are describes by random variables -->
<!-- and probability distributions. This section provides a brief discussion -->
<!-- of the properties of random variables. -->
<!-- The probability theory is about random variables. Roughly speaking, a -->
<!-- random variable can be regarded as an uncertain, numerical quantity -->
<!-- (i.e. the value in $\mathbb{R}$) whose possible values depend on the -->
<!-- outcomes of a certain random phenomenon. The random variable is usually -->
<!-- denoted by a capital letter $X, Y, \ldots,$ etc.. -->
<!-- More precisely, let $S$ be a sample space. A **random variable** $X$ is -->
<!-- a real-valued function defined on the sample space $S$, -->
<!-- $$X : S \rightarrow \mathbb{R}.$$ Hence, the random variable $X$ is a -->
<!-- function that maps outcomes to real values. -->
<!-- ::: {.example} -->
<!-- **Example 4**. *Two coins are tossed simultaneously and the outcomes are -->
<!-- $HH, HT, TH$ and $TT$. We can associate the outcomes of this experiment -->
<!-- with the set $A = \{1,2,3,4 \}$, where $X(HH) = 1, X(HT) = 2, X(TH) = 3$ -->
<!-- and $X(TT) = 4$. Assume each of the outcomes has an equal probability of -->
<!-- 1/4. Here, we can associate a function $P$ (known as a probability -->
<!-- measure) defined on $S = \{HH, HT, TH, TT \}$ by -->
<!-- $$P(HH) = 1/4,  P(HT) = 1/4,  P(TH) = 1/4,  P(TT) = 1/4.$$* -->
<!-- ::: -->
<!-- A probability measure $P : \mathcal{A} \rightarrow [0,1]$, where -->
<!-- $\mathcal{A}$ is a collection of subsets of $S$, has the following -->
<!-- properties -->
<!-- 1.  $0 \le P(A), \quad A \subset S$. -->
<!-- 2.  $P(S) = 1$. -->
<!-- 3.  If $A_i \cap A_j = \emptyset$ for $i,j = 1,2, \ldots$, and -->
<!--     $i \neq j$ where $A_j \subset S$, then -->
<!--     $$P(\cup^\infty_{i=1} A_i)  = \sum^\infty_{i=1} P(A_i).$$ -->
<!-- Random variables can be discrete or continuous. If the range of a random -->
<!-- variable is finite or countably infinite, then the random variable is a -->
<!-- **discrete random variable**. Otherwise, if its range is an uncountable -->
<!-- set, then it is a **continuous random variable**. -->
<!-- Probability distribution -->
<!-- ------------------------ -->
<!-- The probability distribution of a random variable $X$ is a function -->
<!-- describing all possible values of $X$ and their corresponding -->
<!-- probabilities or the likelihood of obtaining those values of $X$. -->
<!-- Functions that define the probability measure for a discrete or a -->
<!-- continuous random variable are the **probability mass function (pmf)** -->
<!-- and the **probability density function (pdf)**, respectively. -->
<!-- Suppose $X$ is a discrete random variable. Then the function -->
<!-- $$f(x) = P(X = x)$$ that is defined for each $x$ in the range of $X$ is -->
<!-- called the **probability mass function** (p.m.f) of a random variable -->
<!-- $X$. -->
<!-- Suppose $X$ is a continuous random variable with c.d.f $F$ and there -->
<!-- exists a nonnegative, integrable function $f$, -->
<!-- $f: \mathbb{R} \rightarrow [0, \infty)$ such that -->
<!-- $$F(x) = \int_{-\infty}^x f(y)\, dy$$ Then the function $f$ is called -->
<!-- the **probability density function** (p.d.f) of a random variable $X$. -->
<!-- Examples of discrete and continuous random variables {#examples-of-discrete-and-continuous-random-variables .unnumbered} -->
<!-- ---------------------------------------------------- -->
<!-- The main quantities of interest in a portfolio of motor insurance are -->
<!-- the number of claims arriving in a fixed time period and the sizes of -->
<!-- those claims. Clearly, the number of claims can be describe by a -->
<!-- discrete random variable, whose range is finite or countably infinite. -->
<!-- On the other hand, the claim sizes can be describe by a continuous -->
<!-- random variable defined over continuous sample spaces. -->
<!-- ::: {.example} -->
<!-- **Example 5**. *Let $N$ denote the number of claims which arise up to a -->
<!-- given time. The range of all possible values $N$ is -->
<!-- $\mathbf{N} \cup \{0\}$. Here $N$ is an example of discrete random -->
<!-- variable. We could model the number of claims by the Poisson family of -->
<!-- distributions. Recall that a random variable $N$ has a Poisson -->
<!-- distribution with the parameter $\lambda$ if its probability -->
<!-- distribution is given by -->
<!-- $$f(n) = e^{- \lambda} \frac{\lambda^n}{n !}, \quad \text{ for } n = 0,1,\ldots.$$* -->
<!-- *Now suppose further that the number of claims $N$ which arise on a -->
<!-- portfolio in a week has a $\text{Poisson}(\lambda)$ where $\lambda = 5$. -->
<!-- Calculate the following quantities:* -->
<!-- 1.  *$\Pr(N \ge 6)$.* -->
<!-- 2.  *$\mathrm{E}[N]$.* -->
<!-- ::: -->
<!-- 1.  $\Pr(N \ge 6) = 1 - \Pr(N \le 5) = 1 - \sum_{n=0}^5 f(n) = 0.3840393.$ -->
<!-- 2.  Clearly, $\mathrm{E}[N] = \lambda = 5$. -->
<!-- ::: {.example} -->
<!-- **Example 6**. *Let $X$ denote the claim sizes in a given time period. -->
<!-- The range of all possible values $X$ is the set of all non-negative -->
<!-- numbers. Here $X$ is an example of a continuous random variable. -->
<!-- Suitable families of distributions which could be used to modelled claim -->
<!-- sizes are \"fat tails\" distribution. They allow for possibilities of -->
<!-- large claim sizes.* -->
<!-- *Examples of fat-tailed distributions include* -->
<!-- -   *the Pareto distribution,* -->
<!-- -   *the Log-normal distribution,* -->
<!-- -   *the Weibull distribution with shape parameter greater than 0 but -->
<!--     less than 1, and* -->
<!-- -   *the Burr distribution.* -->
<!-- ::: -->
<!-- The course \"SCMA 470 Risk Analysis and Credibility\" provides more -->
<!-- details about the loss distribution. -->
<!-- Conditional probability -->
<!-- ----------------------- -->
<!-- A stochastic process can be defined as a collection or sequence of -->
<!-- random variables. The concept of **conditional probability** plays an -->
<!-- important role to analyse dependency between random variables in the -->
<!-- process. Roughly speaking, conditional probability is the probability of -->
<!-- seeing some event knowing that some other event has actually occurred. -->
<!-- Let $A$ and $B$ be two events (elements of $\mathcal{A}$). The -->
<!-- conditional probability of event $A$ given $B$ denoted by $P(A | B)$ is -->
<!-- defined as $$P(A|B) =  \frac{P(A \cap B)}{P(B)}.$$ Note that -->
<!-- $P(A \cap B)$ is often called the joint probability of $A$ and $B$, and -->
<!-- $P(A)$ and $P(B)$ are often called the marginal probabilities of $A$ and -->
<!-- $B$, respectively. -->
<!-- The events $A$ and $B$ are independent if the occurrence of either one -->
<!-- of the events does not affect the probability of occurrence of the -->
<!-- other. More precisely, the events $A$ and $B$ are independent if -->
<!-- $$P(A \cap B) = P(A)P(B),$$ or equivalently, $$P(A|B) =  P(A).$$ -->
<!-- Law of total probability {#law-of-total-probability .unnumbered} -->
<!-- ------------------------ -->
<!-- Suppose there are three events: $A$, $B$, and $C$. Events $B$ and $C$ -->
<!-- are distinct from each other while event $A$ intersects with both -->
<!-- events. We do not know the probability of event $A$. However, partial -->
<!-- information and dependencies between events can be used to calculate the -->
<!-- probability of event $A$, i.e. we know the probability of event A under -->
<!-- condition B and the probability of event A under condition C. -->
<!-- The total probability rule states that by using the two conditional -->
<!-- probabilities, we can find the probability of event A, which is -->
<!-- $$P(A) = P(A \cap B) + P(A \cap C).$$ In general, suppose -->
<!-- $B_1, B_2, \ldots B_n$ be a collection of events that partition the -->
<!-- sample space. Then for any event $A$, -->
<!-- $$P(A) = \sum_{i = 1}^n   P(A \cap B_i )  = \sum_{i = 1}^n   P(A | B_i ) P(B_i) .$$ -->
<!-- ::: {.example} -->
<!-- **Example 7**. *Suppose in a particular study area, the vaccination rate -->
<!-- for the yearly flu virus is 70%. Suppose of those vaccinated, 10% of the -->
<!-- residents still get the flu that year. Calculate the conditional -->
<!-- probability of someone getting the flu in this area given that the -->
<!-- person was vaccinated.* -->
<!-- ::: -->
<!-- ::: {.example} -->
<!-- **Example 8**. *You are an invester buying shares of a company. You have -->
<!-- discovered that the company is planning to introduce a new project that -->
<!-- is likely to affect the company's stock price. You have determined the -->
<!-- following probabilities:* -->
<!-- -   *There is a 80% probability that the new project will be launched.* -->
<!-- -   *If a company launches the project, there is a 85% probability that -->
<!--     the company's stock price will increase.* -->
<!-- -   *If a company does not launch the project, there is a 30% -->
<!--     probability that the company's stock price will increase.* -->
<!-- ::: -->
<!-- Calculate the probability that the company's stock price will increase. -->
<!-- Conditional distribution and conditional expectation -->
<!-- ---------------------------------------------------- -->
<!-- Let $X$ and $Y$ be two discrete random variables with joint probability -->
<!-- mass function $$f(x,y) = P(X = x, Y = y).$$ If $X$ and $Y$ are -->
<!-- continuous random variables, the joint probability density function -->
<!-- $f (x, y)$ satisfies -->
<!-- $$P( X \le x, Y \le y) = \int_{-\infty}^x \int_{-\infty}^y f(u,v) \, du\, dv.$$ -->
<!-- When no information is given about the value of $Y$, the marginal -->
<!-- probability density function of $X$, $f_X(x)$ is used to calculate the -->
<!-- probabilities of events concerning $X$. However, when the value of $Y$ -->
<!-- is known, to find such probabilities, $f_{X|Y} (x|y)$, the conditional -->
<!-- probability density function of $X$ given that $Y = y$ is used and is -->
<!-- defined as follows: $$f_{X|Y} (x|y)  = \frac{f(x,y)}{f_Y(y)}$$ provided -->
<!-- that $f_Y (y) > 0$. The conditional mass function of $X$ is defined in a -->
<!-- similar manner. $$P(X = x | Y = y) = \frac{P(X = x, Y = y)}{P(X = x)}.$$ -->
<!-- Note also that the conditional probability density function of $X$ given -->
<!-- that $Y = y$ is itself a probability density function, i.e. -->
<!-- $$\int_{-\infty}^\infty f_{X|Y}(x|y)\, dx  =  1.$$ -->
<!-- Note that the conditional probability distribution function of $X$ given -->
<!-- that $Y = y$, the conditional expectation of $X$ given that $Y = y$ can -->
<!-- be as follows: -->
<!-- $$F_{Y|X}(x|y) = P(X \le x | Y = y) = \int_ {-\infty}^x f_{X|Y}(t|y) \, dt$$ -->
<!-- and -->
<!-- $$\mathrm{E}(X|Y = y) =  \int_{-\infty}^{\infty} x  f_{X|Y}(x|y) \, dx,$$ -->
<!-- where $f_Y(y) > 0$. -->
<!-- Note that if $X$ and $Y$ are independent, then $f_{X|Y}$ coincides with -->
<!-- $f_X$ because -->
<!-- $$f_{X|Y}(x|y) = \frac{f(x,y)}{f_Y(y)} =\frac{f_X(x)f_Y(y)}{f_Y(y)} = f_X(x).$$ -->
<!-- Central Limit Theorem -->
<!-- --------------------- -->
<!-- This section introduces the Central Limit Theorem, which is an important -->
<!-- theorem in probability theory. It states that the mean of $n$ -->
<!-- independent and identically distributed random variables has an -->
<!-- approximate normal distribution given a sufficiently large $n$. This -->
<!-- applies to a collection of random variables from any distribution with a -->
<!-- finite mean and variance. In summary we can use the Central Limit -->
<!-- Theorem to extract probabilistic information about the sums of -->
<!-- independent and identical random variables. -->
<!-- Central Limit Theorem {#central-limit-theorem-1 .unnumbered} -->
<!-- --------------------- -->
<!-- Let $X_1, X_2, \ldots$ be a sequence of i.i.d. random variables with a -->
<!-- finite mean $\mathrm{E}[X_i] = \mu$ and finite variance -->
<!-- $\mathrm{Var}[X_i] = \sigma^2$. Let $Z_n$ be the normalised average of -->
<!-- the first $n$ random variables $$\begin{aligned} -->
<!--         Z_n &= \frac{\sum_{i=1}^n X_i/n  - \mu}{\sigma/\sqrt{n}} \\ -->
<!--                &= \frac{X_1 + X_2 + \ldots + X_n  - n\mu}{\sigma \sqrt{n}}. -->
<!--     \end{aligned}$$ Then $Z_n$ converges in distribution to a standard -->
<!-- normal distribution. -->
<!-- Stochastic processes -->
<!-- ==================== -->
<!-- Evolution of a random process is at least partially random, and each run -->
<!-- the process leads to potentially a different outcome. It is of great -->
<!-- interest to understand or model the behaviour of a random process by -->
<!-- describing how different states, represented by random variables $X$'s, -->
<!-- evolve in the system over time. Just as probability theory is considered -->
<!-- as the study of mathematical models of random phenomena, the theory of -->
<!-- stochastic processes plays an important role in the study of -->
<!-- time-dependent random phenomena. Stochastic processes can be used to -->
<!-- represent many different random phenomena from different fields such as -->
<!-- science, engineering, finance, and economics. -->
<!-- A **stochastic process** is a collection of random variables -->
<!-- $\{ X_t : t \in T\}$ defined on a common sample space, where -->
<!-- -   $t$ is a parameter running over some index set $T$, called the -->
<!--     **time domain**. -->
<!-- -   The common sample space of the random variables (the range of -->
<!--     possible values for $X_t$) denoted by $S$ is called the **state -->
<!--     space** of the process. -->
<!-- 1.  The set of random variables may be dependent or need not be -->
<!--     identically distributed. -->
<!-- 2.  Techniques used to study stochastic processes depend on whether the -->
<!--     state space or the index set (the time domain) are discrete or -->
<!--     continuous. -->
<!-- Classification of stochastic processes -->
<!-- -------------------------------------- -->
<!-- Stochastic processes can be classified on the basis of the nature of -->
<!-- their state space and index set. -->
<!-- 1.  **Discrete state space with discrete time changes** : No claims -->
<!--     discount (NCD) policy: A car owner purchases a motor insurance -->
<!--     policy for which the premium charged depends on the claim record. -->
<!--     Let $X_t$ denote the discount status of a policyholder with three -->
<!--     levels of discount, i.e. $S = \{0,1,2\}$ corresponding to three -->
<!--     discount levels of 0%, 20% and 40% and the time set is -->
<!--     $T = \{0,1,2,\ldots\}$. Both time and state space are discrete. -->
<!-- 2.  **Discrete state space with continuous time changes** : In a health -->
<!--     insurance system, an insurance company may classify policyholders as -->
<!--     Healthy, Sick or Dead, i.e. $S = \{H, S, D\}$. The time domain can -->
<!--     be taken as continuous, $T = [0,\infty)$. -->
<!-- 3.  **Continuous state space with continuous time changes** : Let $S_t$ -->
<!--     be the total amount claimed by time $t \in T$ where $T = [0,\infty)$ -->
<!--     and the state space is $\mathbb{R}$. Both time and state space are -->
<!--     continuous. Some continuous time stochastic process taking value in -->
<!--     a continuous state space will be studied in Risk Analysis and -->
<!--     Credibility course. -->
<!-- 4.  **Continuous state space with discrete time changes** : The outcomes -->
<!--     of the above claim process $S_t$ could be recorded continuously, -->
<!--     however, we may choose to model the values only at discrete time, -->
<!--     for e.g. the total claim amounts at the end of each day. This may -->
<!--     due to the limitation of the measurement process (for e.g. expensive -->
<!--     to measure). Hence, the time domain is discrete but the state space -->
<!--     is continuous. -->
<!-- In case that claim amounts are recorded to the nearest baht or in -->
<!-- satang, i.e. discrete state space, we could also approximate or model -->
<!-- the process by using a discrete state space, rather than continuous. -->
<!-- Random walk: an introductory example -->
<!-- ------------------------------------ -->
<!-- One of the simplest examples of a stochastic process is a simple random -->
<!-- walk. Consider a simple model of the price of a stock measured in -->
<!-- satang. For each trading day $n = 0,1,2, \ldots$, the stock price -->
<!-- increases by 1 satang with probability $p$ or decreases by 1 satang with -->
<!-- probability $q = 1-p$. Let $X_n$ denote the stock price at day $n$ and -->
<!-- $X_0 = 100$, i.e. $X_0 =$. This simple model is called a simple random -->
<!-- walk. -->
<!-- In the simple random walk process, time is discrete (as observed at the -->
<!-- end of each day) and the state space is discrete. The stochastic model -->
<!-- has an infinite number of outcomes known as **stochastic realisations or -->
<!-- sample paths**. A **sample path** is then just the sequence of a -->
<!-- particular set of experiments. Graphs of some stochastic realisations of -->
<!-- the simple random walk with $p = 0.5$ and $a = 100$ are shown in Figure -->
<!-- [1]{reference-type="ref" reference="fig:SamplePaths"}. -->
<!-- ![Some stochastic realisations of the simple random -->
<!-- walk](SamplePaths.pdf){#fig:SamplePaths width="4in"} -->
<!-- A complete description of the simple random walk, observed as a -->
<!-- collection of $n$ random variables at time points -->
<!-- $t_1, t_2, \ldots, t_n$ can be specified by the joint distribution of -->
<!-- $X_{t_1}, X_{t_2}, \ldots, X_{t_n}$, i.e. -->
<!-- $$F(x_1, x_2, \ldots, x_n) = \Pr(X_{t_1} \le x_1, X_{t_2} \le x_2, \ldots, X_{t_n} \le x_n).$$ -->
<!-- However, the **multidimensional distribution function cannot be easily -->
<!-- written in a closed form** unless the random variables have a -->
<!-- multivariate normal distribution. In practice, it is more convenient to -->
<!-- deal with some stochastic processes via some simple **intermediary -->
<!-- processes** or under some addition assumptions. -->
<!-- In general, a simple random walk $X_n$ is a discrete-time stochastic -->
<!-- process defined by -->
<!-- -   $X_0 = a$ and -->
<!-- -   for $n \ge1$, -->
<!--     $$X_n = a + \sum_{i=1}^n  Z_i, \text{ where } Z_i = \begin{cases} -->
<!--         1, & \text{ with probability } p  \\ -->
<!--         -1, & \text{ with probability } q =  1- p. -->
<!--      \end{cases}$$ -->
<!-- 1.  When $p = 1/2$, the value of the process increases or decreases -->
<!--     randomly by 1 unit with equal probability. In this case, the process -->
<!--     is known as a **symmetric** random walk. -->
<!-- 2.  The (intermediary) process $\{ Z_i : i \in \mathbb{N}\}$ is a -->
<!--     sequence of independent identically distributed (i.i.d.) random -->
<!--     variables. The process $X_t$ themselves are neither independent nor -->
<!--     identically distributed. This process $Z_i$ is also known as **white -->
<!--     noise process**. -->
<!-- ::: {.example} -->
<!-- **Example 9**. *Explain why the simple random process $X_n$ is neither -->
<!-- independent nor identically distributed.* -->
<!-- ::: -->
<!-- Suppose that $X_0 = 100$. Firstly, we will show that $X_n$ is not -->
<!-- independent. From definition, the process $X_n$ can be written as -->
<!-- $$X_n = X_{n-1} + Z_n.$$ That is, the value of $X_n$ is the previous -->
<!-- value plus a random change of 1 or $-1$. Therefore, the value of the -->
<!-- process depends on the previous value and they are not independent. For -->
<!-- e.g., -->
<!-- $$\Pr(X_2 = 102) > 0 \quad \text{ but } \quad  \Pr(X_2 = 102 | X_1 = 99) = 0.$$ -->
<!-- The process $X_n$ cannot be identically distributed. For e.g. $X_1$ can -->
<!-- take the values of 99 and 101, while $X_2$ can take three different -->
<!-- values of 98, 100 and 102. -->
<!-- ::: {.example} -->
<!-- **Example 10**. *Let $$\begin{aligned} -->
<!--     \mu &= \mathrm{E}[Z_i] \\ -->
<!--     \sigma^2 &= \mathrm{Var}[Z_i] \end{aligned}$$ Calculate the -->
<!-- expectation ($\mu$) and variance ($\sigma^2$) of the random variable -->
<!-- $Z_i$.* -->
<!-- ::: -->
<!-- $$\begin{aligned} -->
<!--     \mu &= \mathrm{E}[Z_i] = 1\cdot p + (-1) \cdot q = p - q.\\\end{aligned}$$ -->
<!-- $$\begin{aligned} -->
<!--     \sigma^2 &= \mathrm{Var}[Z_i] \\ -->
<!--             &=\mathrm{E}[Z_i^2] - (\mathrm{E}[Z_i] )^2 \\ -->
<!--             &= 1 - (p-q)^2  = (p+q)^2 - (p-q)^2\\ -->
<!--             &= 4pq. \end{aligned}$$ -->
<!-- ::: {.example} -->
<!-- **Example 11**. *Calculate the expectation and variance of the process -->
<!-- $X_n$ at time $n$.* -->
<!-- ::: -->
<!-- $$\begin{aligned} -->
<!--      \mathrm{E}[X_n] &=  \mathrm{E}[a + \sum_{i=1}^n Z_i] = a + n\mu.\end{aligned}$$ -->
<!-- $$\begin{aligned} -->
<!--     \mathrm{Var}[X_n]&= \mathrm{Var}[a + \sum_{i=1}^n Z_i]  = n \sigma^2.\end{aligned}$$ -->
<!-- It should be noted that the variance of $X_n$ increases with time. -->
<!-- ::: {.example} -->
<!-- **Example 12**. *For the random process, calculate -->
<!-- $$\Pr(X_2 = 98, X_5 = 99 | X_0 = 100).$$* -->
<!-- ::: -->
<!-- The process $X_n$ must decrease on the first two days, which happens -->
<!-- with probability $(1-p)^2$. Independently, it must then increases on -->
<!-- another two days and decrease on one day (not necessarily in that -->
<!-- order), giving three different possibilities. Each of these has -->
<!-- probability $p^2(1-p)$. So -->
<!-- $$\Pr(X_2 = 98, X_5 = 99 | X_0 = 100) = (1-p)^2 \cdot 3 p^2(1-p) = 3p^2(1-p)^3.$$ -->
<!-- In what follows, we will see that exact calculations are possible for -->
<!-- the simple random walk process. Note also that it is sufficient to -->
<!-- understand the behaviour of the random walk when it starts at $X_0 = 0$. -->
<!-- ::: {.example} -->
<!-- **Example 13**. *For the random process with $X_0 = 0$, $X_{2n}$ is -->
<!-- always even and $X_{2n+1}$ is always odd. Based on the binomial -->
<!-- distribution, show that $$\begin{aligned} -->
<!--     \Pr(X_{2n} = 2m) &= {2n \choose n+m} p^{n+m} q^{n-m}, \quad   -n \le m \le n \\ -->
<!--     \Pr(X_{2n+1} = 2m+1) &= {2n + 1 \choose n+m+1} p^{n+m+1} q^{n-m}, \quad   -n-1 \le m \le n.\end{aligned}$$* -->
<!-- ::: -->
<!-- Let $A$ denote the number of $+1$ and $B$ denote the number of $-1$. -->
<!-- Then $A + B = 2n$ and $X_{2n} = A - B$ (i.e. the position at time $2n$). -->
<!-- Hence, $$\begin{aligned} -->
<!--     \Pr(X_{2n} = 2m) &= \Pr( A - B = 2m) \\ -->
<!--     &= \Pr( A - (2n - A) = 2m)  =   \Pr( 2A - 2n  = 2m) =   \Pr( A   = m + n)\\ -->
<!--     &= {2n \choose n+m} p^{n+m} q^{2n-(n+m)}, \quad   -n \le m \le n \\ -->
<!--     &= {2n \choose n+m} p^{n+m} q^{n-m}, \quad   -n \le m \le n.\end{aligned}$$ -->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="stochastic-processes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-review-probability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/pairote-sat/SCMA469/blob/master/01-review-probability.Rmd",
"text": null
},
"download": ["SCMA469Bookdownproj.pdf", "SCMA469Bookdownproj.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
