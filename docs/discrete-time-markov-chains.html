<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Discrete-time Markov chains | SCMA469 Actuarial Statistics</title>
  <meta name="description" content="Chapter 2 Discrete-time Markov chains | SCMA469 Actuarial Statistics" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Discrete-time Markov chains | SCMA469 Actuarial Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Discrete-time Markov chains | SCMA469 Actuarial Statistics" />
  
  
  

<meta name="author" content="Pairote Satiracoo" />


<meta name="date" content="2021-08-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="the-chapman-kolmogorov-equations.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SCMA469</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Down the rabbit-hole</a></li>
<li class="chapter" data-level="2" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html"><i class="fa fa-check"></i><b>2</b> Discrete-time Markov chains</a>
<ul>
<li class="chapter" data-level="2.1" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#one-step-transition-probabilities"><i class="fa fa-check"></i><b>2.1</b> One-step transition probabilities</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html"><i class="fa fa-check"></i><b>3</b> The Chapman-Kolmogorov equations</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#the-chapman-kolmogorov-equations-and-n-step-transition-probabilities"><i class="fa fa-check"></i><b>3.1</b> The Chapman-Kolmogorov equations and <span class="math inline">\(n\)</span>-step transition probabilities</a></li>
<li class="chapter" data-level="3.2" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#distribution-of-x_n"><i class="fa fa-check"></i><b>3.2</b> Distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="3.3" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#joint-distribution"><i class="fa fa-check"></i><b>3.3</b> Joint Distribution</a></li>
<li class="chapter" data-level="3.4" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#random-walk-with-absorbing-and-reflecting-barriers"><i class="fa fa-check"></i><b>3.4</b> Random walk with absorbing and reflecting barrier(s)</a></li>
<li class="chapter" data-level="3.5" data-path="the-chapman-kolmogorov-equations.html"><a href="the-chapman-kolmogorov-equations.html#an-example-of-nonhomogeneous-markov-chain"><i class="fa fa-check"></i><b>3.5</b> An example of nonhomogeneous Markov chain</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>4</b> Simulation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simulation.html"><a href="simulation.html#monte-carlo-methods"><i class="fa fa-check"></i><b>4.1</b> Monte Carlo Methods</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="classification-of-states.html"><a href="classification-of-states.html"><i class="fa fa-check"></i><b>5</b> Classification of states</a></li>
<li class="chapter" data-level="6" data-path="absorption-probabilities-and-expected-time-to-absorption.html"><a href="absorption-probabilities-and-expected-time-to-absorption.html"><i class="fa fa-check"></i><b>6</b> Absorption probabilities and expected time to absorption</a>
<ul>
<li class="chapter" data-level="6.1" data-path="absorption-probabilities-and-expected-time-to-absorption.html"><a href="absorption-probabilities-and-expected-time-to-absorption.html#first-step-analysis"><i class="fa fa-check"></i><b>6.1</b> First step analysis</a></li>
<li class="chapter" data-level="6.2" data-path="absorption-probabilities-and-expected-time-to-absorption.html"><a href="absorption-probabilities-and-expected-time-to-absorption.html#the-expected-time-to-absorption"><i class="fa fa-check"></i><b>6.2</b> The expected time to absorption</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html"><i class="fa fa-check"></i><b>7</b> The long-term distribution of a Markov chain</a>
<ul>
<li class="chapter" data-level="7.1" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#stationary-and-limiting-distributions-for-a-single-closed-class"><i class="fa fa-check"></i><b>7.1</b> Stationary and limiting distributions for a single closed class</a>
<ul>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#stationary-distributions"><i class="fa fa-check"></i>Stationary distributions</a></li>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#proportion-of-time-in-each-state"><i class="fa fa-check"></i>Proportion of Time in Each State</a></li>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#the-method-of-finding-the-stationary-distribution"><i class="fa fa-check"></i>The method of finding the stationary distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#sufficient-conditions-for-the-long-run-behaviour-of-a-markov-chain"><i class="fa fa-check"></i><b>7.2</b> Sufficient conditions for the long-run behaviour of a Markov chain</a></li>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#limiting-distributions"><i class="fa fa-check"></i>Limiting distributions</a></li>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#main-result"><i class="fa fa-check"></i>Main result</a>
<ul>
<li class="chapter" data-level="" data-path="the-long-term-distribution-of-a-markov-chain.html"><a href="the-long-term-distribution-of-a-markov-chain.html#applications-of-markov-chains-to-ncd-systems"><i class="fa fa-check"></i>Applications of Markov chains to NCD systems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>8</b> Introduction to Stochastic Processes</a></li>
<li class="chapter" data-level="9" data-path="examples-of-real-world-processes.html"><a href="examples-of-real-world-processes.html"><i class="fa fa-check"></i><b>9</b> Examples of real world processes</a></li>
<li class="chapter" data-level="10" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html"><i class="fa fa-check"></i><b>10</b> Review of probability theory</a>
<ul>
<li class="chapter" data-level="10.1" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#random-variables"><i class="fa fa-check"></i><b>10.1</b> Random variables</a></li>
<li class="chapter" data-level="10.2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#probability-distribution"><i class="fa fa-check"></i><b>10.2</b> Probability distribution</a></li>
<li class="chapter" data-level="" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#examples-of-discrete-and-continuous-random-variables"><i class="fa fa-check"></i>Examples of discrete and continuous random variables</a></li>
<li class="chapter" data-level="10.3" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>10.3</b> Conditional probability</a></li>
<li class="chapter" data-level="" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#law-of-total-probability"><i class="fa fa-check"></i>Law of total probability</a></li>
<li class="chapter" data-level="10.4" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-distribution-and-conditional-expectation"><i class="fa fa-check"></i><b>10.4</b> Conditional distribution and conditional expectation</a></li>
<li class="chapter" data-level="10.5" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>10.5</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#central-limit-theorem-1"><i class="fa fa-check"></i>Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>11</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="11.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#classification-of-stochastic-processes"><i class="fa fa-check"></i><b>11.1</b> Classification of stochastic processes</a></li>
<li class="chapter" data-level="11.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html#random-walk-an-introductory-example"><i class="fa fa-check"></i><b>11.2</b> Random walk: an introductory example</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SCMA469 Actuarial Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="discrete-time-markov-chains" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Discrete-time Markov chains</h1>
<p>Recall the simple random walk model of the price of the stock. Suppose
the stock price for the first four days are
<span class="math display">\[(X_0, X_1, X_2, X_3) = (100, 99, 98, 99).\]</span> Based on this past
information, what can we say about the price at day 4, <span class="math inline">\(X_4\)</span>? Although,
we completely know the whole past price history, the only information
relevant for predicting their future price is the price on the previous
day, i.e. <span class="math inline">\(X_3\)</span>. This means that
<span class="math display">\[\Pr(X_{4} = j | X_0 = 100, X_{1} = 99,  X_2 = 98 ,  X_3 = 99) = \Pr(X_{4} = j | X_3 = 99).\]</span>
Given the current price <span class="math inline">\(X_3\)</span>, the price <span class="math inline">\(X_4\)</span> at day 4 is independent
of the history prices <span class="math inline">\(X_0, X_1, X_2\)</span>. The sequence of stock prices
<span class="math inline">\(X_0, X_1, \ldots, X_n\)</span> is an example of a <strong>Markov chain</strong>.</p>
<p>A Markov process is a special type of stochastic processes with the
property that the future evolution of the process depends only on its
current state and not on its past history. That is given the value of
<span class="math inline">\(X_t\)</span>, the values of <span class="math inline">\(X_s\)</span> for <span class="math inline">\(s &gt; t\)</span> do not depend on the values of
<span class="math inline">\(X_u\)</span> for <span class="math inline">\(u &lt; t\)</span>. This property is called the <strong>Markov property</strong>.</p>
<p>A <strong>discrete-time Markov chain</strong> is a discrete-time stochastic process
that satisfies the Markov property:
<span class="math display">\[\Pr(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \ldots, X_0 = i_{0}) = \Pr(X_{n+1} = j | X_n = i),\]</span>
for all time points <span class="math inline">\(n\)</span> and all states <span class="math inline">\(i_0, i_1, \ldots, i_{n-1},i,j\)</span>.
It is convenient to assume that the state space of the Markov chain is a
subset of non-negative integers, i.e. <span class="math inline">\(S \subseteq \{0, 1, \ldots \}\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-1" class="example"><strong>Example 2.1  </strong></span><strong>Example 1</strong>. <em>A process with independent increments has the Markov
property.</em></p>
</div>
<p>Recall the following definitions. An increment of a process is the
amount by which its value changes over a period of time, for e.g.
<span class="math inline">\(X_{t +u} - X_t\)</span> where <span class="math inline">\(u &gt; 0\)</span>.</p>
<p>A process <span class="math inline">\(X_t\)</span> is said to have independent increments if for all <span class="math inline">\(t\)</span>
and every <span class="math inline">\(u &gt; 0\)</span>, the increment <span class="math inline">\(X_{t +u} - X_t\)</span> is independent of all
the past of the process <span class="math inline">\(\{X_s : 0 \le s \le t \}\)</span>).</p>
<p>In order to show that a process with independent increments has the
Markov property, we proceed as follows: <span class="math display">\[\begin{aligned}
\Pr(X_t \in A | X_{s_1} = x_1, X_{s_2} = x_2, \ldots, X_{s} = x) 
&amp;= \Pr(X_t - X_s + x \in A | X_{s_1} = x_1, X_{s_2} = x_2, \ldots, X_{s} = x) \\
&amp;= \Pr(X_t - X_s + x \in A |  X_{s} = x)  \text{(by independence of the past)} \\
&amp;= \Pr(X_t  \in A |  X_{s} = x).\end{aligned}\]</span></p>
<p>The random walk process has the Markov property.</p>
<div id="one-step-transition-probabilities" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> One-step transition probabilities</h2>
<p>The conditional probability that <span class="math inline">\(X_{n+1}\)</span> is in state <span class="math inline">\(j\)</span> given that
<span class="math inline">\(X_n\)</span> is in state <span class="math inline">\(i\)</span> is called <strong>one-step transition probability</strong> and
is denoted by <span class="math display">\[\Pr(X_{n+1} = j | X_n = i) = p_{ij}^{n,n+1}.\]</span> Note that
the transition probabilities depend not only on the current and future
states, <strong>but also on the time of transition <span class="math inline">\(n\)</span></strong>.</p>
<p>If the transition probabilities <span class="math inline">\(p_{ij}^{n,n+1}\)</span> in a Markov chain do
not depend on time <span class="math inline">\(n\)</span>, the Markov chain is said to be
<strong>time-homogeneous or stationary or simply homogeneous</strong>. Then
<span class="math display">\[p_{ij}^{n,n+1} = \Pr(X_{n+1} = j | X_n = i)  = \Pr(X_{1} = j | X_0 = i)  = p_{ij}.\]</span>
Otherwise, it is said to be <strong>nonstationary</strong> or <strong>nonhomogeneous</strong>.</p>
<p>Unless stated otherwise, it shall be assumed that the Markov chain is
stationary. The matrix <span class="math inline">\(P\)</span> whose elements are <span class="math inline">\(p_{ij}\)</span> is called the
<strong>transition probability matrix</strong> of the process. <span class="math display">\[P = \begin{bmatrix}
    p_{11} &amp; p_{12} &amp; p_{13} &amp; \dots   \\
    p_{21} &amp; p_{22} &amp; p_{23} &amp; \dots   \\
    p_{31} &amp; p_{32} &amp; p_{33} &amp; \dots   \\
    \vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span> Note that the elements of the matrix <span class="math inline">\(P\)</span> satisfies the
following properties:
<span class="math display">\[\ 0 \le p_{ij} \le 1, \quad \text{ and } \quad \sum_{j \in S}p_{ij} = 1,\]</span>
for all <span class="math inline">\(i,j \in S.\)</span> A matrix that satisfies these properties is called
a <strong>stochastic matrix</strong>.</p>
<div class="example">
<p><span id="exm:NCD" class="example"><strong>Example 2.2  </strong></span><strong>Example 2</strong>. <em>No claims discount (NCD) policy: Let <span class="math inline">\(X_n\)</span> be the
discount status of a policyholder at time <span class="math inline">\(n\)</span>. There are three levels of
discount, i.e. <span class="math inline">\(S = \{0,1,2\}\)</span> corresponding to three discount levels of
0, 20% and 40%. The following rules are assumed:</em></p>
<ul>
<li><p><em>For a claim-free year, the policyholder moves up a level or remains
in state 2 (the maximum discount state).</em></p></li>
<li><p><em>If there is at least one claim, the policyholder moves down one
level or remains in state 0.</em></p></li>
</ul>
<p><em>Suppose also that the probability of a claim-free year is <span class="math inline">\(p\)</span> and is
independent of <span class="math inline">\(n\)</span>. The transition probability matrix is given by
<span class="math display">\[P = \begin{bmatrix}
    1- p &amp; p &amp; 0    \\
    1-p &amp; 0 &amp; p   \\
    0 &amp; 1-p &amp; p    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span> The transition diagram is illustrated in the following
figure.</em></p>
<p><em>The following questions are of interest.</em></p>
<ol style="list-style-type: decimal">
<li><p><em>What is the probability
<span class="math display">\[\Pr(X_0 = i_0, X_1 = i_1, X_2 = i_2, \ldots, X_n = i_n)?\]</span></em></p></li>
<li><p><em>What is the probability
<span class="math display">\[\Pr(X_{n+1} = i_{n+1}, X_{n+2} = i_{n+2},  \ldots, X_{n+m} = i_{n+m}| X_n = i_n, X_{n-1} = i_{n-1}, \ldots, X_0 = i_{0})?\]</span></em></p></li>
<li><p><em>What is the probability of transferring from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span>
in <span class="math inline">\(n\)</span> steps <span class="math display">\[\Pr(X_{m+n} = j | X_m = i )?\]</span></em></p></li>
<li><p><em>What is the long-term behavior of the Makov chain, i.e.
<span class="math inline">\(\lim_{n \rightarrow \infty} \Pr(X_n = j), j = 0,1,2\)</span> given that
<span class="math inline">\(\Pr(X_0 = 0)\)</span>.</em></p></li>
</ol>
</div>
<p>Later we will apply matrix algebra to compute these types of
probabilities and long-term probabilities.</p>
<div class="example">
<p><span id="exm:healthInsurance" class="example"><strong>Example 2.3  </strong></span><strong>Example 3</strong>. <em>In a health insurance system, at the end of each day an
insurance company classifies policyholders as Healthy, Sick or Dead,
i.e. <span class="math inline">\(S = \{H, S, D\}\)</span>. The following transition matrix <span class="math inline">\(P\)</span> for a
healthy-sick-dead model is given by <span class="math display">\[P = \begin{bmatrix}
    p_{11} &amp; p_{12} &amp; p_{13}    \\
    p_{21} &amp; p_{22} &amp; p_{23}   \\
   0 &amp; 0 &amp; 1   \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span></em></p>
</div>
<p>The transition diagram is shown below.</p>
<p>It turns out that the probabilistic description of the Markov chain is
completely determined by its transition probability matrix and its
initial probability distribution <span class="math inline">\(X_0\)</span> at time 0.</p>
<div class="example">
<p><span id="exm:unlabeled-div-2" class="example"><strong>Example 2.4  </strong></span><strong>Example 4</strong>. <em>By using the definition of conditional probabilities,
show that
<span class="math display">\[\Pr(X_0 = i_0, X_1 = i_1, X_2 = i_2, \ldots, X_n = i_n) = \mu_{i_0}\, p_{i_0i_1} \cdots \, p_{i_{n-2} i_{n-1}}\, p_{i_{n-1} i_n},\]</span>
where <span class="math inline">\(\boldsymbol{\mu} = \boldsymbol{\mu}^{(0)}\)</span> is the distribution of
initial random variable <span class="math inline">\(X_0\)</span>, i.e. <span class="math inline">\(\mu_i = \Pr(X_0 = i)\)</span> (the
probability mass function of <span class="math inline">\(X_0\)</span>.)</em></p>
</div>
<p><span class="math display">\[\begin{aligned}
 &amp;\Pr(X_0 = i_0, X_1 = i_1, \ldots, X_n = i_n) \\
  &amp;= \Pr(X_0 = i_0, X_1 = i_1, \ldots, X_{n-1} = i_{n-1}) \cdot \Pr(X_n = i_n | X_0 = i_0, X_1 = i_1, \ldots, X_{n-1} = i_{n-1})\\
  &amp;= \Pr(X_0 = i_0, X_1 = i_1, \ldots, X_{n-1} = i_{n-1}) \cdot \Pr(X_n = i_n |  X_{n-1} = i_{n-1})\\
  &amp;=  \Pr(X_0 = i_0, X_1 = i_1, \ldots, X_{n-1} = i_{n-1}) \cdot p_{i_{n-1} i_n} \\
  &amp;\quad \vdots \\
  &amp;= \mu_{i_0}\, p_{i_0i_1} \cdots \, p_{i_{n-2} i_{n-1}}\, p_{i_{n-1} i_n}.
  \end{aligned}\]</span></p>
<div class="example">
<p><span id="exm:MKProperty1" class="example"><strong>Example 2.5  </strong></span><strong>Example 5</strong>. <em>Show that <span class="math display">\[\begin{aligned}
\Pr(X_{n+1} &amp;= i_{n+1}, X_{n+2} = i_{n+2},  \ldots, X_{n+m} = i_{n+m}| X_n = i_n, X_{n-1} = i_{n-1}, \ldots, X_0 = i_{0}) \\
            &amp;= \Pr(X_{n+1} = i_{n+1}, X_{n+2} = i_{n+2},  \ldots, X_{n+m} = i_{n+m}| X_n = i_n) \\
            &amp;=  p_{i_{n} i_{n+1}} \cdots \, p_{i_{n+m-2} i_{n+m-1}}\, p_{i_{n+m-1} i_{n+m}}.\end{aligned}\]</span></em></p>
</div>
<p><span class="math display">\[\begin{aligned}
&amp;\Pr(X_{n+1} = i_{n+1}, X_{n+2} = i_{n+2},  \ldots, X_{n+m} = i_{n+m}| X_n = i_n, X_{n-1} = i_{n-1}, \ldots, X_0 = i_{0}) \\
&amp;= \Pr(X_{n+1} = i_{n+1}, X_{n+2} = i_{n+2},  \ldots, X_{n+m} = i_{n+m}| X_n = i_n) \\ 
&amp;= \Pr( X_{n+2} = i_{n+2},  \ldots, X_{n+m} = i_{n+m}| X_{n+1} = i_{n+1}, X_n = i_n)  \cdot \Pr(X_{n+1} = i_{n+1} |  X_n = i_n ) \\ 
&amp;= \Pr( X_{n+2} = i_{n+2},  \ldots, X_{n+m} = i_{n+m}| X_{n+1} = i_{n+1})  \cdot p_{i_n i_{n+1}} \\ 
&amp;\quad \vdots \\
&amp;= \Pr( X_{n+m} = i_{n+m}| X_{n+m-1} = i_{n+m-1}) \cdots \Pr( X_{n+2} = i_{n+2}| X_{n + 1} = i_{n + 1}) \cdot p_{i_n i_{n+1}} \\ 
&amp;= p_{i_{n+m-1} i_{n+m}} \cdot p_{i_{n+m-2} i_{n+m-1}}   \cdots p_{i_n i_{n+1}} .\end{aligned}\]</span></p>
<p>More general probabilities of the possible realisations of the process
can be calculated by summing the probabilities of elementary elements of
these forms.</p>
<div class="example">
<p><span id="exm:unlabeled-div-3" class="example"><strong>Example 2.6  </strong></span><strong>Example 6</strong>. <em>For the NCD system defined on the state space
<span class="math inline">\(S = \{0,1,2\}\)</span> as given in
Example <a href="#NCD" reference-type="ref" reference="NCD">Example 2</a>, suppose
that the probability of a claim-free year <span class="math inline">\(p = 3/4\)</span>, and the
distribution of the initial discount rate
<span class="math inline">\(\boldsymbol{\mu} = (0.5,0.3,0.2)\)</span>. Find the following:</em></p>
</div>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\Pr(X_0 = 2, X_1 = 1, X_2 = 0).\)</span></p></li>
<li><p><span class="math inline">\(\Pr( X_1 = 1, X_2 = 0 | X_0 = 2).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_{10} = 2, X_{11} = 1, X_{12} = 0).\)</span></p></li>
<li><p><span class="math inline">\(\Pr( X_{11} = 1, X_{12} = 0 | X_{10} = 2).\)</span></p></li>
</ol>
<p>The corresponding transition matrix is <span class="math display">\[P = \begin{bmatrix}
    1/4 &amp; 3/4 &amp; 0    \\
    1/4 &amp; 0 &amp; 3/4   \\
    0 &amp; 1/4 &amp; 3/4    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Denote <span class="math inline">\(\boldsymbol{\mu} = (\mu_1, \mu_2, \mu_3) = (0.5,0.3,0.2)\)</span>
<span class="math display">\[\begin{aligned}
    \Pr(X_0 = 2, X_1 = 1, X_2 = 0) &amp;=  \Pr(X_0 = 2, X_1 = 1) \cdot \Pr(X_2 = 0 | X_0 = 2, X_1 = 1) \\
    &amp;= \Pr(X_0 = 2, X_1 = 1) \cdot \Pr(X_2 = 0 | X_1 = 1) \quad \text{(by Markov property)}\\
    &amp;= \Pr(X_0 = 2) \cdot \Pr(X_1 = 1 | X_0 = 2 ) \cdot  \Pr(X_2 = 0 | X_1 = 1) \quad  \text{(again by Markov property)}\\
    &amp;= \mu_3 p_{32} p_{21} = 0.2\cdot(1/4)\cdot(1/4) = 1/80.\end{aligned}\]</span></p>
<p>Alternatively, it follows from
Example <a href="#MKProperty1" reference-type="ref" reference="MKProperty1">Example 5</a> that,
<span class="math display">\[\Pr(X_0 = 2, X_1 = 1, X_2 = 0) = \mu_3 p_{32} p_{21} = 0.2\cdot(1/4)\cdot(1/4) = 1/80.\]</span></p></li>
<li><p><span class="math display">\[\begin{aligned}
\Pr( X_1 = 1, X_2 = 0 | X_0 = 2)
&amp;=   \Pr( X_1 = 1 | X_0 = 2)  \cdot \Pr( X_2 = 0 | X_1 = 1, X_0 = 2) \\ 
&amp;=   \Pr( X_1 = 1 | X_0 = 2) \cdot \Pr( X_2 = 0 | X_1 = 1) \quad \text{(by Markov property)}\\ 
&amp;= p_{32} p_{21} = (1/4)\cdot(1/4) = 1/16.\end{aligned}\]</span></p></li>
<li><p>Following conditional probability, the Markov property, and
time-homogeneity (to be discussed later) results in
<span class="math display">\[\begin{aligned}
    \Pr(X_{10} = 2, X_{11} = 1, X_{12} = 0) &amp;=  \Pr(X_{10} = 2)  \cdot \Pr(X_{11} = 1, X_{12} = 0 | X_{10} = 2) \\
     &amp;=  \Pr(X_{10} = 2)  \cdot \Pr(X_{11} = 1 | X_{10} = 2) \cdot \Pr( X_{12} = 0 | X_{10} = 2, X_{11} = 1)  \\
     &amp;=  \Pr(X_{10} = 2)  \cdot \Pr(X_{11} = 1 | X_{10} = 2) \cdot \Pr( X_{12} = 0 |  X_{11} = 1)  \\
     &amp;= \Pr(X_{10} = 2)  \cdot \Pr(X_{1} = 1 | X_{0} = 2) \cdot \Pr( X_{1} = 0 |  X_{0} = 1) \\
      &amp;= \Pr(X_{10} = 2)  \cdot p_{32} p_{21} = 0.6922\cdot (1/4)\cdot(1/4) = 0.0433.  \\\end{aligned}\]</span>
Later we will show that
<span class="math inline">\(\Pr(X_{10} = 2) = (\boldsymbol{\mu} P^{10})_3 = 0.6922\)</span> (here
<span class="math inline">\((\boldsymbol{\mu} P^{10})_i\)</span> denotes the <span class="math inline">\(i\)</span>-th entry of the vector
<span class="math inline">\(\boldsymbol{\mu} P^{10}\)</span>.</p></li>
<li><p>From conditional probability, the Markov property, and
time-homogeneity, it follows that <span class="math display">\[\begin{aligned}
\Pr( X_{11} = 1, X_{12} = 0 | X_{10} = 2)
&amp;=   \Pr( X_{11} = 1 | X_{10} = 2)  \cdot \Pr( X_{12} = 0 | X_{11} = 1, X_{10} = 2) \\ 
&amp;=   \Pr( X_{11} = 1 | X_{10} = 2) \cdot \Pr( X_{12} = 0 | X_{11} = 1) \quad \text{(by Markov property)}\\ 
&amp;=   \Pr( X_{1} = 1 | X_{0} = 2) \cdot \Pr( X_{1} = 0 | X_{0} = 1) \quad \text{(by time-homogeneity)}\\ 
&amp;= p_{32} p_{21} = (1/4)\cdot(1/4) = 1/16.\end{aligned}\]</span></p></li>
</ol>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-chapman-kolmogorov-equations.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/pairote-sat/SCMA469/edit/master/02-tears.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/pairote-sat/SCMA469/blob/master/02-tears.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
