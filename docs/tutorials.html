<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Tutorials | SCMA469 Actuarial Statistics</title>
  <meta name="description" content="Chapter 5 Tutorials | SCMA469 Actuarial Statistics" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Tutorials | SCMA469 Actuarial Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Tutorials | SCMA469 Actuarial Statistics" />
  
  
  

<meta name="author" content="Pairote Satiracoo" />


<meta name="date" content="2021-09-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="discrete-time-markov-chains.html"/>
<link rel="next" href="applications.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SCMA469 Actuarial Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Stochastic Processes</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#examples-of-real-world-processes"><i class="fa fa-check"></i><b>1.1</b> Examples of real world processes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html"><i class="fa fa-check"></i><b>2</b> Review of probability theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#random-variables"><i class="fa fa-check"></i><b>2.1</b> Random variables</a></li>
<li class="chapter" data-level="2.2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#probability-distribution"><i class="fa fa-check"></i><b>2.2</b> Probability distribution</a></li>
<li class="chapter" data-level="2.3" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>2.3</b> Conditional probability</a></li>
<li class="chapter" data-level="2.4" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#law-of-total-probability"><i class="fa fa-check"></i><b>2.4</b> Law of total probability</a></li>
<li class="chapter" data-level="2.5" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-distribution-and-conditional-expectation"><i class="fa fa-check"></i><b>2.5</b> Conditional distribution and conditional expectation</a></li>
<li class="chapter" data-level="2.6" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.6</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>3</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#classification-of-stochastic-processes"><i class="fa fa-check"></i><b>3.1</b> Classification of stochastic processes</a></li>
<li class="chapter" data-level="3.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html#random-walk-an-introductory-example"><i class="fa fa-check"></i><b>3.2</b> Random walk: an introductory example</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html"><i class="fa fa-check"></i><b>4</b> Discrete-time Markov chains</a>
<ul>
<li class="chapter" data-level="4.1" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#one-step-transition-probabilities"><i class="fa fa-check"></i><b>4.1</b> One-step transition probabilities</a></li>
<li class="chapter" data-level="4.2" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-chapman-kolmogorov-equation-and-n-step-transition-probabilities"><i class="fa fa-check"></i><b>4.2</b> The Chapman-Kolmogorov equation and <span class="math inline">\(n\)</span>-step transition probabilities</a></li>
<li class="chapter" data-level="4.3" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#distribution-of-x_n"><i class="fa fa-check"></i><b>4.3</b> Distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="4.4" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#joint-distribution"><i class="fa fa-check"></i><b>4.4</b> Joint Distribution</a></li>
<li class="chapter" data-level="4.5" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#random-walk-with-absorbing-and-reflecting-barriers"><i class="fa fa-check"></i><b>4.5</b> Random walk with absorbing and reflecting barrier(s)</a></li>
<li class="chapter" data-level="4.6" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#an-example-of-nonhomogeneous-markov-chain"><i class="fa fa-check"></i><b>4.6</b> An example of nonhomogeneous Markov chain</a></li>
<li class="chapter" data-level="4.7" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#simulation"><i class="fa fa-check"></i><b>4.7</b> Simulation</a></li>
<li class="chapter" data-level="4.8" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#monte-carlo-methods"><i class="fa fa-check"></i><b>4.8</b> Monte Carlo Methods</a></li>
<li class="chapter" data-level="4.9" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#classification-of-states"><i class="fa fa-check"></i><b>4.9</b> Classification of states</a></li>
<li class="chapter" data-level="4.10" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#absorption-probabilities-and-expected-time-to-absorption"><i class="fa fa-check"></i><b>4.10</b> Absorption probabilities and expected time to absorption</a></li>
<li class="chapter" data-level="4.11" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#first-step-analysis"><i class="fa fa-check"></i><b>4.11</b> First step analysis</a></li>
<li class="chapter" data-level="4.12" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-expected-time-to-absorption"><i class="fa fa-check"></i><b>4.12</b> The expected time to absorption</a></li>
<li class="chapter" data-level="4.13" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-long-term-distribution-of-a-markov-chain"><i class="fa fa-check"></i><b>4.13</b> The long-term distribution of a Markov chain</a></li>
<li class="chapter" data-level="4.14" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#stationary-and-limiting-distributions-for-a-single-closed-class"><i class="fa fa-check"></i><b>4.14</b> Stationary and limiting distributions for a single closed class</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#stationary-distributions"><i class="fa fa-check"></i>Stationary distributions</a></li>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#proportion-of-time-in-each-state"><i class="fa fa-check"></i>Proportion of Time in Each State</a></li>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-method-of-finding-the-stationary-distribution"><i class="fa fa-check"></i>The method of finding the stationary distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#sufficient-conditions-for-the-long-run-behaviour-of-a-markov-chain"><i class="fa fa-check"></i><b>4.15</b> Sufficient conditions for the long-run behaviour of a Markov chain</a></li>
<li class="chapter" data-level="4.16" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#limiting-distributions"><i class="fa fa-check"></i><b>4.16</b> Limiting distributions</a></li>
<li class="chapter" data-level="4.17" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#main-result"><i class="fa fa-check"></i><b>4.17</b> Main result</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#applications-of-markov-chains-to-ncd-systems"><i class="fa fa-check"></i>Applications of Markov chains to NCD systems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="tutorials.html"><a href="tutorials.html"><i class="fa fa-check"></i><b>5</b> Tutorials</a>
<ul>
<li class="chapter" data-level="5.1" data-path="tutorials.html"><a href="tutorials.html#tutorial-1"><i class="fa fa-check"></i><b>5.1</b> Tutorial 1</a></li>
<li class="chapter" data-level="5.2" data-path="tutorials.html"><a href="tutorials.html#tutorial-2"><i class="fa fa-check"></i><b>5.2</b> Tutorial 2</a></li>
<li class="chapter" data-level="5.3" data-path="tutorials.html"><a href="tutorials.html#tutorial-3"><i class="fa fa-check"></i><b>5.3</b> Tutorial 3</a></li>
<li class="chapter" data-level="5.4" data-path="tutorials.html"><a href="tutorials.html#tutorial-2-1"><i class="fa fa-check"></i><b>5.4</b> Tutorial 2</a></li>
<li class="chapter" data-level="5.5" data-path="tutorials.html"><a href="tutorials.html#tutorial-3-1"><i class="fa fa-check"></i><b>5.5</b> Tutorial 3</a></li>
<li class="chapter" data-level="5.6" data-path="tutorials.html"><a href="tutorials.html#tutorial-4"><i class="fa fa-check"></i><b>5.6</b> Tutorial 4</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>6</b> Applications</a>
<ul>
<li class="chapter" data-level="6.1" data-path="applications.html"><a href="applications.html#datacamp-light"><i class="fa fa-check"></i><b>6.1</b> DataCamp Light</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>7</b> Final words</a>
<ul>
<li class="chapter" data-level="7.1" data-path="final-words.html"><a href="final-words.html#datacamp-light-1"><i class="fa fa-check"></i><b>7.1</b> DataCamp Light</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SCMA469 Actuarial Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tutorials" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Tutorials</h1>
<div id="tutorial-1" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Tutorial 1</h2>
<ol style="list-style-type: decimal">
<li><p>Consider a random walk, <span class="math inline">\(S_n\)</span>, with <span class="math inline">\(S_0 = 0\)</span> and where each step is
normally distributed with mean 0 and variance 10.</p>
<ol style="list-style-type: decimal">
<li><p>What is the distribution of <span class="math inline">\(S_{10}\)</span>?</p></li>
<li><p>Calculate <span class="math inline">\(\Pr(S_{10} &lt; -10)\)</span>.</p></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>We have <span class="math inline">\(S_{10}\)</span> is a sum of
<span class="math inline">\(S_0\)</span> and the i.i.d random variables <span class="math inline">\(Z_i\)</span>, each distributed
normal distribution, <span class="math inline">\(Z_i \sim N(0,10)\)</span>. Moreover,
<span class="math display">\[\mathrm{E}[S_{10}] = \mathrm{E}[S_0 + \sum_{i=1}^{10} Z_i] = S_0 + \sum_{i=1}^{10} \mathrm{E}[Z_i] = 0\]</span>
and
<span class="math display">\[\mathrm{Var}[S_{10}] = \mathrm{Var}[S_0 + \sum_{i=1}^{10} Z_i] = \sum_{i=1}^{10} \mathrm{Var}[Z_i] = 100\]</span>
Therefore, the distribution of <span class="math inline">\(S_{10}\)</span> is normally distributed,
<span class="math inline">\(S_{10} \sim N(0,100)\)</span>.</p></li>
<li><p>From the previous result,
<span class="math display">\[\Pr(S_{10} &lt; -10) = \Pr(Z &lt; -1) = 0.1587.\]</span></p></li>
</ol></li>
<li><p>Suppose that the value of a commodity as a random walk, where each
day the change in price has mean $0.05 and variance $0.1. Use the
central limit theorem to estimate the probability that its value is
more than $6 after 100 days if the initial value is $0.50.</p>
<p><strong>Solution:</strong> We have <span class="math inline">\(S_{100}\)</span> is a sum of <span class="math inline">\(S_0\)</span> and the i.i.d
random variables <span class="math inline">\(Z_i\)</span>, each distributed normal distribution,
<span class="math inline">\(Z_i \sim N(0.05,0.1)\)</span>. Moreover,
<span class="math display">\[\mathrm{E}[S_{100}] = \mathrm{E}[S_0 + \sum_{i=1}^{100} Z_i] = S_0 + \sum_{i=1}^{100} \mathrm{E}[Z_i] = 5.5\]</span>
and
<span class="math display">\[\mathrm{Var}[S_{100}] = \mathrm{Var}[S_0 + \sum_{i=1}^{100} Z_i] = \sum_{i=1}^{100} \mathrm{Var}[Z_i] = 10\]</span>
Therefore, the distribution of <span class="math inline">\(S_{100}\)</span> is normally distributed,
<span class="math inline">\(S_{100} \sim N(5.5,10)\)</span>.</p>
<p>The Central Limit Theorem implies that <span class="math inline">\(S_{100}\)</span> is approximately
normally distributed, <span class="math inline">\(S_{100} \sim N(5.5,10)\)</span>.</p>
<p><span class="math display">\[\Pr(S_{100} &gt; 6) = \Pr(Z &gt; 0.1581) = 1 -  \Pr(Z &lt; 0.1581)  = 1- 0.5628 = 0.4372.\]</span></p></li>
<li><p>For the random walk process as described in the lecture note,</p>
<ol style="list-style-type: decimal">
<li><p>Calculate <span class="math inline">\(\Pr(X_8 = 96 | X_0 = 100),\)</span></p></li>
<li><p>Calculate <span class="math inline">\(\Pr(X_1 = 99, X_8 = 96 | X_0 = 100),\)</span></p></li>
<li><p>Calculate <span class="math inline">\(\Pr(X_1 = 99, X_4 = 98, X_8 = 96 | X_0 = 100),\)</span></p></li>
<li><p>Calculate <span class="math inline">\(\Pr( X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100),\)</span></p></li>
<li><p>Given <span class="math inline">\(X_0 = 100\)</span>, calculate <span class="math inline">\(\mathrm{E}[X_5]\)</span>.</p></li>
<li><p>Write down the joint distribution of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_3\)</span> given
<span class="math inline">\(X_0 = 100\)</span>. (Hint: consider all possible sample paths)</p></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Here the price must increase on any 2 day(s) and decrease on any
6 day(s), not necessarily in that order. There are
<span class="math inline">\({ 8 \choose 2} = 28\)</span> different possibilities and each of these
has probability <span class="math inline">\(p^{2}(1-p)^{6}\)</span>. Therefore, the required
probability is
<span class="math display">\[\Pr(X_8 = 96 | X_0 = 100) =  28  p^{2}(1-p)^{6} .\]</span></p></li>
<li><p>The problem can be divided into two periods:</p>
<ul>
<li><p>The first period of 1 day(s): the price in this period must
increase on any 0 day(s) and decrease on any 1 day(s), not
necessarily in that order. There are <span class="math inline">\({ 1 \choose 0}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{0}(1-p)^{1}\)</span>.</p></li>
<li><p>The next period of 7 day(s): the price in this period must
increase on any 2 day(s) and decrease on any 5 day(s), not
necessarily in that order. There are <span class="math inline">\({ 7 \choose 2}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{2}(1-p)^{5}\)</span>.</p></li>
</ul>
<p>The required probability is
<span class="math display">\[\Pr(X_1 = 99, X_8 = 96 | X_0 = 100)  =  21  p^{2}(1-p)^{6} .\]</span></p></li>
<li><p>Similar to the previous problem, the required probability can be
calculated as follows:</p>
<p>The problem can be divided into three periods:</p>
<ul>
<li><p>The first period of 1 day(s): the price in this period must
increase on any 0 day(s) and decrease on any 1 day(s), not
necessarily in that order. There are <span class="math inline">\({ 1 \choose 0}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{0}(1-p)^{1}\)</span>.</p></li>
<li><p>The next period of 3 day(s): the price in this period must
increase on any 1 day(s) and decrease on any 2 day(s), not
necessarily in that order. There are <span class="math inline">\({ 3 \choose 1}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{1}(1-p)^{2}\)</span>.</p></li>
<li><p>The last period of 4 day(s): the price in this period must
increase on any 1 day(s) and decrease on any 3 day(s), not
necessarily in that order. There are <span class="math inline">\({ 4 \choose 1}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{1}(1-p)^{3}\)</span>.</p></li>
</ul>
<p>The required probability is <span class="math display">\[\Pr(X_1 = 99,
X_4 = 98, X_8 = 96 | X_0 = 100)  =  12  p^{2}(1-p)^{6} .\]</span></p></li>
<li><p>By Markov property, we have <span class="math display">\[\Pr(
X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100), 
= \Pr(
X_4 = 98, X_8 = 96 |X_1 = 99).\]</span> Again, the problem can be
divided into two periods:</p>
<ul>
<li><p>The first period of 3 day(s): the price in this period must
increase on any 1 day(s) and decrease on any 2 day(s), not
necessarily in that order. There are <span class="math inline">\({ 3 \choose 1}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{1}(1-p)^{2}\)</span>.</p></li>
<li><p>The next period of 4 day(s): the price in this period must
increase on any 1 day(s) and decrease on any 3 day(s), not
necessarily in that order. There are <span class="math inline">\({ 4 \choose 1}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{1}(1-p)^{3}\)</span>.</p></li>
</ul>
<p>The required probability is <span class="math display">\[\Pr(
X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100)
= \Pr(
X_4 = 98, X_8 = 96 |X_1 = 99)  =  12  p^{2}(1-p)^{5} .\]</span></p></li>
<li><p>The variable <span class="math inline">\(X_5\)</span> can take the values from
<span class="math inline">\(95, 97, 99, 101, 103, 105\)</span>. In particular, <span class="math display">\[\begin{aligned}
    \Pr(X_5 &amp;= 95) = {5 \choose 0} p^0 (1-p)^5 =  1 
p^0 (1-p)^5    \\
    \Pr(X_5 &amp;= 97) = {5 \choose 1} p^1 (1-p)^4 = 5 
    p^1 (1-p)^4\\
    \Pr(X_5 &amp;= 99) = {5 \choose 2} p^2 (1-p)^3 = 10 
    p^2 (1-p)^3\\
    &amp;\vdots \\
    \Pr(X_5 &amp;= 105) = {5 \choose 5} p^5 (1-p)^0 = 1 
    p^5 (1-p)^0 \end{aligned}\]</span></p>
<p>Therefore, <span class="math inline">\(\mathrm{E}[X_5] =  95 \cdot \left( 1 p^0 (1-p)^5 \right) + 97 \cdot \left(5 p^1 (1-p)^4 \right) + 99 \cdot \left(10 p^2 (1-p)^3 \right) + \cdots + 105 \cdot \left( 1  p^5 (1-p)^0 \right) = 95 + 10*x.\)</span>
Alternatively, <span class="math display">\[\begin{aligned}
  E\left[X_{5}\right] &amp;=E\left[100+\sum_{i=1}^{5} Z_{i}\right] \\
  &amp;= 100+5 \cdot E\left[Z_{i}\right]  \\
  &amp;=100+ 5 (2 p-1)  \\
  &amp;=95 + 10p\end{aligned}\]</span>
where <span class="math inline">\(E\left[Z_{i}\right] = p-q = p - (1 - p) = 2p -1.\)</span></p></li>
</ol></li>
<li><p>For each event,</p>
<ul>
<li><p>Identify a stochastic process <span class="math inline">\(\{ X_t : t \in T\}\)</span> and describe
<span class="math inline">\(X_t\)</span> in context.</p></li>
<li><p>Describe the time domain and state space. State whether the time
domain and state space are discrete or continuous.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Sociologists categorise the population of a country into upper-,
middle- and lower-class groups. One of the government offices
has monitored the movement of successive generations among these
three groups.</p></li>
<li><p>The insurer’s surplus (an excess of income or assets over
expenditure or liabilities in a given period) at any future time
which is defined as the initial surplus plus the premium income
up to time <span class="math inline">\(t\)</span> minus the aggregate claims up to time <span class="math inline">\(t\)</span>.</p></li>
<li><p>In a working day, a coffee shop owner records customer arrival
times.</p></li>
<li><p>The gambler starts with m and bets per game. The probability of
winning is <span class="math inline">\(p\)</span> and the probability of losing is <span class="math inline">\(q\)</span> where
<span class="math inline">\(p + q = 1\)</span>. In addition, the gambler is ruined (or goes broke)
if he reaches state 0, and also stops the game if he reaches
state <span class="math inline">\(N\)</span>.</p></li>
<li><p>In the board game Monopoly, there are 40 squares. A player is
interested to know the successive board position.</p></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(X_{n}\)</span> be the class of <span class="math inline">\(n^{\text {th }}\)</span> generation of a
family. The state space, <span class="math inline">\(S=\{\text {Upper, Middle, Lower} \}\)</span>,
is discrete. The index set, <span class="math inline">\(I=\{0,1,2, \ldots\}\)</span>, is also
discrete.</p></li>
<li><p>Let <span class="math inline">\(S(t)\)</span> be the insurer’s surplus at time <span class="math inline">\(t\)</span>.
<span class="math inline">\(S=\mathbb{R} \text { and } I=[0, \infty)\)</span>.</p></li>
<li><p>Let <span class="math inline">\(X_{n}\)</span> be the amount of money of the gambler after game
<span class="math inline">\(n\)</span>.</p>
<p><span class="math inline">\(S=\{0,1,2 \ldots, N\} \text { and } I=\{0,1,2 ,\ldots \}\)</span>.</p></li>
<li><p>Suppose that the opening hours of the coffee shop are from 7:00
am to 6:00 pm (i.e. 11 hours). Let <span class="math inline">\(X_{n}\)</span> be the arrival time
of customer <span class="math inline">\(n\)</span>. State space (continuous)</p>
<p><span class="math inline">\(S=[0,11 \times 60]=[0,660]\)</span> (in minutes) and
<span class="math inline">\(I=\{1,2, \ldots\}\)</span>.</p></li>
<li><p>Let <span class="math inline">\(x_{n}\)</span> be a player’s board position after <span class="math inline">\(n\)</span> plays.</p>
<p><span class="math inline">\(S=\{1,2,3, \ldots, 40\}\)</span> and <span class="math inline">\(I=\{0,1,2, \ldots \}.\)</span></p></li>
</ol></li>
<li><p>The simple weather pattern can be classified into three types
including rainy (<span class="math inline">\(R\)</span>), cloudy (<span class="math inline">\(C\)</span>) and sunny (<span class="math inline">\(S\)</span>). The weather is
observed daily. The following information is provided.</p>
<ul>
<li><p>On any given rainy day, the probability that it will rain the
next day is 0.7; the probability that it will be cloudy the next
day 0.2.</p></li>
<li><p>On any given cloudy day, the probability that it will rain the
next day is 0.75; the probability that it will be sunny the next
day 0.1.</p></li>
<li><p>On any given sunny day, the probability that it will rain the
next day is 0.2; the probability that it will be sunny the next
day 0.4.</p></li>
</ul>
<p>Explain how this may be modelled by a Markov chain.</p>
<p><strong>Solution:</strong> The three weather conditions describe the three state of
the Markov chain. Let <span class="math inline">\(X_{n}\)</span>be the weather condition on day <span class="math inline">\(n\)</span>.</p>
<ul>
<li><p>State 1 (R) rainy day</p></li>
<li><p>State 2 (C) cloudy day</p></li>
<li><p>State 3 (S) sunny day</p></li>
</ul>
<p>The transition probability matrix <span class="math inline">\(P\)</span> for this Markov chain is</p>
<p><span class="math display">\[P=\left[\begin{array}{lll}
0.7 &amp; 0.2 &amp; 0.1 \\
0.75 &amp; 0.15 &amp; 0.1 \\
0.2 &amp; 0.4 &amp; 0.4
\end{array}\right]\]</span></p>
<p>This stochastic process has the Morkov property because the weather
condition on the next day depends only on the condition today.</p></li>
<li><p>Explain whether an independent and identically distributed sequence
of random variables has a Markov property.</p>
<p><strong>Solution:</strong> Assume that
this Markov chain <span class="math inline">\(X_0, X_1, X_2 \ldots,\)</span> takes values in
<span class="math inline">\(\{1,2, \ldots, k\} \text { with }\)</span></p>
<p><span class="math display">\[P\left(X_{n}=j\right) = p_{j} \quad \text { for } j=1,2, \ldots, k \quad \text { and } n \geq 0 .\]</span>
Note that this equality holds for all <span class="math inline">\(n\)</span> because
<span class="math inline">\(\left\{X_{n} \right\}_{n \ge 0}\)</span> have the same distribution.</p>
<p>By independence,</p>
<p><span class="math display">\[P\left(x_{n}=j \mid x_{n-1}=i\right)=P\left(x_{n}=j\right)=p_{j},\]</span></p>
<p>This proves our claim that the i.i.d. sequence of random variables
has a Markov property. Note also that the transition matrix is
<span class="math display">\[P = 
\begin{bmatrix}
p_1 &amp; p_2 &amp; \cdots &amp; p_k \\
p_1 &amp; p_2 &amp; \cdots &amp; p_k \\
\vdots &amp; \vdots &amp;  &amp; \vdots \\
p_1 &amp; p_2 &amp; \cdots &amp; p_k \\
\end{bmatrix}.\]</span></p></li>
<li><p>The random variables <span class="math inline">\(Z_1, Z_2, \ldots\)</span> are independent and with the
common probability mass function <span class="math display">\[Z_i = \begin{cases}
    1, &amp; \text{ with probability }  0.2 \\
    2, &amp; \text{ with probability }  0.3 \\  
    3, &amp; \text{ with probability }  0.4 \\  
    4, &amp; \text{ with probability }  0.1 \\  
 \end{cases}\]</span> Let <span class="math inline">\(X_0 = 1\)</span> and
<span class="math inline">\(X_n = \max\{Z_1, Z_2, \ldots, Z_n \}\)</span> be the largest <span class="math inline">\(Z\)</span> observed
to date. Explain how this may be modelled by a Markov chain.
<strong>Solution:</strong></p>
<p>Given <span class="math inline">\(X_{0}=1\)</span> and
<span class="math inline">\(X_{n}=\max \left\{Z_{1}, Z_{2}, \ldots, Z_{n}\right\}\)</span> where
<span class="math inline">\(\left\{Z_{i}\right\}\)</span> are i.i.d. random variables with</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(i\)</span></th>
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
<th align="left">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(P(Z_i = i)\)</span></td>
<td align="left">0.2</td>
<td align="left">0.3</td>
<td align="left">0.4</td>
<td align="left">0.1</td>
</tr>
</tbody>
</table>
<p>We note that <span class="math display">\[\begin{aligned}
X_{n+1} &amp;=\operatorname{max}\left\{Z_{1}, Z_{2}, \ldots, Z_{n+1}\right\} \\
&amp;=\operatorname{max}\left\{X_{n}, Z_{n+1}\right\}
\end{aligned}\]</span> Consider the transition probabilities</p>
<p><span class="math display">\[\begin{aligned}
P\left(X_{n+1} = j \mid X_{n}=i \right) &amp;= P\left(\max \left\{X_{n}, Z_{n+1}\right\}=j \mid X_{n}=i\right) \\
&amp;=P\left(\max \left\{i, Z_{n+1}\right\}=j \mid X_{n}=i\right)
\end{aligned}\]</span></p>
<p><strong>Case 1:</strong> If <span class="math inline">\(i=1\)</span>, then <span class="math display">\[\max \left\{1, Z_{n+1}\right\}= 
\begin{cases}
1  &amp; \text{w.p. } 0.2 \\
2 &amp; \text{w.p. } 0.3 \\
3  &amp; \text{w.p. } 0.4 \\
4  &amp; \text{w.p. } 0.1 \\
\end{cases}\]</span></p>
<p><strong>Case 2:</strong> If <span class="math inline">\(i=2\)</span>, then <span class="math display">\[\max \left\{2, Z_{n+1}\right\}= 
\begin{cases}
1  &amp; \text{w.p. } 0 \\
2 &amp; \text{w.p. } 0.5 \quad (\text{i.e. } z_{n+1} = 1 \text{ or } 2  )\\
3  &amp; \text{w.p. } 0.4 \\
4  &amp; \text{w.p. } 0.1 \\
\end{cases}\]</span></p>
<p><strong>Case 3:</strong> If <span class="math inline">\(i=3\)</span>, then <span class="math display">\[\max \left\{3, Z_{n+1}\right\}= 
\begin{cases}
1  &amp; \text{w.p. } 0 \\
2 &amp; \text{w.p. } 0 \\
3  &amp; \text{w.p. } 0.9 \\
4  &amp; \text{w.p. } 0.1 \\
\end{cases}\]</span></p>
<p><strong>Case 4:</strong> If <span class="math inline">\(i=4\)</span>, then <span class="math display">\[\max \left\{4, Z_{n+1}\right\}= 
\begin{cases}
1  &amp; \text{w.p. } 0 \\
2 &amp; \text{w.p. } 0 \\
3  &amp; \text{w.p. } 0 \\
4  &amp; \text{w.p. } 1 \\
\end{cases}\]</span> The transition probability matrix is then</p>
<p><span class="math display">\[P = 
\begin{bmatrix}
0.2 &amp; 0.3 &amp; 0.4 &amp; 0.1 \\
0 &amp; 0.5 &amp; 0.4 &amp; 0.1 \\
0 &amp; 0 &amp; 0.9 &amp; 0.1 \\
0 &amp; 0 &amp; 0 &amp; 0.1 \\
\end{bmatrix}.\]</span> Clearly the sequence <span class="math inline">\(X_0, X_1, X_2,\ldots\)</span> can be
modelled by the Markov chain with the transition probability matrix
<span class="math inline">\(P\)</span>. Moreover, given the most recent value <span class="math inline">\(X_n\)</span>, its future value
<span class="math inline">\(X_{n+1}\)</span> is independent of the past history
<span class="math inline">\(X_0, X_1, \ldots, X_{n-1}\)</span>.</p></li>
</ol>
</div>
<div id="tutorial-2" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Tutorial 2</h2>
<ol style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on states <span class="math inline">\(1, 2, 3\)</span> has the
following transition matrix <span class="math display">\[P = \begin{bmatrix}
    0.5 &amp; 0.3 &amp; 0.2    \\
    0.2 &amp; 0.2 &amp; 0.6  \\
    0.3 &amp; 0.2 &amp; 0.5    \\
\end{bmatrix}.\]</span> The distribution of the initial random variable
<span class="math inline">\(X_0\)</span> is <span class="math inline">\(\boldsymbol{\mu} = (0.3, 0.3, 0.4)\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_0 = 1, X_1 = 2, X_2 = 3).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_1 = 2, X_2 = 3 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 3 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_3 = 3 | X_1 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 3).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\mathrm{E}[X_2]\)</span></p></li>
</ol></li>
</ol>
<p><strong>Solutions:</strong></p>
<ol style="list-style-type: decimal">
<li><p>The transition diagram for the chain is shown in the figure below:
<img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p></li>
<li><p><span class="math inline">\(\Pr(X_0 = 1, X_1 = 2, X_2 = 3) = \mu_1 p_{12} p_{23} = (0.3)(0.3)(0.6) = 0.054.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_1 = 2, X_2 = 3 | X_0 = 1) = p_{12} p_{23} = (0.3)(0.6) = 0.18.\)</span></p></li>
<li><p>From the time homogeneous assumption, it follows that <span class="math display">\[\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1) = \Pr(X_1 = 2, X_2 = 3 | X_0 = 1) = 0.18.\]</span></p></li>
<li><p><span class="math inline">\(\Pr(X_2 = 3 | X_0 = 1) = (P^2)_{13} = 0.38.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_3 = 3 | X_1 = 1) = \Pr(X_2 = 3 | X_0 = 1) = (P^2)_{13} = 0.38.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_2 = 3) = (\boldsymbol{\mu}P^2)_3 = 0.424.\)</span></p></li>
<li><p><span class="math inline">\(\mathrm{E}[X_2] = \sum_{k=1}^3 k \Pr(X_2 = k) = (1, 2, 3) \cdot (0.343, 0.233, 0.424) = 2.081.\)</span></p></li>
</ol>
<p>Note that</p>
<pre><code>## P^2 
##  A  3 - dimensional discrete Markov Chain defined by the following states: 
##  1, 2, 3 
##  The transition matrix  (by rows)  is defined as follows: 
##      1    2    3
## 1 0.37 0.25 0.38
## 2 0.32 0.22 0.46
## 3 0.34 0.23 0.43</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on states 1,2,3 has the
following transition matrix <span class="math display">\[P = \begin{bmatrix}
    0 &amp; 1/2 &amp; 1/2   \\
    1/3  &amp; 1/3  &amp; 1/3   \\
    1/2  &amp; 1/2  &amp; 0    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span>
The process starts in states <span class="math inline">\(X_0 = 1\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_0 = 1, X_1 = 3, X_2 = 2).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_1 = 3, X_2 = 2 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 2 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_3 = 2 | X_1 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 2).\)</span></p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>The transition diagram for the chain is shown in the figure below:
<img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p></li>
<li><p><span class="math inline">\(\Pr(X_0 = 1, X_1 = 3, X_2 = 2) = \mu_1 p_{13} p_{32} = (1)(1/2)(1/2) = 1/4.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_1 = 3, X_2 = 2 | X_0 = 1) = p_{13} p_{32} = (1/2)(1/2) = 1/4.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_2 = 2 | X_0 = 1) = (P^2)_{12} = 5/12.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_3 = 2 | X_1 = 1) = \Pr(X_2 = 2 | X_0 = 1) = (P^2)_{12} = 5/12.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_2 = 2) = (\boldsymbol{\mu}P^2)_2 = 5/12.\)</span></p></li>
</ol>
<p>Note that</p>
<pre><code>## P^2 
##  A  3 - dimensional discrete Markov Chain defined by the following states: 
##  1, 2, 3 
##  The transition matrix  (by rows)  is defined as follows: 
##           1         2         3
## 1 0.4166667 0.4166667 0.1666667
## 2 0.2777778 0.4444444 0.2777778
## 3 0.1666667 0.4166667 0.4166667</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on sates 1,2 has the following
transition matrix <span class="math display">\[P = \begin{bmatrix}
    1-a &amp; a   \\
    b &amp; 1-b   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix},\]</span> where <span class="math inline">\(0 &lt; a,b &lt; 1.\)</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>the distribution of <span class="math inline">\(X_1\)</span>.</p></li>
<li><p>Show that <span class="math display">\[P^n = \frac{1}{a+b} \begin{bmatrix}
    b &amp; a   \\
    b &amp; a   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix} +
\frac{(1-a-b)^n}{a+b} \begin{bmatrix}
    a &amp; -a   \\
    -b &amp; b   \\
\end{bmatrix}.\]</span></p></li>
<li><p>Given that <span class="math inline">\(X_0 = 1\)</span>, what is the probability that in the long
run the system will be in state 1? (Hint: consider
<span class="math inline">\(\lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n\)</span>)</p></li>
<li><p>Given that <span class="math inline">\(X_0 = 1\)</span>, what is the probability that in the long
run the system will be in state 2?</p></li>
<li><p>Given that <span class="math inline">\(X_0 = 2\)</span>, what is the probability that in the long
run the system will be in state 1?</p></li>
<li><p>Given that <span class="math inline">\(X_0 = 2\)</span>, what is the probability that in the long
run the system will be in state 2?</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Leave it to the reader.</p></li>
<li><p>Denote <span class="math inline">\(\boldsymbol{\mu} = (\mu_1, \mu_2)\)</span> the initial probability distribution. Then the distribution of <span class="math inline">\(X_1\)</span> is <span class="math inline">\(\boldsymbol{\mu}^{(1)} = \boldsymbol{\mu} P = (\mu_1(1-a) + \mu_2 b, \mu_1 a + \mu_2(1-b))\)</span></p></li>
<li><p>We apply eigendecomposition of a matrix. For more details, please follow this link from Wikipedia <a href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix">link</a>.</p></li>
</ol>
<p>The eigenvalues of <span class="math inline">\(P\)</span> are <span class="math inline">\(\lambda_1 = 1\)</span> and <span class="math inline">\(\lambda_2 = 1 - a -b\)</span> and the corresponding eigenvectors are
<span class="math display">\[v_1 = \begin{bmatrix}
            1   \\
            1   \\
         \end{bmatrix}, \quad
         v_2 = \begin{bmatrix}
            -a/b   \\
            1   \\
         \end{bmatrix}.
    \]</span><br />
Then the transition matrix can be factorised as
<span class="math display">\[P = \begin{bmatrix}
            1 &amp; -a/b \\
            1 &amp; 1 \\
         \end{bmatrix}
         \begin{bmatrix}
            1 &amp; 0   \\
            0 &amp; 1 - a - b   \\
        \end{bmatrix}
        \begin{bmatrix}
            1 &amp; -a/b \\
            1 &amp; 1 \\
         \end{bmatrix}^{-1}.
    \]</span><br />
Hence <span class="math display">\[\begin{aligned}
      P^n &amp;= \left( \begin{bmatrix}
            1 &amp; -a/b \\
            1 &amp; 1 \\
         \end{bmatrix}
         \begin{bmatrix}
            1 &amp; 0   \\
            0 &amp; (1 - a - b)^n   \\
        \end{bmatrix} \right)
        \begin{bmatrix}
            1 &amp; -a/b \\
            1 &amp; 1 \\
         \end{bmatrix}^{-1}  \\
         &amp;= \begin{bmatrix}
            1 &amp; -\frac{a}{b}(1 - a - b)^n \\
            1 &amp; (1 - a - b)^n \\
         \end{bmatrix} 
         \left(
         \frac{1}{1 + a/b}
         \begin{bmatrix}
            1 &amp; a/b \\
            -1 &amp; 1 \\
         \end{bmatrix}
         \right)  \\
         &amp;= \frac{1}{a+b}
         \begin{bmatrix}
         b + a(1 - a - b)^n &amp; a - a(1 - a - b)^n \\
         b - b(1 - a - b)^n &amp; a + b(1 - a - b)^n
         \end{bmatrix} \\
         &amp;= \frac{1}{a+b}
         \begin{bmatrix}
         b &amp; a \\
         b &amp; a
         \end{bmatrix} +
         \frac{(1 - a - b)^n}{a+b}
         \begin{bmatrix}
         a &amp; -a \\
         -b &amp; b
         \end{bmatrix}
         \end{aligned}.
         \]</span>
Note that <span class="math display">\[\lim_{n \rightarrow \infty} P^n = 
         \frac{1}{a+b}
         \begin{bmatrix}
         b &amp; a \\
         b &amp; a
         \end{bmatrix}, \]</span>
which follows from the facts that <span class="math inline">\(-1 &lt; 1 -a -b &lt; 1\)</span> and <span class="math inline">\((1- a-b)^n \rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>.</p>
<ol start="4" style="list-style-type: decimal">
<li><p>It follows from the above results that in the long run
<span class="math display">\[ \lim_{n \rightarrow \infty} \Pr(X_n = 1| X_0 = 1) = (\lim_{n \rightarrow \infty} P^n)_{11} = \frac{b}{a+b}. \]</span></p></li>
<li><p>In the long run, we have
<span class="math display">\[ \lim_{n \rightarrow \infty} \Pr(X_n = 2| X_0 = 1) = (\lim_{n \rightarrow \infty} P^n)_{12} = \frac{a}{a+b}. \]</span></p></li>
<li><p>In the long run, we have
<span class="math display">\[ \lim_{n \rightarrow \infty} \Pr(X_n = 1| X_0 = 2) = (\lim_{n \rightarrow \infty} P^n)_{21} = \frac{b}{a+b}. \]</span></p></li>
<li><p>In the long run, we have
<span class="math display">\[ \lim_{n \rightarrow \infty} \Pr(X_n = 2| X_0 = 2) = (\lim_{n \rightarrow \infty} P^n)_{22} = \frac{a}{a+b}. \]</span></p></li>
</ol>
<p>Furthermore, for any initial distribution <span class="math inline">\(\boldsymbol{\mu}\)</span>, the limiting distribution with this initial distribution is
<span class="math display">\[ \lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n  = (\frac{b}{a+b}, \frac{a}{a+b}).\]</span>
This gives the long term proportion of the Markov chain, i.e. the probability of finding the process in state 1 is <span class="math inline">\(\frac{b}{a+b}\)</span> and in state 2 is <span class="math inline">\(\frac{a}{a+b}\)</span>, irrespective of the stating state.</p>
<ol start="4" style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(a\)</span> be a constant and <span class="math inline">\(\xi_1, \xi_2, \ldots\)</span> be a sequence of
independent and identically distributed (i.i.d.) random variables.
The stochastic process <span class="math inline">\(\{ X_n\}\)</span> is defined by
<span class="math display">\[X_0 = a, \quad X_n = X_{n-1} + \xi_n, \, n &gt; 1.\]</span> This process is
known as a random walk.</p>
<ol style="list-style-type: decimal">
<li><p>Express the state <span class="math inline">\(X_n\)</span> in terms of <span class="math inline">\(X_0\)</span> and the random
variables <span class="math inline">\(\xi_i, i = 1,2 \ldots\)</span>.</p></li>
<li><p>Find <span class="math inline">\(\mathrm{E}[X_n]\)</span> and <span class="math inline">\(\mathrm{Var}[X_n]\)</span>.</p></li>
<li><p>Does the process have the Markov property? Explain.</p></li>
<li><p>Is the process stationary? Explain.</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>From the definition, it follows that
<span class="math display">\[
\begin{aligned}
X_0 &amp;= a \\
X_1 &amp;= X_0 + \xi_1 = a + \xi_1 \\
X_2 &amp;= X_1 + \xi_2 = a + \xi_1 + \xi_2 \\
    &amp;\vdots \\
X_n &amp;= X_{n-1} + \xi_n = a + \sum_{i=1}^n \xi_i, \quad n \ge 1.
\end{aligned}
\]</span></p></li>
<li><p>Let <span class="math inline">\(\mu = \mathrm{E}[\xi_i]\)</span> and <span class="math inline">\(\sigma^2 = \mathrm{Var}[\xi_i]\)</span> denote the mean and variance of the increments <span class="math inline">\(\xi_i\)</span>. Then
<span class="math display">\[
\begin{aligned}  
\mathrm{E}[X_n] &amp;= \mathrm{E}\left[a + \sum_{i=1}^n \xi_i\right] = a+ \sum_{i=1}^n \mathrm{E}[\xi_i] = a + n \mu, \\
\mathrm{Var}[X_n] &amp;= \mathrm{Var}\left[a + \sum_{i=1}^n \xi_i\right] =  \sum_{i=1}^n \mathrm{Var}[\xi_i] =  n \sigma^2.
\end{aligned}
\]</span>
The last equality follows from the assumption that <span class="math inline">\(\xi_1, \xi_2, \ldots\)</span> are independent.</p></li>
<li><p>The process <span class="math inline">\(\{X_n\}_{n\ge0}\)</span> has independent increments and , hence, has the Markov
property. More details can be found from the lecture note <a href="https://pairote-sat.github.io/SCMA469/discrete-time-markov-chains.html">link</a>.</p></li>
<li><p>The process is <strong>not</strong> stationary because <span class="math inline">\(\mathrm{E}[X_n]\)</span> is not constant and <span class="math inline">\(\mathrm{Var}[X_n]\)</span> also depends on <span class="math inline">\(n\)</span>.</p></li>
<li><p>Consider a homogeneous discrete-time Markov chain that describes the
daily weather pattern. The weather patterns are classified into 3
conditions: R(rainy), C (cloudy) and S(sunny). Based on the daily
observations, the following information are given:</p>
<ul>
<li><p>On any rainy day, the probability that it will rain the next day
is 0.7; the probability that tomorrow will be cloudy is 0.2 and
the probability that tomorrow will be sunny is 0.1.</p></li>
<li><p>On any cloudy day, the probability that it will rain the next
day is 0.5; the probability that tomorrow will be cloudy is 0.35
and the probability that tomorrow will be sunny is 0.15.</p></li>
<li><p>On any sunny day, the probability that it will rain the next day
is 0.1; the probability that tomorrow will be cloudy is 0.4 and
the probability that tomorrow will be sunny is 0.5.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain and write down a
transition matrix.</p></li>
<li><p>Find the probability that tomorrow is cloudy and the day after
is rainy, given that it is sunny today.</p></li>
<li><p>Given that today is rainy, find the probability that it will be
sunny in two days time.</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li>The transition matrix <span class="math inline">\(P\)</span> and the transition diagram are given in the results below :</li>
</ol>
<pre><code>## P 
##  A  3 - dimensional discrete Markov Chain defined by the following states: 
##  R, C, S 
##  The transition matrix  (by rows)  is defined as follows: 
##     R    C    S
## R 0.7 0.20 0.10
## C 0.5 0.35 0.15
## S 0.1 0.40 0.50</code></pre>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<ol start="2" style="list-style-type: decimal">
<li><p>The probability that tomorrow is cloudy and the day after is rainy, given that it is sunny today is
<span class="math display">\[ \Pr(X_1 = C, X_2 = R | X_0 = S) = (0.4)(0.5) = 0.2.\]</span></p></li>
<li><p>Given that today is rainy, the probability that it will be sunny in two days time is
<span class="math display">\[ \Pr(X_2 = S | X_0 = R) = (P^2)_{13} = 0.15.\]</span></p></li>
</ol>
</div>
<div id="tutorial-3" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Tutorial 3</h2>
<ol style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on states 1, 2, 3 with initial
distribution <span class="math inline">\(\boldsymbol{\mu} = (1/4,1/4,1/2)\)</span>. It has the
following transition matrix <span class="math display">\[P = \begin{bmatrix}
    1/2 &amp; 1/4 &amp; 1/4   \\
    1/3  &amp; 1/3  &amp; 1/3   \\
    1/5  &amp; 2/5  &amp; 2/5    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span> Compute the following probabilities:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_0 = 3, X_1 = 2 , X_2 = 1).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_1 = 3, X_2 = 2 , X_3 = 1).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_{1} = 2, X_{3} = 2, X_{5} = 2).\)</span></p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<pre><code>1.  We have  </code></pre>
<p><span class="math inline">\(\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1) = p_{11} p_{12} p_{23} = (1/2)(1/4)(1/3) = 1/24.\)</span></p>
<pre><code>2.  We have  </code></pre>
<p><span class="math inline">\(\Pr(X_0 = 3, X_1 = 2, X_2 = 1) = \mu_3 p_{32} p_{21} = (0.5)(2/5)(1/3) = 1/15.\)</span></p>
<pre><code>3.  We have </code></pre>
<p><span class="math display">\[\begin{aligned} \Pr(X_1 = 3, X_2 = 2, X_3 = 1) &amp;= 
\sum_{i=1}^{3} \Pr(X_0 = i) \Pr(X_1 = 3, X_2 = 2, X_3 = 1 | X_0 = i) \\ 
&amp;= \sum_{i=1}^{3} \mu_i p_{i3} p_{32} p_{21} \\
&amp;=  \left( \sum_{i=1}^{3} \mu_i p_{i3} \right) p_{32} p_{21}  \\
&amp;= (\boldsymbol{\mu}P)_3 p_{32} p_{21}\\
&amp;= (83/240)(2/5)(1/3) \\
&amp;= 83/1800  =  0.0461111.
\end{aligned}\]</span></p>
<pre><code>4. We have </code></pre>
<p><span class="math display">\[\begin{aligned} \Pr(X_1 = 2, X_3 = 2, X_5 = 2) &amp;= 
\sum_{i=1}^{3} \Pr(X_0 = i) \Pr(X_1 = 2, X_3 = 2, X_5 = 2 | X_0 = i) \\ 
&amp;= \sum_{i=1}^{3} \mu_i p_{i2} p^{(2)}_{22} p^{(2)}_{22} \\
&amp;=  \left( \sum_{i=1}^{3} \mu_i p_{i2} \right) p^{(2)}_{22} p^{(2)}_{22}  \\
&amp;= (\boldsymbol{\mu}P)_2 p^{(2)}_{22} p^{(2)}_{22}\\
&amp;= (83/240)(59/180)(59/180) \\
&amp;= 9356/251805 = 0.0371557.
\end{aligned}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p>A Markov chain with state space <span class="math inline">\(S = \{1,2,3,4,5,6\}\)</span> has the
following transition matrix: <span class="math display">\[P = \begin{bmatrix}
1/4 &amp; 0 &amp; 3/4 &amp; 0 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 1/2 &amp; 0 &amp; 0 &amp; 1/2  \\
1/5 &amp; 1/5 &amp; 1/5 &amp; 0 &amp; 1/5 &amp; 1/5   \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0  \\
1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2/3  \\
\end{bmatrix}.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram.</p></li>
<li><p>Identify the communication classes and classify them as closed
or non-closed.</p></li>
<li><p>Is the Markov chain irreducible?</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<pre><code>1. The transition diagram is shown in the figure below:</code></pre>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre><code>2. There are two closed classes </code></pre>
<p><span class="math inline">\(C^1 = \{1, 3, 6\}\)</span> and <span class="math inline">\(C^2 = \{5\}\)</span> because</p>
<ul>
<li><p><span class="math inline">\(p_{55} = 1\)</span> and</p></li>
<li><p><span class="math inline">\(1 \rightarrow 3 \rightarrow 6 \rightarrow 1\)</span>, and hence <span class="math inline">\(1, 3, 6\)</span> are in the same communication class. In addition, for each <span class="math inline">\(i \in C^1\)</span>, <span class="math inline">\(\sum_{j \in C^1} p_{ij} = 1\)</span>, which implies that escaping from <span class="math inline">\(C^1\)</span> is impossible. Therefore <span class="math inline">\(C^1\)</span> is a closed class.</p>
<p>There is one non-closed class <span class="math inline">\(O = \{2, 4\}\)</span>. This is because <span class="math inline">\(2 \leftrightarrow 4\)</span> and <span class="math inline">\(p_{43} &gt;0\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li>The Markov chain is reducible because it contains more than one communication classes.</li>
</ol></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>For each of the Markov chains whose
transition matrix is given below, identify the closed classes and
the vector of absorption probabilities associated with each of these
closed classes. Assume that the states are labelled <span class="math inline">\(1,2,3 \ldots\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math display">\[\begin{bmatrix}
        1/6 &amp; 0 &amp; 1/3 &amp; 1/2      \\
        0 &amp; 1/3 &amp; 2/3 &amp; 0   \\
    1/2 &amp; 1/2 &amp; 0 &amp; 0     \\    
    0 &amp; 0 &amp; 1/4 &amp; 3/4     \\
\end{bmatrix}.\]</span></p></li>
<li><p><span class="math display">\[\begin{bmatrix}
        0 &amp; 1/4 &amp; 3/4 &amp; 0      \\
        0 &amp; 1/3 &amp; 0 &amp; 2/3   \\
    1/3 &amp; 0 &amp; 1/3 &amp; 1/3     \\  
    0 &amp; 0 &amp; 0 &amp; 1     \\
\end{bmatrix}.\]</span></p></li>
<li><p><span class="math display">\[\begin{bmatrix}
       1/4 &amp; 1/4 &amp; 1/4 &amp; 1/4      \\
       0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
       0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
   0 &amp; 0 &amp; 0 &amp; 1     \\
     \end{bmatrix}.\]</span></p></li>
<li><p><span class="math display">\[\begin{bmatrix}
       0 &amp; 0 &amp; 0 &amp; 1/2  &amp; 0 &amp; 0 &amp; 1/2   \\
       1/6 &amp; 0 &amp; 1/6 &amp; 0  &amp; 0 &amp; 1/6 &amp; 1/2 \\
   0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0    \\ 
       1/2 &amp; 0 &amp; 0 &amp; 1/2  &amp; 0 &amp; 0 &amp; 0   \\
   1/4 &amp; 1/4 &amp; 0 &amp; 0  &amp; 0 &amp; 0 &amp; 1/2 \\
   0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0    \\ 
       1/2 &amp; 0 &amp; 0 &amp; 0  &amp; 0 &amp; 0 &amp; 1/2   \\
     \end{bmatrix}.\]</span></p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<pre><code>1. Every two states communicate, so </code></pre>
<p><span class="math inline">\(\{1, 2, 3, 4 \}\)</span> is a single closed class (since <span class="math inline">\(1 \rightarrow 4 \rightarrow 3 \rightarrow 2 \rightarrow 3 \rightarrow 1\)</span>). The absorption probabilities are 1, since each state is in this closed class. The transition diagram is shown in the figure below:</p>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre><code>2. There are two non-closed classes </code></pre>
<p><span class="math inline">\(O^1 = \{1, 3\}\)</span> and <span class="math inline">\(O^2 = \{2\}\)</span> and a closed class
<span class="math inline">\(C^1 = \{4\}\)</span>. Since we have a single closed class, all absorption probabilities to this closed class <span class="math inline">\(C^1 = \{4\}\)</span> are equal to 1. The transition diagram is shown in the figure below:</p>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<pre><code>3. There are two closed classes </code></pre>
<p><span class="math inline">\(C^1 = \{2, 3\}\)</span> and <span class="math inline">\(C^2 = \{4\}\)</span> and a non-closed class
<span class="math inline">\(O^1 = \{1\}\)</span>. The transition diagram is shown in the figure below:</p>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Let
<span class="math inline">\(\mathbf{u}=\mathbf{u}^{C_{2}}\)</span> be the vector of absorption
probabilities in the closed class <span class="math inline">\(C^2 = \{4\}\)</span>. Write
<span class="math inline">\(\mathbf{u}= (u_1,u_2,u_3,u_4)^T\)</span> and <span class="math inline">\(u_4 = 1\)</span> and <span class="math inline">\(u_2 = u_3 =0\)</span>,</p>
<p>From <span class="math inline">\(\mathbf{u}=P \cdot \mathbf{u}\)</span>,</p>
<p><span class="math display">\[\left(\begin{array}{c}u_{1} \\ u_{2} \\  u_{3} \\ u_{4}\end{array}\right)=\begin{bmatrix}
                1/4 &amp; 1/4 &amp; 1/4 &amp; 1/4      \\
                0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
                0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
            0 &amp; 0 &amp; 0 &amp; 1     \\
        \end{bmatrix} \left(\begin{array}{c}u_{1} \\ u_{2} \\  u_{3} \\ u_{4}\end{array}\right) \text { gives}\]</span>
<span class="math display">\[ u_1 = \frac{1}{4} u_1 + \frac{1}{4}\]</span> Solving the
linear system for <span class="math inline">\(u_1\)</span> yields <span class="math inline">\(u_1 = 1/3\)</span>.
Hence, the absorption probabilities in the closed class <span class="math inline">\(C_2\)</span> is
<span class="math display">\[\mathbf{u}= (1/3,0,0,1)^T.\]</span>
In addition, since there are two closed classes,
<span class="math inline">\(\mathbf{u}^{C_1} = \mathbf{1} - \mathbf{u}^{C_2} = (2/3,1,1,0)^T.\)</span></p>
<pre><code>4. There are two closed classes </code></pre>
<p><span class="math inline">\(C^1 = \{1, 4, 7\}\)</span> and <span class="math inline">\(C^2 = \{3\}\)</span> and two non-closed classes
<span class="math inline">\(O^1 = \{2, 6\}\)</span> and <span class="math inline">\(O^2 = \{5\}\)</span>. The transition diagram is shown in the figure below:</p>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Let
<span class="math inline">\(\mathbf{u}=\mathbf{u}^{C_{2}}\)</span> be the vector of absorption
probabilities in the closed class <span class="math inline">\(C^2 = \{3\}\)</span>. Write
<span class="math inline">\(\mathbf{u}= (u_1,u_2,u_3,\ldots, u_7)^T\)</span> and <span class="math inline">\(u_3 = 1\)</span> and <span class="math inline">\(u_1 = u_4 = u_7 =0\)</span>,</p>
<p><span class="math display">\[\left(\begin{array}{c}u_{1} \\ u_{2} \\ \vdots \\ u_{7}\end{array}\right)=P\left(\begin{array}{c}u_{1} \\ u_{2} \\ \vdots \\ u_{7}\end{array}\right) \text{ gives}\]</span>
<span class="math display">\[\begin{aligned}
    u_2 &amp;= \frac{1}{6}  + \frac{1}{6} u_6 \\
    u_5 &amp;=   \frac{1}{4} u_2\\
    u_6 &amp;=   u_2.\\   \end{aligned}\]</span>
Solving the linear system for <span class="math inline">\(u_2, u_5\)</span> and <span class="math inline">\(u_6\)</span> yields <span class="math inline">\(u_2 = 1/5, u_5 = 1/20\)</span> and <span class="math inline">\(u_6 = 1/5\)</span>.
Hence, the absorption probabilities in the closed class <span class="math inline">\(C_2\)</span> is
<span class="math display">\[\mathbf{u}= (0,1/5,1,0,1/20,1/5,0)^T.\]</span>
In addition, since there are two closed classes,
<span class="math inline">\(\mathbf{u}^{C_1} = \mathbf{1} - \mathbf{u}^{C_2} = (1,4/5,0,1,19/20,4/5,1)^T.\)</span></p>
<ol start="4" style="list-style-type: decimal">
<li><p>If the Markov chain defined in Question 3 is irreducible,
i.e. it has a unique stationary distribution, then find the
stationary distribution of the chain.</p></li>
<li><p>Assume that a Markov chain has more than one closed classes (say <span class="math inline">\(r\)</span>
closed classes). The Markov chain can <strong>have many stationary
distributions</strong>. Assume further that within each of these <span class="math inline">\(r\)</span> closed
classes, the associated Markov chain is aperiodic. The followings
hold:</p>
<ul>
<li><p>Within a closed class <span class="math inline">\(C_1\)</span>, let <span class="math inline">\(P_1\)</span> be a reduction of a
matrix <span class="math inline">\(P\)</span> which is formed by deleting all rows and columns
corresponding to states from other classes. Then there exists a
unique stationary distribution, denoted by
<span class="math inline">\(\{\pi_j^{(1)}\}_{j \in C_1}.\)</span></p></li>
<li><p>Similarly, let
<span class="math inline">\(\{\pi_j^{(2)}\}_{j \in C_2}, \ldots, \{\pi_j^{(r)}\}_{j \in C_r}\)</span>
be stationary distributions within other classes.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li>Show that for any numbers <span class="math inline">\(\gamma_1, \gamma_2, \ldots, \gamma_r\)</span>
such that <span class="math inline">\(\sum_{m=1}^r \gamma_m = 1\)</span>, the following
distribution <span class="math inline">\(\{ \pi_j \}\)</span> is stationary, where</li>
</ol>
<p><span class="math display" id="eq:limitdist">\[\begin{equation} 
  \tag{5.1}
    \pi_j =
     \begin{cases}
        \pi_j^{(k)} \gamma_k &amp; \text{for } j \in C_k, \, k= 1,\ldots, r \\
        0 &amp; \text{if } j \text{ is in a nonclosed class.}
      \end{cases}
    \end{equation}\]</span>
(In particular, any stationary distribution of the Markov chain is of this form.)</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Write down the general form of stationary distributions of the
Markov chain in Questions 3.3 and 3.4.</p></li>
<li><p>Now we will focus on limiting distributions. Consider the three
following possible cases.</p>
<ol style="list-style-type: decimal">
<li><p>If <span class="math inline">\(X_0 = i\)</span> and <span class="math inline">\(i \in C_k\)</span> for some closed class <span class="math inline">\(C_k\)</span>,
then verify that the limiting distribution is defined as in Eqn.<a href="tutorials.html#eq:limitdist">(5.1)</a> where <span class="math inline">\(\gamma_k =1\)</span> and
<span class="math inline">\(\gamma_m = 0,\)</span> for <span class="math inline">\(m \neq k\)</span>.</p></li>
<li><p>If <span class="math inline">\(X_0 = i\)</span> and <span class="math inline">\(i\)</span> is in a nonclosed class, then verify
that the limiting distribution is defined as in
Eqn.<a href="tutorials.html#eq:limitdist">(5.1)</a> where <span class="math inline">\(\gamma_k = \alpha^{(k)}_i\)</span>
for <span class="math inline">\(k = 1,2,\ldots r\)</span> where <span class="math inline">\(\alpha^{(k)}_i\)</span> is the
probability of absorption in class <span class="math inline">\(C_k\)</span>. More precisely,
<span class="math display">\[\pi_j =
 \begin{cases}
    \pi_j^{(k)} \alpha^{(k)}_i &amp; \text{for } j \in C_k, \, k= 1,\ldots, r \\
    0 &amp; \text{if } j \text{ is in a nonclosed class.}
  \end{cases}
      %\pi_j^{(k)} \gamma_k \text{ for } j \in C_k, \, k= 1,\ldots, r \text { and }\]</span></p></li>
<li><p>If <span class="math inline">\(X_0\)</span> is random, then this will leave as extra exercise.
(Hint: you may need to apply first step anslysis)</p></li>
</ol></li>
</ol></li>
<li><p>A no-claims discount system for motor insurance has four levels of
discount:</p>
<table>
<thead>
<tr class="header">
<th align="center">Level</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Discount</td>
<td align="center">0%</td>
<td align="center">10%</td>
<td align="center">30%</td>
<td align="center">50%</td>
</tr>
</tbody>
</table>
<p>The rules for moving between these levels are given as follows:</p>
<ul>
<li><p>Following a claim-free year, move to the next higher level, or
remain at level 4.</p></li>
<li><p>Following a year with one claim, move to the next lower level,
or remain at level 1.</p></li>
<li><p>Following a year with two or more claims, move down two levels,
or move to level 1 (from level 2), or remain at level 1.</p></li>
</ul>
<p>A portfolio consists of 10,000 policyholders. Suppose also that the
number of claims per year is <span class="math inline">\(\mathcal{Poisson}(0.1)\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Calculate <span class="math inline">\(\Pr[N = 0]\)</span>, <span class="math inline">\(\Pr[N = 1]\)</span>, and <span class="math inline">\(\Pr[N \ge 2]\)</span> for
each group.</p></li>
<li><p>Write down the transition probability matrix of this no-claims
discount system.</p></li>
<li><p>Find the probability that a policyholder who has the 30%
discount has no discount after 2 years.</p></li>
<li><p>Calculate the expected number of policyholders at each level at
times 1 and 2, assuming no exits.</p></li>
<li><p>Calculate the expected number of policyholders at each level
once stability has been achieved, assuming no exits.</p></li>
</ol></li>
<li><p>A no-claims discount system for motor insurance has four levels of
discount:</p>
<table>
<thead>
<tr class="header">
<th align="center">Level</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Discount</td>
<td align="center">0%</td>
<td align="center">20%</td>
<td align="center">30%</td>
<td align="center">50%</td>
</tr>
</tbody>
</table>
<p>The rules for moving between these levels are given as follows:</p>
<ul>
<li><p>For a claim-free year, a policyholder moves to the next higher
level, or remains at level 4.</p></li>
<li><p>For every claim in a year, the policyholder moves down a
discount level or remains at level 1, for example if the
policyholder is in level 4 and has one accident, he/she moves to
level 3, and 2 accidents, he/she moves to level 2, and 2 or more
accidents to level 1.</p></li>
</ul>
<p>For a given policyholder, the number of claims each year, <span class="math inline">\(N\)</span>, has a
negative binomial distribution with parameters <span class="math inline">\(k=2\)</span> and <span class="math inline">\(p = 0.5\)</span>.</p>
<p>Note that a random variable <span class="math inline">\(N\)</span> has a negative distribution with
parameters <span class="math inline">\(k\)</span> and <span class="math inline">\(p\)</span>, denoted by <span class="math inline">\(N \sim \dnb\)</span> if its probability
mass function is given by
<span class="math display">\[f_N(n) = \Pr(N = n) = \frac{\Gamma(k+n)}{\Gamma(n+1)\Gamma(k)} p^k (1- p)^n \quad n = 0,1,2,\ldots.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>Write down the transition matrix of this no-claims discount
system.</p></li>
<li><p>Find the probability that a policyholder who has the maximum
discount level will have 20% discount after two years.</p></li>
</ol></li>
</ol>
</div>
<div id="tutorial-2-1" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Tutorial 2</h2>
<ol style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on states 1 ,2 ,3 has the
following transition matrix <span class="math display">\[P = \begin{bmatrix}
    0.5 &amp; 0.3 &amp; 0.2    \\
    0.2 &amp; 0.2 &amp; 0.6  \\
    0.3 &amp; 0.2 &amp;  0.5    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span> The distribution of the initial random variable
<span class="math inline">\(X_0\)</span> is <span class="math inline">\(\boldsymbol{\mu} = (0.3,0,3,0.4)\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_0 = 1, X_1 = 2, X_2 = 3).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_1 = 2, X_2 = 3 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 3 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_3 = 3 | X_1 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 3).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\mathrm{E}[X_2]\)</span></p></li>
</ol></li>
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on states 1 ,2 ,3 has the
following transition matrix <span class="math display">\[P = \begin{bmatrix}
    0 &amp; 1/2 &amp; 1/2   \\
    1/3  &amp; 1/3  &amp; 1/3   \\
    1/2  &amp; 1/2  &amp; 0    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span> The process starts in states <span class="math inline">\(X_0 = 1\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_0 = 1, X_1 = 3, X_2 = 2).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_1 = 3, X_2 = 2 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 2 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_3 = 2 | X_1 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 2).\)</span></p></li>
</ol></li>
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on sates 1 ,2 has the following
transition matrix <span class="math display">\[P = \begin{bmatrix}
    1-a &amp; a   \\
    b &amp; 1-b   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix},\]</span> where <span class="math inline">\(0 &lt; a,b &lt; 1.\)</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>the distribution of <span class="math inline">\(X_1\)</span>.</p></li>
<li><p>Show that <span class="math display">\[P^n = \frac{1}{a+b} \begin{bmatrix}
    b &amp; a   \\
    b &amp; a   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix} +
\frac{(1-a-b)^n}{a+b} \begin{bmatrix}
    a &amp; -a   \\
    -b &amp; b   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span></p></li>
<li><p>Given that <span class="math inline">\(X_0 = 1\)</span>, what is the probability that in the long
run the system will be in state 1? (Hint: consider
<span class="math inline">\(\lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n\)</span>)</p></li>
<li><p>Given that <span class="math inline">\(X_0 = 1\)</span>, what is the probability that in the long
run the system will be in state 2?</p></li>
<li><p>Given that <span class="math inline">\(X_0 = 2\)</span>, what is the probability that in the long
run the system will be in state 1?</p></li>
<li><p>Given that <span class="math inline">\(X_0 = 2\)</span>, what is the probability that in the long
run the system will be in state 2?</p></li>
</ol></li>
<li><p>Let <span class="math inline">\(a\)</span> be a constant and <span class="math inline">\(\xi_1, \xi_2, \ldots\)</span> be a sequence of
independent and identically distributed (i.i.d.) random variables.
The stochastic process <span class="math inline">\(\{ X_n\}\)</span> is defined by
<span class="math display">\[X_0 = a, \quad X_n = X_{n-1} + \xi_n, \, n &gt; 1.\]</span> This process is
known as a random walk.</p>
<ol style="list-style-type: decimal">
<li><p>Express the state <span class="math inline">\(X_n\)</span> in terms of <span class="math inline">\(X_0\)</span> and the random
variables <span class="math inline">\(\xi_i, i = 1,2 \ldots\)</span>.</p></li>
<li><p>Find <span class="math inline">\(\mathrm{E}[X_n]\)</span> and <span class="math inline">\(\mathrm{Var}[X_n]\)</span>.</p></li>
<li><p>Does the process have the Markov property? Explain.</p></li>
<li><p>Is the process stationary? Explain.</p></li>
</ol></li>
<li><p>Consider a homogeneous discrete-time Markov chain that describes the
daily weather pattern. The weather patterns are classified into 3
conditions: R(rainy), C (cloudy) and S(sunny). Based on the daily
observations, the following information are given:</p>
<ul>
<li><p>On any rainy day, the probability that it will rain the next day
is 0.7; the probability that tomorrow will be cloudy is 0.2 and
the probability that tomorrow will be sunny is 0.1.</p></li>
<li><p>On any cloudy day, the probability that it will rain the next
day is 0.5; the probability that tomorrow will be cloudy is 0.35
and the probability that tomorrow will be sunny is 0.15.</p></li>
<li><p>On any sunny day, the probability that it will rain the next day
is 0.1; the probability that tomorrow will be cloudy is 0.4 and
the probability that tomorrow will be sunny is 0.5.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain and write down a
transition matrix.</p></li>
<li><p>Find the probability that tomorrow is cloudy and the day after
is rainy, given that it is sunny today.</p></li>
<li><p>Given that today is rainy, find the probability that it will be
sunny in two days time.</p></li>
</ol></li>
</ol>
</div>
<div id="tutorial-3-1" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Tutorial 3</h2>
<ol style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on states 1, 2, 3 with initial
distribution <span class="math inline">\(\boldsymbol{\mu} = (1/4,1/4,1/2)\)</span>. It has the
following transition matrix <span class="math display">\[P = \begin{bmatrix}
    1/2 &amp; 1/4 &amp; 1/4   \\
    1/3  &amp; 1/3  &amp; 1/3   \\
    1/5  &amp; 2/5  &amp; 2/5    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span> Compute the following probabilities:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_0 = 3, X_1 = 2 , X_2 = 1).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_1 = 3, X_2 = 2 , X_3 = 1).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_{1} = 2, X_{3} = 2, X_{5} = 2).\)</span></p></li>
</ol></li>
<li><p>A Markov chain with state space <span class="math inline">\(S = \{1,2,3,4,5,6\}\)</span> has the
following transition matrix: <span class="math display">\[P = \begin{bmatrix}
1/4 &amp; 0 &amp; 3/4 &amp; 0 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 1/2 &amp; 0 &amp; 0 &amp; 1/2  \\
1/5 &amp; 1/5 &amp; 1/5 &amp; 0 &amp; 1/5 &amp; 1/5   \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0  \\
1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2/3  \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram.</p></li>
<li><p>Identify the communication classes and classify them as closed
or non-closed.</p></li>
<li><p>Is the Markov chain irreducible?</p></li>
</ol></li>
<li><p>For each of the Markov chains whose
transition matrix is given below, identify the closed classes and
the vector of absorption probabilities associated with each of these
closed classes. Assume that the states are labelled <span class="math inline">\(1,2,3 \ldots\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math display">\[\begin{bmatrix}
        1/6 &amp; 0 &amp; 1/3 &amp; 1/2      \\
        0 &amp; 1/3 &amp; 2/3 &amp; 0   \\
    1/2 &amp; 1/2 &amp; 0 &amp; 0     \\    
    0 &amp; 0 &amp; 1/4 &amp; 3/4     \\
\end{bmatrix}.\]</span></p></li>
<li><p><span class="math display">\[\begin{bmatrix}
        0 &amp; 1/4 &amp; 3/4 &amp; 0      \\
        0 &amp; 1/3 &amp; 0 &amp; 2/3   \\
    1/3 &amp; 0 &amp; 1/3 &amp; 1/3     \\  
    0 &amp; 0 &amp; 0 &amp; 1     \\
\end{bmatrix}.\]</span></p></li>
<li><p><span class="math display">\[\begin{bmatrix}
       1/4 &amp; 1/4 &amp; 1/4 &amp; 1/4      \\
       0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
       0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
   0 &amp; 0 &amp; 0 &amp; 1     \\
     \end{bmatrix}.\]</span></p></li>
<li><p><span class="math display">\[\begin{bmatrix}
       0 &amp; 0 &amp; 0 &amp; 1/2  &amp; 0 &amp; 0 &amp; 1/2   \\
       1/6 &amp; 0 &amp; 1/6 &amp; 0  &amp; 0 &amp; 1/6 &amp; 1/2 \\
   0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0    \\ 
       1/2 &amp; 0 &amp; 0 &amp; 1/2  &amp; 0 &amp; 0 &amp; 0   \\
   1/4 &amp; 1/4 &amp; 0 &amp; 0  &amp; 0 &amp; 0 &amp; 1/2 \\
   0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0    \\ 
       1/2 &amp; 0 &amp; 0 &amp; 0  &amp; 0 &amp; 0 &amp; 1/2   \\
     \end{bmatrix}.\]</span></p></li>
</ol></li>
<li><p>If the Markov chain defined in Question 3 is irreducible,
i.e. it has a unique stationary distribution, then find the
stationary distribution of the chain.</p></li>
<li><p>Assume that a Markov chain has more than one closed classes (say <span class="math inline">\(r\)</span>
closed classes). The Markov chain can <strong>have many stationary
distributions</strong>. Assume further that within each of these <span class="math inline">\(r\)</span> closed
classes, the associated Markov chain is aperiodic. The followings
hold:</p>
<ul>
<li><p>Within a closed class <span class="math inline">\(C_1\)</span>, let <span class="math inline">\(P_1\)</span> be a reduction of a
matrix <span class="math inline">\(P\)</span> which is formed by deleting all rows and columns
corresponding to states from other classes. Then there exists a
unique stationary distribution, denoted by
<span class="math inline">\(\{\pi_j^{(1)}\}_{j \in C_1}.\)</span></p></li>
<li><p>Similarly, let
<span class="math inline">\(\{\pi_j^{(2)}\}_{j \in C_2}, \ldots, \{\pi_j^{(r)}\}_{j \in C_r}\)</span>
be stationary distributions within other classes.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li>Show that for any numbers <span class="math inline">\(\gamma_1, \gamma_2, \ldots, \gamma_r\)</span>
such that <span class="math inline">\(\sum_{m=1}^r \gamma_m = 1\)</span>, the following
distribution <span class="math inline">\(\{ \pi_j \}\)</span> is stationary, where</li>
</ol>
<p><span class="math display" id="eq:limitdist">\[\begin{equation} 
  \tag{5.1}
    \pi_j =
     \begin{cases}
        \pi_j^{(k)} \gamma_k &amp; \text{for } j \in C_k, \, k= 1,\ldots, r \\
        0 &amp; \text{if } j \text{ is in a nonclosed class.}
      \end{cases}
    \end{equation}\]</span>
(In particular, any stationary distribution of the Markov chain is of this form.)</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Write down the general form of stationary distributions of the
Markov chain in Questions 3.3 and 3.4.</p></li>
<li><p>Now we will focus on limiting distributions. Consider the three
following possible cases.</p>
<ol style="list-style-type: decimal">
<li><p>If <span class="math inline">\(X_0 = i\)</span> and <span class="math inline">\(i \in C_k\)</span> for some closed class <span class="math inline">\(C_k\)</span>,
then verify that the limiting distribution is defined as in Eqn.<a href="tutorials.html#eq:limitdist">(5.1)</a> where <span class="math inline">\(\gamma_k =1\)</span> and
<span class="math inline">\(\gamma_m = 0,\)</span> for <span class="math inline">\(m \neq k\)</span>.</p></li>
<li><p>If <span class="math inline">\(X_0 = i\)</span> and <span class="math inline">\(i\)</span> is in a nonclosed class, then verify
that the limiting distribution is defined as in
Eqn.<a href="tutorials.html#eq:limitdist">(5.1)</a> where <span class="math inline">\(\gamma_k = \alpha^{(k)}_i\)</span>
for <span class="math inline">\(k = 1,2,\ldots r\)</span> where <span class="math inline">\(\alpha^{(k)}_i\)</span> is the
probability of absorption in class <span class="math inline">\(C_k\)</span>. More precisely,
<span class="math display">\[\pi_j =
 \begin{cases}
    \pi_j^{(k)} \alpha^{(k)}_i &amp; \text{for } j \in C_k, \, k= 1,\ldots, r \\
    0 &amp; \text{if } j \text{ is in a nonclosed class.}
  \end{cases}
      %\pi_j^{(k)} \gamma_k \text{ for } j \in C_k, \, k= 1,\ldots, r \text { and }\]</span></p></li>
<li><p>If <span class="math inline">\(X_0\)</span> is random, then this will leave as extra exercise.
(Hint: you may need to apply first step anslysis)</p></li>
</ol></li>
</ol></li>
<li><p>A no-claims discount system for motor insurance has four levels of
discount:</p>
<table>
<thead>
<tr class="header">
<th align="center">Level</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Discount</td>
<td align="center">0%</td>
<td align="center">10%</td>
<td align="center">30%</td>
<td align="center">50%</td>
</tr>
</tbody>
</table>
<p>The rules for moving between these levels are given as follows:</p>
<ul>
<li><p>Following a claim-free year, move to the next higher level, or
remain at level 4.</p></li>
<li><p>Following a year with one claim, move to the next lower level,
or remain at level 1.</p></li>
<li><p>Following a year with two or more claims, move down two levels,
or move to level 1 (from level 2), or remain at level 1.</p></li>
</ul>
<p>A portfolio consists of 10,000 policyholders. Suppose also that the
number of claims per year is <span class="math inline">\(\mathcal{Poisson}(0.1)\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Calculate <span class="math inline">\(\Pr[N = 0]\)</span>, <span class="math inline">\(\Pr[N = 1]\)</span>, and <span class="math inline">\(\Pr[N \ge 2]\)</span> for
each group.</p></li>
<li><p>Write down the transition probability matrix of this no-claims
discount system.</p></li>
<li><p>Find the probability that a policyholder who has the 30%
discount has no discount after 2 years.</p></li>
<li><p>Calculate the expected number of policyholders at each level at
times 1 and 2, assuming no exits given that all policyholders start at level 1.</p></li>
<li><p>Calculate the expected number of policyholders at each level
once stability has been achieved, assuming no exits.</p></li>
</ol></li>
<li><p>A no-claims discount system for motor insurance has four levels of
discount:</p>
<table>
<thead>
<tr class="header">
<th align="center">Level</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Discount</td>
<td align="center">0%</td>
<td align="center">20%</td>
<td align="center">30%</td>
<td align="center">50%</td>
</tr>
</tbody>
</table>
<p>The rules for moving between these levels are given as follows:</p>
<ul>
<li><p>For a claim-free year, a policyholder moves to the next higher
level, or remains at level 4.</p></li>
<li><p>For every claim in a year, the policyholder moves down a
discount level or remains at level 1, for example if the
policyholder is in level 4 and has one accident, he/she moves to
level 3, and 2 accidents, he/she moves to level 2, and 2 or more
accidents to level 1.</p></li>
</ul>
<p>For a given policyholder, the number of claims each year, <span class="math inline">\(N\)</span>, has a
negative binomial distribution with parameters <span class="math inline">\(k=2\)</span> and <span class="math inline">\(p = 0.5\)</span>.</p>
<p>Note that a random variable <span class="math inline">\(N\)</span> has a negative distribution with
parameters <span class="math inline">\(k\)</span> and <span class="math inline">\(p\)</span>, denoted by <span class="math inline">\(N \sim \dnb\)</span> if its probability
mass function is given by
<span class="math display">\[f_N(n) = \Pr(N = n) = \frac{\Gamma(k+n)}{\Gamma(n+1)\Gamma(k)} p^k (1- p)^n \quad n = 0,1,2,\ldots.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>Write down the transition matrix of this no-claims discount
system.</p></li>
<li><p>Find the probability that a policyholder who has the maximum
discount level will have 20% discount after two years.</p></li>
</ol></li>
</ol>
</div>
<div id="tutorial-4" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Tutorial 4</h2>
<ol style="list-style-type: decimal">
<li><p>Customers arrive in a shop according to a Poisson process of rate
<span class="math inline">\(\lambda = 4\)</span>. Let <span class="math inline">\(N(t)\)</span> be the number of customers that have
arrived up to time <span class="math inline">\(t\)</span>. Determine the following probabilities,
conditional probabilities and expectations.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\Pr(N(1) = 2).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) = 2 \text{ and } N(3) = 6).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) = 2 | N(3) = 6).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(3) = 6 | N(1) = 2).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) \le 2).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) = 1 \text{ and } N(2) = 3).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) \ge 2 | N(1) \ge 1).\)</span></p></li>
<li><p><span class="math inline">\(\mathrm{E}[N(2)]\)</span></p></li>
<li><p><span class="math inline">\(\mathrm{E}[N(1)^2]\)</span></p></li>
<li><p><span class="math inline">\(\mathrm{E}[N(1)N(2)]\)</span></p></li>
</ol></li>
<li><p>Customers arrive in a shop according to a Poisson process of rate
<span class="math inline">\(\lambda = 4\)</span> per hour. The shop opens at 9 am. Calculate the
probability that exactly one customer has arrived by 9.30 am and a
total of five customers have arrived by 11.30.</p></li>
<li><p>Defects occur along a cable according to a Poisson process of rate
<span class="math inline">\(\lambda = 0.1\)</span> per kilometre.</p>
<ol style="list-style-type: decimal">
<li><p>Calculate the probability that no defects appear in the first
two kilometres of cable.</p></li>
<li><p>Given that there are no defects in the first two kilometres of
cable, calculate the probability of no defects between two and
three kilometres of cable.</p></li>
</ol></li>
<li><p>Customers arrive at a department store according to a Poisson
process with rate <span class="math inline">\(\lambda = 2\)</span> per minute.</p>
<ol style="list-style-type: decimal">
<li><p>Calculate the probability that in a given 5 minute period there
will be no customers arriving?</p></li>
<li><p>Calculate the probability that the 10th customer after 11 am
will arrive before 11:05 am?</p></li>
<li><p>If a third of customers are men, calculate the probability that
in a 5 minute period more than 3 men arrive given more than 4
women arrive.</p></li>
<li><p>If every 5th customer receives a discount voucher, calculate the
distribution of the times between these vouchers being given
out? What is the probability that a time longer</p></li>
</ol></li>
<li><p>You have a bird table in your garden which attracts tailorbirds and
pigeons. Tailorbirds arrive according to a Poisson process with rate
<span class="math inline">\(\lambda_1\)</span> and the pigeons arrive according to a Poisson process
with rate <span class="math inline">\(\lambda_2\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>How long does it take for the first bird to arrive after a fixed
point in time?</p></li>
<li><p>Calculate the probability this bird is a tailorbird?</p></li>
<li><p>What is the distribution of the number of birds in the time
interval <span class="math inline">\([t_1, t_2)\)</span>?</p></li>
<li><p>Calculate the probability that exactly 3 tailorbirds arrive
before the first pigeon after a fixed point in time?</p></li>
</ol></li>
<li><p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be independent Poisson distributed random variables
with parameters <span class="math inline">\(\lambda_X\)</span> and <span class="math inline">\(\lambda_Y\)</span>, respectively. Determine
the conditional distribution of <span class="math inline">\(X\)</span>, given that <span class="math inline">\(N = X + Y = n\)</span>.</p></li>
<li><p>Accidents occur on an highway according to a Poisson process at the
rate of 20 accidents per week. One out of four accidents involve
speeding.</p>
<ol style="list-style-type: decimal">
<li><p>What is the probability that ten accidents involving speeding
will occur next week?</p></li>
<li><p>What is the probability that at least one accident occurs
tomorrow?</p></li>
<li><p>If sixty accidents occur in four weeks, what is the probability
that less than half of them involve speeding?</p></li>
</ol></li>
<li><p>Severe floods hit a southern of Thailand according to a Poisson
process with <span class="math inline">\(\lambda = 4\)</span>. The number of insurance claims filed
after any sever flood has a Poisson distribution with mean 60. The
number of server floods is independent of the number of insurance
claims. Find the expectation and standard deviation of the total
number of claims filed by time <span class="math inline">\(t\)</span>.</p></li>
<li><p>Assume that births occur at a hospital at the average rate of 3
births per hour. Assume that the probability that any birth is a boy
is 0.52.</p>
<ol style="list-style-type: decimal">
<li><p>On an 8-hour shift, what is the expectation and standard
deviation of the number of male births?</p></li>
<li><p>Assume that ten babies were born yesterday. Find the probability
that six are boys.</p></li>
<li><p>Find the probability that only boys were born between 6 and 10
a.m.</p></li>
</ol></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="discrete-time-markov-chains.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="applications.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-Tutorials.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/pairote-sat/SCMA469/blob/master/04-Tutorials.Rmd",
"text": null
},
"download": ["SCMA469Bookdownproj.pdf", "SCMA469Bookdownproj.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
