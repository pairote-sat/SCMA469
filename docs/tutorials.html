<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Tutorials | SCMA469 Actuarial Statistics</title>
  <meta name="description" content="Chapter 6 Tutorials | SCMA469 Actuarial Statistics" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Tutorials | SCMA469 Actuarial Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Tutorials | SCMA469 Actuarial Statistics" />
  
  
  

<meta name="author" content="Pairote Satiracoo" />


<meta name="date" content="2022-08-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="poisson-processes.html"/>
<link rel="next" href="applications.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SCMA469 Actuarial Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Stochastic Processes</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#examples-of-real-world-processes"><i class="fa fa-check"></i><b>1.1</b> Examples of real world processes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html"><i class="fa fa-check"></i><b>2</b> Review of probability theory</a>
<ul>
<li class="chapter" data-level="2.1" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#random-variables"><i class="fa fa-check"></i><b>2.1</b> Random variables</a></li>
<li class="chapter" data-level="2.2" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#probability-distribution"><i class="fa fa-check"></i><b>2.2</b> Probability distribution</a></li>
<li class="chapter" data-level="2.3" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-probability"><i class="fa fa-check"></i><b>2.3</b> Conditional probability</a></li>
<li class="chapter" data-level="2.4" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#law-of-total-probability"><i class="fa fa-check"></i><b>2.4</b> Law of total probability</a></li>
<li class="chapter" data-level="2.5" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#conditional-distribution-and-conditional-expectation"><i class="fa fa-check"></i><b>2.5</b> Conditional distribution and conditional expectation</a></li>
<li class="chapter" data-level="2.6" data-path="review-of-probability-theory.html"><a href="review-of-probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.6</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>3</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#classification-of-stochastic-processes"><i class="fa fa-check"></i><b>3.1</b> Classification of stochastic processes</a></li>
<li class="chapter" data-level="3.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html#random-walk-an-introductory-example"><i class="fa fa-check"></i><b>3.2</b> Random walk: an introductory example</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html"><i class="fa fa-check"></i><b>4</b> Discrete-time Markov chains</a>
<ul>
<li class="chapter" data-level="4.1" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#one-step-transition-probabilities"><i class="fa fa-check"></i><b>4.1</b> One-step transition probabilities</a></li>
<li class="chapter" data-level="4.2" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-chapman-kolmogorov-equation-and-n-step-transition-probabilities"><i class="fa fa-check"></i><b>4.2</b> The Chapman-Kolmogorov equation and <span class="math inline">\(n\)</span>-step transition probabilities</a></li>
<li class="chapter" data-level="4.3" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#distribution-of-x_n"><i class="fa fa-check"></i><b>4.3</b> Distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="4.4" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#joint-distribution"><i class="fa fa-check"></i><b>4.4</b> Joint Distribution</a></li>
<li class="chapter" data-level="4.5" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#random-walk-with-absorbing-and-reflecting-barriers"><i class="fa fa-check"></i><b>4.5</b> Random walk with absorbing and reflecting barrier(s)</a></li>
<li class="chapter" data-level="4.6" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#an-example-of-nonhomogeneous-markov-chain"><i class="fa fa-check"></i><b>4.6</b> An example of nonhomogeneous Markov chain</a></li>
<li class="chapter" data-level="4.7" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#simulation"><i class="fa fa-check"></i><b>4.7</b> Simulation</a></li>
<li class="chapter" data-level="4.8" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#monte-carlo-methods"><i class="fa fa-check"></i><b>4.8</b> Monte Carlo Methods</a></li>
<li class="chapter" data-level="4.9" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#classification-of-states"><i class="fa fa-check"></i><b>4.9</b> Classification of states</a></li>
<li class="chapter" data-level="4.10" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#absorption-probabilities-and-expected-time-to-absorption"><i class="fa fa-check"></i><b>4.10</b> Absorption probabilities and expected time to absorption</a></li>
<li class="chapter" data-level="4.11" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#first-step-analysis"><i class="fa fa-check"></i><b>4.11</b> First step analysis</a></li>
<li class="chapter" data-level="4.12" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-expected-time-to-absorption"><i class="fa fa-check"></i><b>4.12</b> The expected time to absorption</a></li>
<li class="chapter" data-level="4.13" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-long-term-distribution-of-a-markov-chain"><i class="fa fa-check"></i><b>4.13</b> The long-term distribution of a Markov chain</a></li>
<li class="chapter" data-level="4.14" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#stationary-and-limiting-distributions-for-a-single-closed-class"><i class="fa fa-check"></i><b>4.14</b> Stationary and limiting distributions for a single closed class</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#stationary-distributions"><i class="fa fa-check"></i>Stationary distributions</a></li>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#proportion-of-time-in-each-state"><i class="fa fa-check"></i>Proportion of Time in Each State</a></li>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#the-method-of-finding-the-stationary-distribution"><i class="fa fa-check"></i>The method of finding the stationary distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#sufficient-conditions-for-the-long-run-behaviour-of-a-markov-chain"><i class="fa fa-check"></i><b>4.15</b> Sufficient conditions for the long-run behaviour of a Markov chain</a></li>
<li class="chapter" data-level="4.16" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#limiting-distributions"><i class="fa fa-check"></i><b>4.16</b> Limiting distributions</a></li>
<li class="chapter" data-level="4.17" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#main-result"><i class="fa fa-check"></i><b>4.17</b> Main result</a>
<ul>
<li class="chapter" data-level="" data-path="discrete-time-markov-chains.html"><a href="discrete-time-markov-chains.html#applications-of-markov-chains-to-ncd-systems"><i class="fa fa-check"></i>Applications of Markov chains to NCD systems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="poisson-processes.html"><a href="poisson-processes.html"><i class="fa fa-check"></i><b>5</b> Poisson processes</a>
<ul>
<li class="chapter" data-level="5.1" data-path="poisson-processes.html"><a href="poisson-processes.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="poisson-processes.html"><a href="poisson-processes.html#poisson-process"><i class="fa fa-check"></i><b>5.2</b> Poisson process</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="poisson-processes.html"><a href="poisson-processes.html#counting-process"><i class="fa fa-check"></i><b>5.2.1</b> Counting Process</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="poisson-processes.html"><a href="poisson-processes.html#properties-of-poisson-processes"><i class="fa fa-check"></i><b>5.3</b> Properties of Poisson processes</a></li>
<li class="chapter" data-level="5.4" data-path="poisson-processes.html"><a href="poisson-processes.html#poisson-process-definition-2"><i class="fa fa-check"></i><b>5.4</b> Poisson process : Definition 2</a></li>
<li class="chapter" data-level="5.5" data-path="poisson-processes.html"><a href="poisson-processes.html#inter-arrival-times-inter-event-times-or-holding-times"><i class="fa fa-check"></i><b>5.5</b> Inter arrival times (Inter event times or holding times)</a></li>
<li class="chapter" data-level="" data-path="poisson-processes.html"><a href="poisson-processes.html#important-result"><i class="fa fa-check"></i>Important result</a></li>
<li class="chapter" data-level="5.6" data-path="poisson-processes.html"><a href="poisson-processes.html#superposition-and-thinning-properties"><i class="fa fa-check"></i><b>5.6</b> Superposition and thinning properties</a>
<ul>
<li class="chapter" data-level="" data-path="poisson-processes.html"><a href="poisson-processes.html#superposition-property"><i class="fa fa-check"></i>Superposition property</a></li>
<li class="chapter" data-level="" data-path="poisson-processes.html"><a href="poisson-processes.html#splitting-thinning-property"><i class="fa fa-check"></i>Splitting (Thinning) property</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="poisson-processes.html"><a href="poisson-processes.html#memorylessness"><i class="fa fa-check"></i><b>5.7</b> Memorylessness</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="tutorials.html"><a href="tutorials.html"><i class="fa fa-check"></i><b>6</b> Tutorials</a>
<ul>
<li class="chapter" data-level="6.1" data-path="tutorials.html"><a href="tutorials.html#tutorial-1"><i class="fa fa-check"></i><b>6.1</b> Tutorial 1</a></li>
<li class="chapter" data-level="6.2" data-path="tutorials.html"><a href="tutorials.html#tutorial-2"><i class="fa fa-check"></i><b>6.2</b> Tutorial 2</a></li>
<li class="chapter" data-level="6.3" data-path="tutorials.html"><a href="tutorials.html#tutorial-3"><i class="fa fa-check"></i><b>6.3</b> Tutorial 3</a></li>
<li class="chapter" data-level="6.4" data-path="tutorials.html"><a href="tutorials.html#tutorial-4"><i class="fa fa-check"></i><b>6.4</b> Tutorial 4</a></li>
<li class="chapter" data-level="6.5" data-path="tutorials.html"><a href="tutorials.html#tutorial-5"><i class="fa fa-check"></i><b>6.5</b> Tutorial 5</a></li>
<li class="chapter" data-level="6.6" data-path="tutorials.html"><a href="tutorials.html#tutorial-6"><i class="fa fa-check"></i><b>6.6</b> Tutorial 6</a></li>
<li class="chapter" data-level="6.7" data-path="tutorials.html"><a href="tutorials.html#tutorial-7"><i class="fa fa-check"></i><b>6.7</b> Tutorial 7</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>7</b> Applications</a>
<ul>
<li class="chapter" data-level="7.1" data-path="applications.html"><a href="applications.html#datacamp-light"><i class="fa fa-check"></i><b>7.1</b> DataCamp Light</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>8</b> Final words</a>
<ul>
<li class="chapter" data-level="8.1" data-path="final-words.html"><a href="final-words.html#datacamp-light-1"><i class="fa fa-check"></i><b>8.1</b> DataCamp Light</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">SCMA469 Actuarial Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tutorials" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> Tutorials</h1>
<div id="tutorial-1" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Tutorial 1</h2>
<ol style="list-style-type: decimal">
<li><p>Consider a random walk, <span class="math inline">\(S_n\)</span>, with <span class="math inline">\(S_0 = 0\)</span> and where each step is
normally distributed with mean 0 and variance 10.</p>
<ol style="list-style-type: decimal">
<li><p>What is the distribution of <span class="math inline">\(S_{10}\)</span>?</p></li>
<li><p>Calculate <span class="math inline">\(\Pr(S_{10} &lt; -10)\)</span>.</p></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>We have <span class="math inline">\(S_{10}\)</span> is a sum of
<span class="math inline">\(S_0\)</span> and the i.i.d random variables <span class="math inline">\(Z_i\)</span>, each distributed
normal distribution, <span class="math inline">\(Z_i \sim N(0,10)\)</span>. Moreover,
<span class="math display">\[\mathrm{E}[S_{10}] = \mathrm{E}[S_0 + \sum_{i=1}^{10} Z_i] = S_0 + \sum_{i=1}^{10} \mathrm{E}[Z_i] = 0\]</span>
and
<span class="math display">\[\mathrm{Var}[S_{10}] = \mathrm{Var}[S_0 + \sum_{i=1}^{10} Z_i] = \sum_{i=1}^{10} \mathrm{Var}[Z_i] = 100\]</span>
Therefore, the distribution of <span class="math inline">\(S_{10}\)</span> is normally distributed,
<span class="math inline">\(S_{10} \sim N(0,100)\)</span>.</p></li>
<li><p>From the previous result,
<span class="math display">\[\Pr(S_{10} &lt; -10) = \Pr(Z &lt; -1) = 0.1587.\]</span></p></li>
</ol></li>
<li><p>Suppose that the value of a commodity as a random walk, where each
day the change in price has mean $0.05 and variance $0.1. Use the
central limit theorem to estimate the probability that its value is
more than $6 after 100 days if the initial value is $0.50.</p>
<p><strong>Solution:</strong> We have <span class="math inline">\(S_{100}\)</span> is a sum of <span class="math inline">\(S_0\)</span> and the i.i.d
random variables <span class="math inline">\(Z_i\)</span> (each not need to be normal distribution), i.e. 
<span class="math display">\[ S_{100} = S_0 + \sum_{i=1}^{100} Z_i. \]</span> Moreover,
<span class="math display">\[\mathrm{E}[S_{100}] = \mathrm{E}[S_0 + \sum_{i=1}^{100} Z_i] = S_0 + \sum_{i=1}^{100} \mathrm{E}[Z_i] = 5.5\]</span>
and
<span class="math display">\[\mathrm{Var}[S_{100}] = \mathrm{Var}[S_0 + \sum_{i=1}^{100} Z_i] = \sum_{i=1}^{100} \mathrm{Var}[Z_i] = 10\]</span></p>
<p>The Central Limit Theorem implies that <span class="math inline">\(S_{100}\)</span> is approximately
normally distributed, <span class="math inline">\(S_{100} \sim N(5.5,10)\)</span>.</p>
<p><span class="math display">\[\Pr(S_{100} &gt; 6) = \Pr(Z &gt; 0.1581) = 1 -  \Pr(Z &lt; 0.1581)  = 1- 0.5628 = 0.4372.\]</span></p></li>
<li><p>For the random walk process as described in the lecture note,</p>
<ol style="list-style-type: decimal">
<li><p>Calculate <span class="math inline">\(\Pr(X_8 = 96 | X_0 = 100),\)</span></p></li>
<li><p>Calculate <span class="math inline">\(\Pr(X_1 = 99, X_8 = 96 | X_0 = 100),\)</span></p></li>
<li><p>Calculate <span class="math inline">\(\Pr(X_1 = 99, X_4 = 98, X_8 = 96 | X_0 = 100),\)</span></p></li>
<li><p>Calculate <span class="math inline">\(\Pr( X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100),\)</span></p></li>
<li><p>Given <span class="math inline">\(X_0 = 100\)</span>, calculate <span class="math inline">\(\mathrm{E}[X_5]\)</span>.</p></li>
<li><p>Write down the joint distribution of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_3\)</span> given
<span class="math inline">\(X_0 = 100\)</span>. (Hint: consider all possible sample paths)</p></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Here the price must increase on any 2 day(s) and decrease on any
6 day(s), not necessarily in that order. There are
<span class="math inline">\({ 8 \choose 2} = 28\)</span> different possibilities and each of these
has probability <span class="math inline">\(p^{2}(1-p)^{6}\)</span>. Therefore, the required
probability is
<span class="math display">\[\Pr(X_8 = 96 | X_0 = 100) =  28  p^{2}(1-p)^{6} .\]</span></p></li>
<li><p>The problem can be divided into two periods:</p>
<ul>
<li><p>The first period of 1 day(s): the price in this period must
increase on any 0 day(s) and decrease on any 1 day(s), not
necessarily in that order. There are <span class="math inline">\({ 1 \choose 0}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{0}(1-p)^{1}\)</span>.</p></li>
<li><p>The next period of 7 day(s): the price in this period must
increase on any 2 day(s) and decrease on any 5 day(s), not
necessarily in that order. There are <span class="math inline">\({ 7 \choose 2}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{2}(1-p)^{5}\)</span>.</p></li>
</ul>
<p>The required probability is
<span class="math display">\[\Pr(X_1 = 99, X_8 = 96 | X_0 = 100)  =  21  p^{2}(1-p)^{6} .\]</span></p></li>
<li><p>Similar to the previous problem, the required probability can be
calculated as follows:</p>
<p>The problem can be divided into three periods:</p>
<ul>
<li><p>The first period of 1 day(s): the price in this period must
increase on any 0 day(s) and decrease on any 1 day(s), not
necessarily in that order. There are <span class="math inline">\({ 1 \choose 0}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{0}(1-p)^{1}\)</span>.</p></li>
<li><p>The next period of 3 day(s): the price in this period must
increase on any 1 day(s) and decrease on any 2 day(s), not
necessarily in that order. There are <span class="math inline">\({ 3 \choose 1}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{1}(1-p)^{2}\)</span>.</p></li>
<li><p>The last period of 4 day(s): the price in this period must
increase on any 1 day(s) and decrease on any 3 day(s), not
necessarily in that order. There are <span class="math inline">\({ 4 \choose 1}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{1}(1-p)^{3}\)</span>.</p></li>
</ul>
<p>The required probability is <span class="math display">\[\Pr(X_1 = 99,
X_4 = 98, X_8 = 96 | X_0 = 100)  =  12  p^{2}(1-p)^{6} .\]</span></p></li>
<li><p>By Markov property, we have <span class="math display">\[\Pr(
X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100), 
= \Pr(
X_4 = 98, X_8 = 96 |X_1 = 99).\]</span> Again, the problem can be
divided into two periods:</p>
<ul>
<li><p>The first period of 3 day(s): the price in this period must
increase on any 1 day(s) and decrease on any 2 day(s), not
necessarily in that order. There are <span class="math inline">\({ 3 \choose 1}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{1}(1-p)^{2}\)</span>.</p></li>
<li><p>The next period of 4 day(s): the price in this period must
increase on any 1 day(s) and decrease on any 3 day(s), not
necessarily in that order. There are <span class="math inline">\({ 4 \choose 1}\)</span>
different possibilities and each of these has probability
<span class="math inline">\(p^{1}(1-p)^{3}\)</span>.</p></li>
</ul>
<p>The required probability is <span class="math display">\[\Pr(
X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100)
= \Pr(
X_4 = 98, X_8 = 96 |X_1 = 99)  =  12  p^{2}(1-p)^{5} .\]</span></p></li>
<li><p>The variable <span class="math inline">\(X_5\)</span> can take the values from
<span class="math inline">\(95, 97, 99, 101, 103, 105\)</span>. In particular,</p></li>
</ol></li>
</ol>
<p><span class="math display">\[\begin{aligned}
            \Pr(X_5 &amp;= 95) = {5 \choose 0} p^0 (1-p)^5 =  1 
        p^0 (1-p)^5    \\
            \Pr(X_5 &amp;= 97) = {5 \choose 1} p^1 (1-p)^4 = 5 
            p^1 (1-p)^4\\
            \Pr(X_5 &amp;= 99) = {5 \choose 2} p^2 (1-p)^3 = 10 
            p^2 (1-p)^3\\
            &amp;\vdots \\
            \Pr(X_5 &amp;= 105) = {5 \choose 5} p^5 (1-p)^0 = 1 
            p^5 (1-p)^0 \end{aligned}\]</span></p>
<pre><code>    Therefore, $\mathrm{E}[X_5] = 
     95 \cdot \left( 1 
    p^0 (1-p)^5 \right)
    + 97 \cdot \left(5 
    p^1 (1-p)^4 \right)
    + 99 \cdot \left(10 
    p^2 (1-p)^3 \right)
    + \cdots
    + 105 \cdot \left( 1 
        p^5 (1-p)^0 \right) = 95 + 10*x.$
  Alternatively, 
  </code></pre>
<p><span class="math display">\[\begin{aligned}
      E\left[X_{5}\right] &amp;=E\left[100+\sum_{i=1}^{5} Z_{i}\right] \\
      &amp;= 100+5 \cdot E\left[Z_{i}\right]  \\
      &amp;=100+ 5 (2 p-1)  \\
      &amp;=95 + 10p\end{aligned}\]</span>
where <span class="math inline">\(E\left[Z_{i}\right] = p-q = p - (1 - p) = 2p -1.\)</span></p>
<ol start="4" style="list-style-type: decimal">
<li><p>For each event,</p>
<ul>
<li><p>Identify a stochastic process <span class="math inline">\(\{ X_t : t \in T\}\)</span> and describe
<span class="math inline">\(X_t\)</span> in context.</p></li>
<li><p>Describe the time domain and state space. State whether the time
domain and state space are discrete or continuous.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Sociologists categorise the population of a country into upper-,
middle- and lower-class groups. One of the government offices
has monitored the movement of successive generations among these
three groups.</p></li>
<li><p>The insurer’s surplus (an excess of income or assets over
expenditure or liabilities in a given period) at any future time
which is defined as the initial surplus plus the premium income
up to time <span class="math inline">\(t\)</span> minus the aggregate claims up to time <span class="math inline">\(t\)</span>.</p></li>
<li><p>In a working day, a coffee shop owner records customer arrival
times.</p></li>
<li><p>The gambler starts with m and bets per game. The probability of
winning is <span class="math inline">\(p\)</span> and the probability of losing is <span class="math inline">\(q\)</span> where
<span class="math inline">\(p + q = 1\)</span>. In addition, the gambler is ruined (or goes broke)
if he reaches state 0, and also stops the game if he reaches
state <span class="math inline">\(N\)</span>.</p></li>
<li><p>In the board game Monopoly, there are 40 squares. A player is
interested to know the successive board position.</p></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(X_{n}\)</span> be the class of <span class="math inline">\(n^{\text {th }}\)</span> generation of a
family. The state space, <span class="math inline">\(S=\{\text {Upper, Middle, Lower} \}\)</span>,
is discrete. The index set, <span class="math inline">\(I=\{0,1,2, \ldots\}\)</span>, is also
discrete.</p></li>
<li><p>Let <span class="math inline">\(S(t)\)</span> be the insurer’s surplus at time <span class="math inline">\(t\)</span>.
<span class="math inline">\(S=\mathbb{R} \text { and } I=[0, \infty)\)</span>.</p></li>
<li><p>Let <span class="math inline">\(X_{n}\)</span> be the amount of money of the gambler after game
<span class="math inline">\(n\)</span>.</p>
<p><span class="math inline">\(S=\{0,1,2 \ldots, N\} \text { and } I=\{0,1,2 ,\ldots \}\)</span>.</p></li>
<li><p>Suppose that the opening hours of the coffee shop are from 7:00
am to 6:00 pm (i.e. 11 hours). Let <span class="math inline">\(X_{n}\)</span> be the arrival time
of customer <span class="math inline">\(n\)</span>. State space (continuous)</p>
<p><span class="math inline">\(S=[0,11 \times 60]=[0,660]\)</span> (in minutes) and
<span class="math inline">\(I=\{1,2, \ldots\}\)</span>.</p></li>
<li><p>Let <span class="math inline">\(x_{n}\)</span> be a player’s board position after <span class="math inline">\(n\)</span> plays.</p>
<p><span class="math inline">\(S=\{1,2,3, \ldots, 40\}\)</span> and <span class="math inline">\(I=\{0,1,2, \ldots \}.\)</span></p></li>
</ol></li>
<li><p>The simple weather pattern can be classified into three types
including rainy (<span class="math inline">\(R\)</span>), cloudy (<span class="math inline">\(C\)</span>) and sunny (<span class="math inline">\(S\)</span>). The weather is
observed daily. The following information is provided.</p>
<ul>
<li><p>On any given rainy day, the probability that it will rain the
next day is 0.7; the probability that it will be cloudy the next
day 0.2.</p></li>
<li><p>On any given cloudy day, the probability that it will rain the
next day is 0.75; the probability that it will be sunny the next
day 0.1.</p></li>
<li><p>On any given sunny day, the probability that it will rain the
next day is 0.2; the probability that it will be sunny the next
day 0.4.</p></li>
</ul>
<p>Explain how this may be modelled by a Markov chain.</p>
<p><strong>Solution:</strong> The three weather conditions describe the three state of
the Markov chain. Let <span class="math inline">\(X_{n}\)</span>be the weather condition on day <span class="math inline">\(n\)</span>.</p>
<ul>
<li><p>State 1 (R) rainy day</p></li>
<li><p>State 2 (C) cloudy day</p></li>
<li><p>State 3 (S) sunny day</p></li>
</ul>
<p>The transition probability matrix <span class="math inline">\(P\)</span> for this Markov chain is</p>
<p><span class="math display">\[P=\left[\begin{array}{lll}
0.7 &amp; 0.2 &amp; 0.1 \\
0.75 &amp; 0.15 &amp; 0.1 \\
0.2 &amp; 0.4 &amp; 0.4
\end{array}\right]\]</span></p>
<p>This stochastic process has the Morkov property because the weather
condition on the next day depends only on the condition today.</p></li>
<li><p>Explain whether an independent and identically distributed sequence
of random variables has a Markov property.</p>
<p><strong>Solution:</strong> Assume that
this Markov chain <span class="math inline">\(X_0, X_1, X_2 \ldots,\)</span> takes values in
<span class="math inline">\(\{1,2, \ldots, k\} \text { with }\)</span></p>
<p><span class="math display">\[P\left(X_{n}=j\right) = p_{j} \quad \text { for } j=1,2, \ldots, k \quad \text { and } n \geq 0 .\]</span>
Note that this equality holds for all <span class="math inline">\(n\)</span> because
<span class="math inline">\(\left\{X_{n} \right\}_{n \ge 0}\)</span> have the same distribution.</p>
<p>By independence,</p>
<p><span class="math display">\[P\left(x_{n}=j \mid x_{n-1}=i\right)=P\left(x_{n}=j\right)=p_{j},\]</span></p>
<p>This proves our claim that the i.i.d. sequence of random variables
has a Markov property. Note also that the transition matrix is
<span class="math display">\[P = 
\begin{bmatrix}
p_1 &amp; p_2 &amp; \cdots &amp; p_k \\
p_1 &amp; p_2 &amp; \cdots &amp; p_k \\
\vdots &amp; \vdots &amp;  &amp; \vdots \\
p_1 &amp; p_2 &amp; \cdots &amp; p_k \\
\end{bmatrix}.\]</span></p></li>
<li><p>The random variables <span class="math inline">\(Z_1, Z_2, \ldots\)</span> are independent and with the
common probability mass function <span class="math display">\[Z_i = \begin{cases}
    1, &amp; \text{ with probability }  0.2 \\
    2, &amp; \text{ with probability }  0.3 \\  
    3, &amp; \text{ with probability }  0.4 \\  
    4, &amp; \text{ with probability }  0.1 \\  
 \end{cases}\]</span> Let <span class="math inline">\(X_0 = 1\)</span> and
<span class="math inline">\(X_n = \max\{Z_1, Z_2, \ldots, Z_n \}\)</span> be the largest <span class="math inline">\(Z\)</span> observed
to date. Explain how this may be modelled by a Markov chain.
<strong>Solution:</strong></p>
<p>Given <span class="math inline">\(X_{0}=1\)</span> and
<span class="math inline">\(X_{n}=\max \left\{Z_{1}, Z_{2}, \ldots, Z_{n}\right\}\)</span> where
<span class="math inline">\(\left\{Z_{i}\right\}\)</span> are i.i.d. random variables with</p>
<table>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(i\)</span></th>
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
<th align="left">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(P(Z_i = i)\)</span></td>
<td align="left">0.2</td>
<td align="left">0.3</td>
<td align="left">0.4</td>
<td align="left">0.1</td>
</tr>
</tbody>
</table>
<p>We note that</p></li>
</ol>
<p><span class="math display">\[\begin{aligned}
    X_{n+1} &amp;=\operatorname{max}\left\{Z_{1}, Z_{2}, \ldots, Z_{n+1}\right\} \\
    &amp;=\operatorname{max}\left\{X_{n}, Z_{n+1}\right\}
    \end{aligned}\]</span> Consider the transition probabilities</p>
<pre><code>$$\begin{aligned}
P\left(X_{n+1} = j \mid X_{n}=i \right) &amp;= P\left(\max \left\{X_{n}, Z_{n+1}\right\}=j \mid X_{n}=i\right) \\
&amp;=P\left(\max \left\{i, Z_{n+1}\right\}=j \mid X_{n}=i\right)
\end{aligned}$$

**Case 1:** If $i=1$, then $$\max \left\{1, Z_{n+1}\right\}= 
\begin{cases}
1  &amp; \text{w.p. } 0.2 \\
2 &amp; \text{w.p. } 0.3 \\
3  &amp; \text{w.p. } 0.4 \\
4  &amp; \text{w.p. } 0.1 \\
\end{cases}$$

**Case 2:** If $i=2$, then $$\max \left\{2, Z_{n+1}\right\}= 
\begin{cases}
1  &amp; \text{w.p. } 0 \\
2 &amp; \text{w.p. } 0.5 \quad (\text{i.e. } z_{n+1} = 1 \text{ or } 2  )\\
3  &amp; \text{w.p. } 0.4 \\
4  &amp; \text{w.p. } 0.1 \\
\end{cases}$$

**Case 3:** If $i=3$, then $$\max \left\{3, Z_{n+1}\right\}= 
\begin{cases}
1  &amp; \text{w.p. } 0 \\
2 &amp; \text{w.p. } 0 \\
3  &amp; \text{w.p. } 0.9 \\
4  &amp; \text{w.p. } 0.1 \\
\end{cases}$$

**Case 4:** If $i=4$, then $$\max \left\{4, Z_{n+1}\right\}= 
\begin{cases}
1  &amp; \text{w.p. } 0 \\
2 &amp; \text{w.p. } 0 \\
3  &amp; \text{w.p. } 0 \\
4  &amp; \text{w.p. } 1 \\
\end{cases}$$ The transition probability matrix is then

$$P = 
\begin{bmatrix}
0.2 &amp; 0.3 &amp; 0.4 &amp; 0.1 \\
0 &amp; 0.5 &amp; 0.4 &amp; 0.1 \\
0 &amp; 0 &amp; 0.9 &amp; 0.1 \\
0 &amp; 0 &amp; 0 &amp; 0.1 \\
\end{bmatrix}.$$ Clearly the sequence $X_0, X_1, X_2,\ldots$ can be
modelled by the Markov chain with the transition probability matrix
$P$. Moreover, given the most recent value $X_n$, its future value
$X_{n+1}$ is independent of the past history
$X_0, X_1, \ldots, X_{n-1}$.</code></pre>
</div>
<div id="tutorial-2" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Tutorial 2</h2>
<ol style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on states <span class="math inline">\(1, 2, 3\)</span> has the
following transition matrix <span class="math display">\[P = \begin{bmatrix}
    0.5 &amp; 0.3 &amp; 0.2    \\
    0.2 &amp; 0.2 &amp; 0.6  \\
    0.3 &amp; 0.2 &amp; 0.5    \\
\end{bmatrix}.\]</span> The distribution of the initial random variable
<span class="math inline">\(X_0\)</span> is <span class="math inline">\(\boldsymbol{\mu} = (0.3, 0.3, 0.4)\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_0 = 1, X_1 = 2, X_2 = 3).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_1 = 2, X_2 = 3 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 3 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_3 = 3 | X_1 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 3).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\mathrm{E}[X_2]\)</span></p></li>
</ol></li>
</ol>
<p><strong>Solutions:</strong></p>
<ol style="list-style-type: decimal">
<li><p>The transition diagram for the chain is shown in the figure below:
<img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p></li>
<li><p><span class="math inline">\(\Pr(X_0 = 1, X_1 = 2, X_2 = 3) = \mu_1 p_{12} p_{23} = (0.3)(0.3)(0.6) = 0.054.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_1 = 2, X_2 = 3 | X_0 = 1) = p_{12} p_{23} = (0.3)(0.6) = 0.18.\)</span></p></li>
<li><p>From the time homogeneous assumption, it follows that <span class="math display">\[\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1) = \Pr(X_1 = 2, X_2 = 3 | X_0 = 1) = 0.18.\]</span></p></li>
<li><p><span class="math inline">\(\Pr(X_2 = 3 | X_0 = 1) = (P^2)_{13} = 0.38.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_3 = 3 | X_1 = 1) = \Pr(X_2 = 3 | X_0 = 1) = (P^2)_{13} = 0.38.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_2 = 3) = (\boldsymbol{\mu}P^2)_3 = 0.424.\)</span></p></li>
<li><p><span class="math inline">\(\mathrm{E}[X_2] = \sum_{k=1}^3 k \Pr(X_2 = k) = (1, 2, 3) \cdot (0.343, 0.233, 0.424) = 2.081.\)</span></p></li>
</ol>
<p>Note that</p>
<pre><code>## P^2 
##  A  3 - dimensional discrete Markov Chain defined by the following states: 
##  1, 2, 3 
##  The transition matrix  (by rows)  is defined as follows: 
##      1    2    3
## 1 0.37 0.25 0.38
## 2 0.32 0.22 0.46
## 3 0.34 0.23 0.43</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on states 1,2,3 has the
following transition matrix <span class="math display">\[P = \begin{bmatrix}
    0 &amp; 1/2 &amp; 1/2   \\
    1/3  &amp; 1/3  &amp; 1/3   \\
    1/2  &amp; 1/2  &amp; 0    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span>
The process starts in states <span class="math inline">\(X_0 = 1\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_0 = 1, X_1 = 3, X_2 = 2).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_1 = 3, X_2 = 2 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 2 | X_0 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_3 = 2 | X_1 = 1).\)</span></p></li>
<li><p>Determine <span class="math inline">\(\Pr(X_2 = 2).\)</span></p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>The transition diagram for the chain is shown in the figure below:
<img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p></li>
<li><p><span class="math inline">\(\Pr(X_0 = 1, X_1 = 3, X_2 = 2) = \mu_1 p_{13} p_{32} = (1)(1/2)(1/2) = 1/4.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_1 = 3, X_2 = 2 | X_0 = 1) = p_{13} p_{32} = (1/2)(1/2) = 1/4.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_2 = 2 | X_0 = 1) = (P^2)_{12} = 5/12.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_3 = 2 | X_1 = 1) = \Pr(X_2 = 2 | X_0 = 1) = (P^2)_{12} = 5/12.\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_2 = 2) = (\boldsymbol{\mu}P^2)_2 = 5/12.\)</span></p></li>
</ol>
<p>Note that</p>
<pre><code>## P^2 
##  A  3 - dimensional discrete Markov Chain defined by the following states: 
##  1, 2, 3 
##  The transition matrix  (by rows)  is defined as follows: 
##           1         2         3
## 1 0.4166667 0.4166667 0.1666667
## 2 0.2777778 0.4444444 0.2777778
## 3 0.1666667 0.4166667 0.4166667</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on sates 1,2 has the following
transition matrix <span class="math display">\[P = \begin{bmatrix}
    1-a &amp; a   \\
    b &amp; 1-b   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix},\]</span> where <span class="math inline">\(0 &lt; a,b &lt; 1.\)</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>the distribution of <span class="math inline">\(X_1\)</span>.</p></li>
<li><p>Show that <span class="math display">\[P^n = \frac{1}{a+b} \begin{bmatrix}
    b &amp; a   \\
    b &amp; a   \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix} +
\frac{(1-a-b)^n}{a+b} \begin{bmatrix}
    a &amp; -a   \\
    -b &amp; b   \\
\end{bmatrix}.\]</span></p></li>
<li><p>Given that <span class="math inline">\(X_0 = 1\)</span>, what is the probability that in the long
run the system will be in state 1? (Hint: consider
<span class="math inline">\(\lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n\)</span>)</p></li>
<li><p>Given that <span class="math inline">\(X_0 = 1\)</span>, what is the probability that in the long
run the system will be in state 2?</p></li>
<li><p>Given that <span class="math inline">\(X_0 = 2\)</span>, what is the probability that in the long
run the system will be in state 1?</p></li>
<li><p>Given that <span class="math inline">\(X_0 = 2\)</span>, what is the probability that in the long
run the system will be in state 2?</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Leave it to the reader.</p></li>
<li><p>Denote <span class="math inline">\(\boldsymbol{\mu} = (\mu_1, \mu_2)\)</span> the initial probability distribution. Then the distribution of <span class="math inline">\(X_1\)</span> is <span class="math inline">\(\boldsymbol{\mu}^{(1)} = \boldsymbol{\mu} P = (\mu_1(1-a) + \mu_2 b, \mu_1 a + \mu_2(1-b))\)</span></p></li>
<li><p>We apply eigendecomposition of a matrix. For more details, please follow this link from Wikipedia <a href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix">link</a>.</p></li>
</ol>
<p>The eigenvalues of <span class="math inline">\(P\)</span> are <span class="math inline">\(\lambda_1 = 1\)</span> and <span class="math inline">\(\lambda_2 = 1 - a -b\)</span> and the corresponding eigenvectors are
<span class="math display">\[v_1 = \begin{bmatrix}
            1   \\
            1   \\
         \end{bmatrix}, \quad
         v_2 = \begin{bmatrix}
            -a/b   \\
            1   \\
         \end{bmatrix}.
    \]</span><br />
Then the transition matrix can be factorised as
<span class="math display">\[P = \begin{bmatrix}
            1 &amp; -a/b \\
            1 &amp; 1 \\
         \end{bmatrix}
         \begin{bmatrix}
            1 &amp; 0   \\
            0 &amp; 1 - a - b   \\
        \end{bmatrix}
        \begin{bmatrix}
            1 &amp; -a/b \\
            1 &amp; 1 \\
         \end{bmatrix}^{-1}.
    \]</span><br />
Hence</p>
<p><span class="math display">\[\begin{aligned}
      P^n &amp;= \left( \begin{bmatrix}
            1 &amp; -a/b \\
            1 &amp; 1 \\
         \end{bmatrix}
         \begin{bmatrix}
            1 &amp; 0   \\
            0 &amp; (1 - a - b)^n   \\
        \end{bmatrix} \right)
        \begin{bmatrix}
            1 &amp; -a/b \\
            1 &amp; 1 \\
         \end{bmatrix}^{-1}  \\
         &amp;= \begin{bmatrix}
            1 &amp; -\frac{a}{b}(1 - a - b)^n \\
            1 &amp; (1 - a - b)^n \\
         \end{bmatrix} 
         \left(
         \frac{1}{1 + a/b}
         \begin{bmatrix}
            1 &amp; a/b \\
            -1 &amp; 1 \\
         \end{bmatrix}
         \right)  \\
         &amp;= \frac{1}{a+b}
         \begin{bmatrix}
         b + a(1 - a - b)^n &amp; a - a(1 - a - b)^n \\
         b - b(1 - a - b)^n &amp; a + b(1 - a - b)^n
         \end{bmatrix} \\
         &amp;= \frac{1}{a+b}
         \begin{bmatrix}
         b &amp; a \\
         b &amp; a
         \end{bmatrix} +
         \frac{(1 - a - b)^n}{a+b}
         \begin{bmatrix}
         a &amp; -a \\
         -b &amp; b
         \end{bmatrix}
         \end{aligned}.
         \]</span>
Note that <span class="math display">\[\lim_{n \rightarrow \infty} P^n = 
         \frac{1}{a+b}
         \begin{bmatrix}
         b &amp; a \\
         b &amp; a
         \end{bmatrix}, \]</span>
which follows from the facts that <span class="math inline">\(-1 &lt; 1 -a -b &lt; 1\)</span> and <span class="math inline">\((1- a-b)^n \rightarrow 0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>.</p>
<ol start="4" style="list-style-type: decimal">
<li><p>It follows from the above results that in the long run
<span class="math display">\[ \lim_{n \rightarrow \infty} \Pr(X_n = 1| X_0 = 1) = (\lim_{n \rightarrow \infty} P^n)_{11} = \frac{b}{a+b}. \]</span></p></li>
<li><p>In the long run, we have
<span class="math display">\[ \lim_{n \rightarrow \infty} \Pr(X_n = 2| X_0 = 1) = (\lim_{n \rightarrow \infty} P^n)_{12} = \frac{a}{a+b}. \]</span></p></li>
<li><p>In the long run, we have
<span class="math display">\[ \lim_{n \rightarrow \infty} \Pr(X_n = 1| X_0 = 2) = (\lim_{n \rightarrow \infty} P^n)_{21} = \frac{b}{a+b}. \]</span></p></li>
<li><p>In the long run, we have
<span class="math display">\[ \lim_{n \rightarrow \infty} \Pr(X_n = 2| X_0 = 2) = (\lim_{n \rightarrow \infty} P^n)_{22} = \frac{a}{a+b}. \]</span></p></li>
</ol>
<p>Furthermore, for any initial distribution <span class="math inline">\(\boldsymbol{\mu}\)</span>, the limiting distribution with this initial distribution is
<span class="math display">\[ \lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n  = (\frac{b}{a+b}, \frac{a}{a+b}).\]</span>
This gives the long term proportion of the Markov chain, i.e. the probability of finding the process in state 1 is <span class="math inline">\(\frac{b}{a+b}\)</span> and in state 2 is <span class="math inline">\(\frac{a}{a+b}\)</span>, irrespective of the stating state.</p>
<ol start="4" style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(a\)</span> be a constant and <span class="math inline">\(\xi_1, \xi_2, \ldots\)</span> be a sequence of
independent and identically distributed (i.i.d.) random variables.
The stochastic process <span class="math inline">\(\{ X_n\}\)</span> is defined by
<span class="math display">\[X_0 = a, \quad X_n = X_{n-1} + \xi_n, \, n &gt; 1.\]</span> This process is
known as a random walk.</p>
<ol style="list-style-type: decimal">
<li><p>Express the state <span class="math inline">\(X_n\)</span> in terms of <span class="math inline">\(X_0\)</span> and the random
variables <span class="math inline">\(\xi_i, i = 1,2 \ldots\)</span>.</p></li>
<li><p>Find <span class="math inline">\(\mathrm{E}[X_n]\)</span> and <span class="math inline">\(\mathrm{Var}[X_n]\)</span>.</p></li>
<li><p>Does the process have the Markov property? Explain.</p></li>
<li><p>Is the process stationary? Explain.</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>From the definition, it follows that
<span class="math display">\[
\begin{aligned}
X_0 &amp;= a \\
X_1 &amp;= X_0 + \xi_1 = a + \xi_1 \\
X_2 &amp;= X_1 + \xi_2 = a + \xi_1 + \xi_2 \\
    &amp;\vdots \\
X_n &amp;= X_{n-1} + \xi_n = a + \sum_{i=1}^n \xi_i, \quad n \ge 1.
\end{aligned}
\]</span></p></li>
<li><p>Let <span class="math inline">\(\mu = \mathrm{E}[\xi_i]\)</span> and <span class="math inline">\(\sigma^2 = \mathrm{Var}[\xi_i]\)</span> denote the mean and variance of the increments <span class="math inline">\(\xi_i\)</span>. Then
<span class="math display">\[
\begin{aligned}  
\mathrm{E}[X_n] &amp;= \mathrm{E}\left[a + \sum_{i=1}^n \xi_i\right] = a+ \sum_{i=1}^n \mathrm{E}[\xi_i] = a + n \mu, \\
\mathrm{Var}[X_n] &amp;= \mathrm{Var}\left[a + \sum_{i=1}^n \xi_i\right] =  \sum_{i=1}^n \mathrm{Var}[\xi_i] =  n \sigma^2.
\end{aligned}
\]</span>
The last equality follows from the assumption that <span class="math inline">\(\xi_1, \xi_2, \ldots\)</span> are independent.</p></li>
<li><p>The process <span class="math inline">\(\{X_n\}_{n\ge0}\)</span> has independent increments and , hence, has the Markov
property. More details can be found from the lecture note <a href="https://pairote-sat.github.io/SCMA469/discrete-time-markov-chains.html">link</a>.</p></li>
<li><p>The process is <strong>not</strong> stationary because <span class="math inline">\(\mathrm{E}[X_n]\)</span> is not constant and <span class="math inline">\(\mathrm{Var}[X_n]\)</span> also depends on <span class="math inline">\(n\)</span>.</p></li>
<li><p>Consider a homogeneous discrete-time Markov chain that describes the
daily weather pattern. The weather patterns are classified into 3
conditions: R(rainy), C (cloudy) and S(sunny). Based on the daily
observations, the following information are given:</p>
<ul>
<li><p>On any rainy day, the probability that it will rain the next day
is 0.7; the probability that tomorrow will be cloudy is 0.2 and
the probability that tomorrow will be sunny is 0.1.</p></li>
<li><p>On any cloudy day, the probability that it will rain the next
day is 0.5; the probability that tomorrow will be cloudy is 0.35
and the probability that tomorrow will be sunny is 0.15.</p></li>
<li><p>On any sunny day, the probability that it will rain the next day
is 0.1; the probability that tomorrow will be cloudy is 0.4 and
the probability that tomorrow will be sunny is 0.5.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain and write down a
transition matrix.</p></li>
<li><p>Find the probability that tomorrow is cloudy and the day after
is rainy, given that it is sunny today.</p></li>
<li><p>Given that today is rainy, find the probability that it will be
sunny in two days time.</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li>The transition matrix <span class="math inline">\(P\)</span> and the transition diagram are given in the results below :</li>
</ol>
<pre><code>## P 
##  A  3 - dimensional discrete Markov Chain defined by the following states: 
##  R, C, S 
##  The transition matrix  (by rows)  is defined as follows: 
##     R    C    S
## R 0.7 0.20 0.10
## C 0.5 0.35 0.15
## S 0.1 0.40 0.50</code></pre>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<ol start="2" style="list-style-type: decimal">
<li><p>The probability that tomorrow is cloudy and the day after is rainy, given that it is sunny today is
<span class="math display">\[ \Pr(X_1 = C, X_2 = R | X_0 = S) = (0.4)(0.5) = 0.2.\]</span></p></li>
<li><p>Given that today is rainy, the probability that it will be sunny in two days time is
<span class="math display">\[ \Pr(X_2 = S | X_0 = R) = (P^2)_{13} = 0.15.\]</span></p></li>
</ol>
</div>
<div id="tutorial-3" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Tutorial 3</h2>
<ol style="list-style-type: decimal">
<li><p>A Markov chain <span class="math inline">\(X_0, X_1, \ldots\)</span> on states 1, 2, 3 with initial
distribution <span class="math inline">\(\boldsymbol{\mu} = (1/4,1/4,1/2)\)</span>. It has the
following transition matrix <span class="math display">\[P = \begin{bmatrix}
    1/2 &amp; 1/4 &amp; 1/4   \\
    1/3  &amp; 1/3  &amp; 1/3   \\
    1/5  &amp; 2/5  &amp; 2/5    \\
    %\vdots &amp; \vdots &amp; \vdots  &amp; \vdots \\
    %p_{d1} &amp; p_{d2} &amp; p_{d3} &amp; \dots  &amp; p_{dn}
\end{bmatrix}.\]</span> Compute the following probabilities:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_0 = 3, X_1 = 2 , X_2 = 1).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_1 = 3, X_2 = 2 , X_3 = 1).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(X_{1} = 2, X_{3} = 2, X_{5} = 2).\)</span></p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<pre><code>1.  We have  </code></pre>
<p><span class="math inline">\(\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1) = p_{11} p_{12} p_{23} = (1/2)(1/4)(1/3) = 1/24.\)</span></p>
<pre><code>2.  We have  </code></pre>
<p><span class="math inline">\(\Pr(X_0 = 3, X_1 = 2, X_2 = 1) = \mu_3 p_{32} p_{21} = (0.5)(2/5)(1/3) = 1/15.\)</span></p>
<pre><code>3.  We have </code></pre>
<p><span class="math display">\[\begin{aligned} \Pr(X_1 = 3, X_2 = 2, X_3 = 1) &amp;= 
\sum_{i=1}^{3} \Pr(X_0 = i) \Pr(X_1 = 3, X_2 = 2, X_3 = 1 | X_0 = i) \\ 
&amp;= \sum_{i=1}^{3} \mu_i p_{i3} p_{32} p_{21} \\
&amp;=  \left( \sum_{i=1}^{3} \mu_i p_{i3} \right) p_{32} p_{21}  \\
&amp;= (\boldsymbol{\mu}P)_3 p_{32} p_{21}\\
&amp;= (83/240)(2/5)(1/3) \\
&amp;= 83/1800  =  0.0461111.
\end{aligned}\]</span></p>
<pre><code>4. We have </code></pre>
<p><span class="math display">\[\begin{aligned} \Pr(X_1 = 2, X_3 = 2, X_5 = 2) &amp;= 
\sum_{i=1}^{3} \Pr(X_0 = i) \Pr(X_1 = 2, X_3 = 2, X_5 = 2 | X_0 = i) \\ 
&amp;= \sum_{i=1}^{3} \mu_i p_{i2} p^{(2)}_{22} p^{(2)}_{22} \\
&amp;=  \left( \sum_{i=1}^{3} \mu_i p_{i2} \right) p^{(2)}_{22} p^{(2)}_{22}  \\
&amp;= (\boldsymbol{\mu}P)_2 p^{(2)}_{22} p^{(2)}_{22}\\
&amp;= (83/240)(59/180)(59/180) \\
&amp;= 9356/251805 = 0.0371557.
\end{aligned}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p>A Markov chain with state space <span class="math inline">\(S = \{1,2,3,4,5,6\}\)</span> has the
following transition matrix: <span class="math display">\[P = \begin{bmatrix}
1/4 &amp; 0 &amp; 3/4 &amp; 0 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 1/2 &amp; 0 &amp; 0 &amp; 1/2  \\
1/5 &amp; 1/5 &amp; 1/5 &amp; 0 &amp; 1/5 &amp; 1/5   \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0  \\
1/3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2/3  \\
\end{bmatrix}.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram.</p></li>
<li><p>Identify the communication classes and classify them as closed
or non-closed.</p></li>
<li><p>Is the Markov chain irreducible?</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<pre><code>1. The transition diagram is shown in the figure below:</code></pre>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre><code>2. There are two closed classes </code></pre>
<p><span class="math inline">\(C^1 = \{1, 3, 6\}\)</span> and <span class="math inline">\(C^2 = \{5\}\)</span> because</p>
<ul>
<li><p><span class="math inline">\(p_{55} = 1\)</span> and</p></li>
<li><p><span class="math inline">\(1 \rightarrow 3 \rightarrow 6 \rightarrow 1\)</span>, and hence <span class="math inline">\(1, 3, 6\)</span> are in the same communication class. In addition, for each <span class="math inline">\(i \in C^1\)</span>, <span class="math inline">\(\sum_{j \in C^1} p_{ij} = 1\)</span>, which implies that escaping from <span class="math inline">\(C^1\)</span> is impossible. Therefore <span class="math inline">\(C^1\)</span> is a closed class.</p>
<p>There is one non-closed class <span class="math inline">\(O = \{2, 4\}\)</span>. This is because <span class="math inline">\(2 \leftrightarrow 4\)</span> and <span class="math inline">\(p_{43} &gt;0\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li>The Markov chain is reducible because it contains more than one communication classes.</li>
</ol></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>For each of the Markov chains whose
transition matrix is given below, identify the closed classes and
the vector of absorption probabilities associated with each of these
closed classes. Assume that the states are labelled <span class="math inline">\(1,2,3 \ldots\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math display">\[\begin{bmatrix}
        1/6 &amp; 0 &amp; 1/3 &amp; 1/2      \\
        0 &amp; 1/3 &amp; 2/3 &amp; 0   \\
    1/2 &amp; 1/2 &amp; 0 &amp; 0     \\    
    0 &amp; 0 &amp; 1/4 &amp; 3/4     \\
\end{bmatrix}.\]</span></p></li>
<li><p><span class="math display">\[\begin{bmatrix}
        0 &amp; 1/4 &amp; 3/4 &amp; 0      \\
        0 &amp; 1/3 &amp; 0 &amp; 2/3   \\
    1/3 &amp; 0 &amp; 1/3 &amp; 1/3     \\  
    0 &amp; 0 &amp; 0 &amp; 1     \\
\end{bmatrix}.\]</span></p></li>
<li><p><span class="math display">\[\begin{bmatrix}
       1/4 &amp; 1/4 &amp; 1/4 &amp; 1/4      \\
       0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
       0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
   0 &amp; 0 &amp; 0 &amp; 1     \\
     \end{bmatrix}.\]</span></p></li>
<li><p><span class="math display">\[\begin{bmatrix}
       0 &amp; 0 &amp; 0 &amp; 1/2  &amp; 0 &amp; 0 &amp; 1/2   \\
       1/6 &amp; 0 &amp; 1/6 &amp; 0  &amp; 0 &amp; 1/6 &amp; 1/2 \\
   0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0    \\ 
       1/2 &amp; 0 &amp; 0 &amp; 1/2  &amp; 0 &amp; 0 &amp; 0   \\
   1/4 &amp; 1/4 &amp; 0 &amp; 0  &amp; 0 &amp; 0 &amp; 1/2 \\
   0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0    \\ 
       1/2 &amp; 0 &amp; 0 &amp; 0  &amp; 0 &amp; 0 &amp; 1/2   \\
     \end{bmatrix}.\]</span></p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<pre><code>1. Every two states communicate, so </code></pre>
<p><span class="math inline">\(\{1, 2, 3, 4 \}\)</span> is a single closed class (since <span class="math inline">\(1 \rightarrow 4 \rightarrow 3 \rightarrow 2 \rightarrow 3 \rightarrow 1\)</span>). The absorption probabilities are 1, since each state is in this closed class. The transition diagram is shown in the figure below:</p>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<pre><code>2. There are two non-closed classes </code></pre>
<p><span class="math inline">\(O^1 = \{1, 3\}\)</span> and <span class="math inline">\(O^2 = \{2\}\)</span> and a closed class
<span class="math inline">\(C^1 = \{4\}\)</span>. Since we have a single closed class, all absorption probabilities to this closed class <span class="math inline">\(C^1 = \{4\}\)</span> are equal to 1. The transition diagram is shown in the figure below:</p>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<pre><code>3. There are two closed classes </code></pre>
<p><span class="math inline">\(C^1 = \{2, 3\}\)</span> and <span class="math inline">\(C^2 = \{4\}\)</span> and a non-closed class
<span class="math inline">\(O^1 = \{1\}\)</span>. The transition diagram is shown in the figure below:</p>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Let
<span class="math inline">\(\mathbf{u}=\mathbf{u}^{C_{2}}\)</span> be the vector of absorption
probabilities in the closed class <span class="math inline">\(C^2 = \{4\}\)</span>. Write
<span class="math inline">\(\mathbf{u}= (u_1,u_2,u_3,u_4)^T\)</span> and <span class="math inline">\(u_4 = 1\)</span> and <span class="math inline">\(u_2 = u_3 =0\)</span>,</p>
<p>From <span class="math inline">\(\mathbf{u}=P \cdot \mathbf{u}\)</span>,</p>
<p><span class="math display">\[\left(\begin{array}{c}u_{1} \\ u_{2} \\  u_{3} \\ u_{4}\end{array}\right)=\begin{bmatrix}
                1/4 &amp; 1/4 &amp; 1/4 &amp; 1/4      \\
                0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
                0 &amp; 3/4 &amp; 1/4 &amp; 0   \\
            0 &amp; 0 &amp; 0 &amp; 1     \\
        \end{bmatrix} \left(\begin{array}{c}u_{1} \\ u_{2} \\  u_{3} \\ u_{4}\end{array}\right) \text { gives}\]</span>
<span class="math display">\[ u_1 = \frac{1}{4} u_1 + \frac{1}{4}\]</span> Solving the
linear system for <span class="math inline">\(u_1\)</span> yields <span class="math inline">\(u_1 = 1/3\)</span>.
Hence, the absorption probabilities in the closed class <span class="math inline">\(C_2\)</span> is
<span class="math display">\[\mathbf{u}= (1/3,0,0,1)^T.\]</span>
In addition, since there are two closed classes,
<span class="math inline">\(\mathbf{u}^{C_1} = \mathbf{1} - \mathbf{u}^{C_2} = (2/3,1,1,0)^T.\)</span></p>
<pre><code>4. There are two closed classes </code></pre>
<p><span class="math inline">\(C^1 = \{1, 4, 7\}\)</span> and <span class="math inline">\(C^2 = \{3\}\)</span> and two non-closed classes
<span class="math inline">\(O^1 = \{2, 6\}\)</span> and <span class="math inline">\(O^2 = \{5\}\)</span>. The transition diagram is shown in the figure below:</p>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Let
<span class="math inline">\(\mathbf{u}=\mathbf{u}^{C_{2}}\)</span> be the vector of absorption
probabilities in the closed class <span class="math inline">\(C^2 = \{3\}\)</span>. Write
<span class="math inline">\(\mathbf{u}= (u_1,u_2,u_3,\ldots, u_7)^T\)</span> and <span class="math inline">\(u_3 = 1\)</span> and <span class="math inline">\(u_1 = u_4 = u_7 =0\)</span>,</p>
<p><span class="math display">\[\left(\begin{array}{c}u_{1} \\ u_{2} \\ \vdots \\ u_{7}\end{array}\right)=P\left(\begin{array}{c}u_{1} \\ u_{2} \\ \vdots \\ u_{7}\end{array}\right) \text{ gives}\]</span>
<span class="math display">\[\begin{aligned}
    u_2 &amp;= \frac{1}{6}  + \frac{1}{6} u_6 \\
    u_5 &amp;=   \frac{1}{4} u_2\\
    u_6 &amp;=   u_2.\\   \end{aligned}\]</span>
Solving the linear system for <span class="math inline">\(u_2, u_5\)</span> and <span class="math inline">\(u_6\)</span> yields <span class="math inline">\(u_2 = 1/5, u_5 = 1/20\)</span> and <span class="math inline">\(u_6 = 1/5\)</span>.
Hence, the absorption probabilities in the closed class <span class="math inline">\(C_2\)</span> is
<span class="math display">\[\mathbf{u}= (0,1/5,1,0,1/20,1/5,0)^T.\]</span>
In addition, since there are two closed classes,
<span class="math inline">\(\mathbf{u}^{C_1} = \mathbf{1} - \mathbf{u}^{C_2} = (1,4/5,0,1,19/20,4/5,1)^T.\)</span></p>
<ol start="4" style="list-style-type: decimal">
<li>If the Markov chain defined in Question 3 is irreducible,
i.e. it has a unique stationary distribution, then find the
stationary distribution of the chain.</li>
</ol>
<p><strong>Solution:</strong></p>
<p>The only irreducible Markov chain is 3.1.</p>
<p>Denote the stationary probability distribution by
<span class="math inline">\(\boldsymbol{\pi} = (\pi_1, \pi_2, \pi_3, \pi_4)\)</span>.</p>
<p>To find the stationary distribution, we simply solve the linear
equations <span class="math inline">\(\boldsymbol{\pi} P =\boldsymbol{\pi}\)</span> (note that one of the
equations can be discarded), together with the condition
<span class="math inline">\(\sum_{j \in S} \pi_j = 1\)</span>.</p>
<p>By discarding the third quation, we obtain</p>
<p><span class="math inline">\(\pi_1 + \pi_2 + \pi_3 + \pi_4 = 1\)</span>,
<span class="math display">\[(\pi_1,  \pi_2, \pi_3, \pi_4)  \begin{bmatrix}
                1/6 &amp; 0 &amp; 1/3 &amp; 1/2      \\
                0 &amp; 1/3 &amp; 2/3 &amp; 0   \\
            1/2 &amp; 1/2 &amp; 0 &amp; 0     \\    
            0 &amp; 0 &amp; 1/4 &amp; 3/4     \\
        \end{bmatrix} =  (\pi_1,  \pi_2, \pi_3, \pi_4),\]</span> which is equivalent to
<span class="math display">\[\begin{aligned}
(1/6)\pi_1 + (1/2)\pi_3 &amp;= \pi_1 \\
(1/3)\pi_2 + (1/2)\pi_3 &amp;= \pi_2 \\
(1/2)\pi_1 + (3/4)\pi_4 &amp;= \pi_4 \\
\pi_1 +   \pi_2 +  \pi_3 + \pi_4&amp;= 1 \end{aligned}\]</span></p>
<p>Solving the above system of linear equations, we obtain
<span class="math inline">\(\pi_1, \pi_2, \pi_3\)</span>:
<span class="math display">\[\pi_1 = \frac{12}{71},  \quad \pi_2 = \frac{15}{71},  \quad \pi_3 = \frac{20}{71}, \quad \pi_4 = \frac{24}{71}.\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li><p>Assume that a Markov chain has more than one closed classes (say <span class="math inline">\(r\)</span>
closed classes). The Markov chain can <strong>have many stationary
distributions</strong>. Assume further that within each of these <span class="math inline">\(r\)</span> closed
classes, the associated Markov chain is aperiodic. The followings
hold:</p>
<ul>
<li><p>Within a closed class <span class="math inline">\(C_1\)</span>, let <span class="math inline">\(P_1\)</span> be a reduction of a
matrix <span class="math inline">\(P\)</span> which is formed by deleting all rows and columns
corresponding to states from other classes. Then there exists a
unique stationary distribution, denoted by
<span class="math inline">\(\{\pi_j^{(1)}\}_{j \in C_1}.\)</span></p></li>
<li><p>Similarly, let
<span class="math inline">\(\{\pi_j^{(2)}\}_{j \in C_2}, \ldots, \{\pi_j^{(r)}\}_{j \in C_r}\)</span>
be stationary distributions within other classes.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li>Show that for any numbers <span class="math inline">\(\gamma_1, \gamma_2, \ldots, \gamma_r\)</span>
such that <span class="math inline">\(\sum_{m=1}^r \gamma_m = 1\)</span>, the following
distribution <span class="math inline">\(\{ \pi_j \}\)</span> is stationary, where</li>
</ol>
<p><span class="math display" id="eq:limitdist">\[\begin{equation} 
  \tag{6.1}
    \pi_j =
     \begin{cases}
        \pi_j^{(k)} \gamma_k &amp; \text{for } j \in C_k, \, k= 1,\ldots, r \\
        0 &amp; \text{if } j \text{ is in a nonclosed class.}
      \end{cases}
    \end{equation}\]</span>
(In particular, any stationary distribution of the Markov chain is of this form.)</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Write down the general form of stationary distributions of the
Markov chain in Questions 3.3 and 3.4.</p></li>
<li><p>Now we will focus on limiting distributions. Consider the three
following possible cases.</p>
<ol style="list-style-type: decimal">
<li><p>If <span class="math inline">\(X_0 = i\)</span> and <span class="math inline">\(i \in C_k\)</span> for some closed class <span class="math inline">\(C_k\)</span>,
then verify that the limiting distribution is defined as in Eqn.<a href="tutorials.html#eq:limitdist">(6.1)</a> where <span class="math inline">\(\gamma_k =1\)</span> and
<span class="math inline">\(\gamma_m = 0,\)</span> for <span class="math inline">\(m \neq k\)</span>.</p></li>
<li><p>If <span class="math inline">\(X_0 = i\)</span> and <span class="math inline">\(i\)</span> is in a nonclosed class, then verify
that the limiting distribution is defined as in
Eqn.<a href="tutorials.html#eq:limitdist">(6.1)</a> where <span class="math inline">\(\gamma_k = \alpha^{(k)}_i\)</span>
for <span class="math inline">\(k = 1,2,\ldots r\)</span> where <span class="math inline">\(\alpha^{(k)}_i\)</span> is the
probability of absorption in class <span class="math inline">\(C_k\)</span>. More precisely,
<span class="math display">\[\pi_j =
 \begin{cases}
    \pi_j^{(k)} \alpha^{(k)}_i &amp; \text{for } j \in C_k, \, k= 1,\ldots, r \\
    0 &amp; \text{if } j \text{ is in a nonclosed class.}
  \end{cases}
      %\pi_j^{(k)} \gamma_k \text{ for } j \in C_k, \, k= 1,\ldots, r \text { and }\]</span></p></li>
<li><p>If <span class="math inline">\(X_0\)</span> is random, then this will leave as extra exercise.
(Hint: you may need to apply first step anslysis)</p></li>
</ol></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li>We will illustrate the results of this question by using the Markov chain given in Question 3.3.</li>
</ol>
<p>We know that <span class="math inline">\(C_1 = \{2,3\}\)</span> and <span class="math inline">\(C_2 = \{4\}\)</span> are closed and <span class="math inline">\(\{1\}\)</span> is non-closed. Both <span class="math inline">\(\{2,3\}\)</span> and <span class="math inline">\(\{4\}\)</span> are aperiodic.</p>
<p>The stationary distribution within the class <span class="math inline">\(C_1\)</span>, denoted by
<span class="math inline">\(\boldsymbol{\pi}^{(1)} = (\pi_1, \pi_2 )\)</span> can be obtained from solving
<span class="math inline">\(\pi_1 + \pi_2 = 1\)</span>,
<span class="math display">\[(\pi_1,  \pi_2)  
\begin{bmatrix}
    3/4 &amp; 1/4    \\
    3/4 &amp; 1/4    \\
\end{bmatrix} =  (\pi_1,  \pi_2).\]</span></p>
<p>Therefore, <span class="math inline">\(\boldsymbol{\pi}^{(1)} = (3/4, 1/4 )\)</span>.</p>
<p>Similarly, the stationary distribution within the class <span class="math inline">\(C_2 = \{4\}\)</span> is <span class="math inline">\(\boldsymbol{\pi}^{(2)} = (1)\)</span>.</p>
<p>It is now easy to verify that for for any numbers <span class="math inline">\(\gamma_1 + \gamma_2 = 1\)</span>, the following probability distribution is stationary:</p>
<p><span class="math display">\[\boldsymbol{\pi} = (0, (3/4)\gamma_1, (1/4)\gamma_1, \gamma_2).\]</span></p>
<pre><code>2. In particular, the general form of a stationary distribution is of this form: </code></pre>
<p><span class="math display">\[\boldsymbol{\pi} = (0, (3/4)\gamma_1, (1/4)\gamma_1, \gamma_2).\]</span></p>
<p>It should be emphasised that the above results confirm that the Markov chain have many stationary distributions.</p>
<pre><code>3. Again using the Markov chain given in Question 3.3, we have that </code></pre>
<ul>
<li><p>If either <span class="math inline">\(X_0 = 2\)</span> or <span class="math inline">\(X_0 = 3\)</span> (i.e. the Markov chain initially starts in the closed class <span class="math inline">\(C_1 = \{2,3\}\)</span>), (with the aid of computer software) the limiting distribution is
<span class="math display">\[\boldsymbol{\pi} = (0,3/4,1/4,0).\]</span></p></li>
<li><p>If <span class="math inline">\(X_0 = 4\)</span> (i.e. the Markov chain initially starts in the closed class <span class="math inline">\(C_2 = \{4\}\)</span>), (with the aid of computer software) the limiting distribution is</p></li>
</ul>
<p><span class="math display">\[\boldsymbol{\pi} = (0,0,0,1).\]</span></p>
<ul>
<li>If <span class="math inline">\(X_0 = 1\)</span> (i.e. the Markov chain initially starts in the closed class <span class="math inline">\(C_2 = \{4\}\)</span>), (with the aid of computer software) the limiting distribution is</li>
</ul>
<p><span class="math display">\[\boldsymbol{\pi} = (0, (3/4)\alpha_1^{(1)}, (1/4)\alpha_1^{(1)}, \alpha_1^{(2)}),\]</span>
where <span class="math inline">\(\alpha_1^{(1)} = 2/3\)</span> and <span class="math inline">\(\alpha_1^{(2)} = 1/3\)</span> is the probability of absorption in classes <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>, respectivel.</p>
<p>Hence, <span class="math display">\[\boldsymbol{\pi} = (0, 1/2, 1/6, 1/3).\]</span></p>
<ul>
<li>If <span class="math inline">\(X_0\)</span> is random, one approach is to use the first step analysis to calculate the limiting distribution. This will leave as extra exercise.</li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li><p>A no-claims discount system for motor insurance has four levels of
discount:</p>
<table>
<thead>
<tr class="header">
<th align="center">Level</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Discount</td>
<td align="center">0%</td>
<td align="center">10%</td>
<td align="center">30%</td>
<td align="center">50%</td>
</tr>
</tbody>
</table>
<p>The rules for moving between these levels are given as follows:</p>
<ul>
<li><p>Following a claim-free year, move to the next higher level, or
remain at level 4.</p></li>
<li><p>Following a year with one claim, move to the next lower level,
or remain at level 1.</p></li>
<li><p>Following a year with two or more claims, move down two levels,
or move to level 1 (from level 2), or remain at level 1.</p></li>
</ul>
<p>A portfolio consists of 10,000 policyholders. Suppose also that the
number of claims per year is <span class="math inline">\(\mathcal{Poisson}(0.1)\)</span>. <strong>Suppose at time 0 all policyholders are at level 1.</strong></p>
<ol style="list-style-type: decimal">
<li><p>Calculate <span class="math inline">\(\Pr[N = 0]\)</span>, <span class="math inline">\(\Pr[N = 1]\)</span>, and <span class="math inline">\(\Pr[N \ge 2]\)</span> for
each group.</p></li>
<li><p>Write down the transition probability matrix of this no-claims
discount system.</p></li>
<li><p>Find the probability that a policyholder who has the 30%
discount has no discount after 2 years.</p></li>
<li><p>Calculate the expected number of policyholders at each level at
times 1 and 2, assuming no exits.</p></li>
<li><p>Calculate the expected number of policyholders at each level
once stability has been achieved, assuming no exits.</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong>
1. For a given policyholder, the number of claims each year, <span class="math inline">\(N\)</span>, has a
Poisson distribution with parameter <span class="math inline">\(\lambda=0.1\)</span>. Therefore,</p>
<ul>
<li><p><span class="math inline">\(p_0 = \Pr(N = 0) = e^{-0.1} = 0.9048374\)</span></p></li>
<li><p><span class="math inline">\(p_1 = \Pr(N = 1) = e^{-0.1}(0.1) = 0.0904837\)</span></p></li>
<li><p><span class="math inline">\(p_{2+} = \Pr(N \ge 1) = 0.0046788\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>The transition diagram is shown in the figure below:</li>
</ol></li>
</ul>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<pre><code>The transition matrix is </code></pre>
<pre><code>## P 
##  A  4 - dimensional discrete Markov Chain defined by the following states: 
##  1, 2, 3, 4 
##  The transition matrix  (by rows)  is defined as follows: 
##            1          2          3         4
## 1 0.09516258 0.90483742 0.00000000 0.0000000
## 2 0.09516258 0.00000000 0.90483742 0.0000000
## 3 0.00467884 0.09048374 0.00000000 0.9048374
## 4 0.00000000 0.00467884 0.09048374 0.9048374</code></pre>
<p>which can be obtained from</p>
<p><span class="math display">\[ P = \begin{bmatrix}
                1 - p_0 &amp; p_0 &amp; 0 &amp; 0      \\
                1 - p_0 &amp; 0 &amp; p_0 &amp; 0   \\
            1 - p_0 - p_1 &amp; p_1 &amp; 0 &amp; p_0     \\    
            0 &amp; 1 - p_0 - p_1 &amp; p_1 &amp; p_0     \\
        \end{bmatrix}.\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>The required probability is</li>
</ol>
<p><span class="math display">\[ \Pr(X_2 = 1 | X_0 = 3) = (P^2)_{31} = 0.0090559.\]</span></p>
<pre><code>4. Given that at time 0 all policyholders are at level 1, the initial probability distribution is </code></pre>
<p><span class="math display">\[\boldsymbol{\mu} = (1,0,0,0)\]</span>.</p>
<p>Hence the probability distributions of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are <span class="math inline">\(\boldsymbol{\mu} P\)</span> and <span class="math inline">\(\boldsymbol{\mu} P^2\)</span>:</p>
<ul>
<li><p><span class="math inline">\(\boldsymbol{\mu} P = (0.0951626, 0.9048374, 0, 0)\)</span></p></li>
<li><p><span class="math inline">\(\boldsymbol{\mu} P^2 = (0.0951626, 0.0861067, 0.8187308, 0)\)</span>.</p></li>
</ul>
<p>At times 1,the expected numbers of policyholders at levels 1 to 4 are</p>
<p><span class="math display">\[952, 9048, 0 \text{ and } 0, \text{respectively}.\]</span></p>
<p>At times 2,the expected numbers of policyholders at levels 1 to 4 are</p>
<p><span class="math display">\[952, 861, 8187 \text{ and } 0, \text{respectively}.\]</span></p>
<pre><code>5. It should be note that the Markov chain for this NCD system sastifies the following</code></pre>
<ul>
<li><p>The state space <span class="math inline">\(S\)</span> is finite.</p></li>
<li><p><span class="math inline">\(S\)</span> is irreducible.</p></li>
<li><p>The Markov chain is aperiodic.</p></li>
</ul>
<p>Therefore, these imply the existence of the limiting probability distribution, which is the same as the stationary distribution. We need to find the stationary probability distribution <span class="math inline">\(\boldsymbol{\pi} = (\pi_1, \pi_2, \pi_3, \pi_4)\)</span>, which is the solution of the linear
equations <span class="math inline">\(\boldsymbol{\pi} P =\boldsymbol{\pi}\)</span> (note that one of the equations can be discarded), together with the condition
<span class="math inline">\(\sum_{j \in S} \pi_j = 1\)</span>.</p>
<p>It follows that</p>
<p><span class="math display">\[\boldsymbol{\pi} = (0.0020032, 0.0144456, 0.0935973, 0.8899539),\]</span>
and hence the expected numbers of policyholders at levels 1 to 4 once stability has been achieved, are</p>
<p><span class="math display">\[20, 144, 936 \text{ and } 8900, \text{respectively}.\]</span></p>
<ol start="7" style="list-style-type: decimal">
<li><p>A no-claims discount system for motor insurance has four levels of
discount:</p>
<table>
<thead>
<tr class="header">
<th align="center">Level</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Discount</td>
<td align="center">0%</td>
<td align="center">20%</td>
<td align="center">30%</td>
<td align="center">50%</td>
</tr>
</tbody>
</table>
<p>The rules for moving between these levels are given as follows:</p>
<ul>
<li><p>For a claim-free year, a policyholder moves to the next higher
level, or remains at level 4.</p></li>
<li><p>For every claim in a year, the policyholder moves down a
discount level or remains at level 1, for example if the
policyholder is in level 4 and has one accident, he/she moves to
level 3, and 2 accidents, he/she moves to level 2, and 2 or more
accidents to level 1.</p></li>
</ul>
<p>For a given policyholder, the number of claims each year, <span class="math inline">\(N\)</span>, has a
negative binomial distribution with parameters <span class="math inline">\(k=2\)</span> and <span class="math inline">\(p = 0.5\)</span>.</p>
<p>Note that a random variable <span class="math inline">\(N\)</span> has a negative distribution with
parameters <span class="math inline">\(k\)</span> and <span class="math inline">\(p\)</span>, denoted by <span class="math inline">\(N \sim \mathcal{NB}(k, p)\)</span> if its probability
mass function is given by
<span class="math display">\[f_N(n) = \Pr(N = n) = \frac{\Gamma(k+n)}{\Gamma(n+1)\Gamma(k)} p^k (1- p)^n \quad n = 0,1,2,\ldots.\]</span></p>
<ol style="list-style-type: decimal">
<li><p>Draw a transition diagram for the chain.</p></li>
<li><p>Write down the transition matrix of this no-claims discount
system.</p></li>
<li><p>Find the probability that a policyholder who has the maximum
discount level will have 20% discount after two years.</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<p>For a given policyholder, the number of claims each year, <span class="math inline">\(N\)</span>, has a
negative binomial distribution with parameters <span class="math inline">\(k=2\)</span> and <span class="math inline">\(p = 0.5\)</span>. Therefore,</p>
<p><span class="math display">\[\begin{aligned}
p_n = \Pr(N = n) &amp;= \frac{\Gamma(k+n)}{\Gamma(n+1)\Gamma(k)} p^k (1- p)^n \\   
&amp;= \frac{\Gamma(n+2)}{\Gamma(n+1)\Gamma(2)} 0.5^2 (1- 0.5)^n \\
&amp;= (n+1)0.5^{n+2}    \quad n = 0,1,2,\ldots.
\end{aligned}\]</span>
Therefore,</p>
<ul>
<li><p><span class="math inline">\(p_0 = 0.25\)</span></p></li>
<li><p><span class="math inline">\(p_1 = 0.25\)</span></p></li>
<li><p><span class="math inline">\(p_2 = 0.1875\)</span></p>
<ol style="list-style-type: decimal">
<li>The transition diagram is shown in the figure below:</li>
</ol></li>
</ul>
<p><img src="SCMA469Bookdownproj_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre><code>2. The transition matrix is </code></pre>
<pre><code>## P 
##  A  4 - dimensional discrete Markov Chain defined by the following states: 
##  1, 2, 3, 4 
##  The transition matrix  (by rows)  is defined as follows: 
##        1      2    3    4
## 1 0.7500 0.2500 0.00 0.00
## 2 0.7500 0.0000 0.25 0.00
## 3 0.5000 0.2500 0.00 0.25
## 4 0.3125 0.1875 0.25 0.25</code></pre>
<p>which can be obtained from</p>
<p><span class="math display">\[ P = \begin{bmatrix}
                1 - p_0 &amp; p_0 &amp; 0 &amp; 0      \\
                1 - p_0 &amp; 0 &amp; p_0 &amp; 0   \\
            1 - p_0 - p_1 &amp; p_1 &amp; 0 &amp; p_0     \\    
            1 - p_0 - p_1 -p2 &amp; p_2 &amp; p_1 &amp; p_0     \\
        \end{bmatrix}.\]</span></p>
<pre><code>3. The required probability is</code></pre>
<p><span class="math display">\[ \Pr(X_2 = 2 | X_0 = 4) = (P^2)_{42} = 0.1875.\]</span></p>
<!-- ## Tutorial 2 -->
<!-- 1.  A Markov chain $X_0, X_1, \ldots$ on states 1 ,2 ,3 has the -->
<!--     following transition matrix $$P = \begin{bmatrix} -->
<!--         0.5 & 0.3 & 0.2    \\ -->
<!--         0.2 & 0.2 & 0.6  \\ -->
<!--         0.3 & 0.2 &  0.5    \\ -->
<!--         %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix}.$$ The distribution of the initial random variable -->
<!--     $X_0$ is $\boldsymbol{\mu} = (0.3,0,3,0.4)$. -->
<!--     1.  Draw a transition diagram for the chain. -->
<!--     2.  Determine $\Pr(X_0 = 1, X_1 = 2, X_2 = 3).$ -->
<!--     3.  Determine $\Pr(X_1 = 2, X_2 = 3 | X_0 = 1).$ -->
<!--     4.  Determine $\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1).$ -->
<!--     5.  Determine $\Pr(X_2 = 3 | X_0 = 1).$ -->
<!--     6.  Determine $\Pr(X_3 = 3 | X_1 = 1).$ -->
<!--     7.  Determine $\Pr(X_2 = 3).$ -->
<!--     8.  Determine $\mathrm{E}[X_2]$ -->
<!-- 2.  A Markov chain $X_0, X_1, \ldots$ on states 1 ,2 ,3 has the -->
<!--     following transition matrix $$P = \begin{bmatrix} -->
<!--         0 & 1/2 & 1/2   \\ -->
<!--         1/3  & 1/3  & 1/3   \\ -->
<!--         1/2  & 1/2  & 0    \\ -->
<!--         %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix}.$$ The process starts in states $X_0 = 1$. -->
<!--     1.  Draw a transition diagram for the chain. -->
<!--     2.  Determine $\Pr(X_0 = 1, X_1 = 3, X_2 = 2).$ -->
<!--     3.  Determine $\Pr(X_1 = 3, X_2 = 2 | X_0 = 1).$ -->
<!--     4.  Determine $\Pr(X_2 = 2 | X_0 = 1).$ -->
<!--     5.  Determine $\Pr(X_3 = 2 | X_1 = 1).$ -->
<!--     6.  Determine $\Pr(X_2 = 2).$ -->
<!-- 3.  A Markov chain $X_0, X_1, \ldots$ on sates 1 ,2 has the following -->
<!--     transition matrix $$P = \begin{bmatrix} -->
<!--         1-a & a   \\ -->
<!--         b & 1-b   \\ -->
<!--         %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix},$$ where $0 < a,b < 1.$ -->
<!--     1.  Draw a transition diagram for the chain. -->
<!--     2.  the distribution of $X_1$. -->
<!--     3.  Show that $$P^n = \frac{1}{a+b} \begin{bmatrix} -->
<!--             b & a   \\ -->
<!--             b & a   \\ -->
<!--             %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--             %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--         \end{bmatrix} + -->
<!--         \frac{(1-a-b)^n}{a+b} \begin{bmatrix} -->
<!--             a & -a   \\ -->
<!--             -b & b   \\ -->
<!--             %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--             %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--         \end{bmatrix}.$$ -->
<!--     4.  Given that $X_0 = 1$, what is the probability that in the long -->
<!--         run the system will be in state 1? (Hint: consider -->
<!--         $\lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n$) -->
<!--     5.  Given that $X_0 = 1$, what is the probability that in the long -->
<!--         run the system will be in state 2? -->
<!--     6.  Given that $X_0 = 2$, what is the probability that in the long -->
<!--         run the system will be in state 1? -->
<!--     7.  Given that $X_0 = 2$, what is the probability that in the long -->
<!--         run the system will be in state 2? -->
<!-- 4.  Let $a$ be a constant and $\xi_1, \xi_2, \ldots$ be a sequence of -->
<!--     independent and identically distributed (i.i.d.) random variables. -->
<!--     The stochastic process $\{ X_n\}$ is defined by -->
<!--     $$X_0 = a, \quad X_n = X_{n-1} + \xi_n, \, n > 1.$$ This process is -->
<!--     known as a random walk. -->
<!--     1.  Express the state $X_n$ in terms of $X_0$ and the random -->
<!--         variables $\xi_i, i = 1,2 \ldots$. -->
<!--     2.  Find $\mathrm{E}[X_n]$ and $\mathrm{Var}[X_n]$. -->
<!--     3.  Does the process have the Markov property? Explain. -->
<!--     4.  Is the process stationary? Explain. -->
<!-- 5.  Consider a homogeneous discrete-time Markov chain that describes the -->
<!--     daily weather pattern. The weather patterns are classified into 3 -->
<!--     conditions: R(rainy), C (cloudy) and S(sunny). Based on the daily -->
<!--     observations, the following information are given: -->
<!--     -   On any rainy day, the probability that it will rain the next day -->
<!--         is 0.7; the probability that tomorrow will be cloudy is 0.2 and -->
<!--         the probability that tomorrow will be sunny is 0.1. -->
<!--     -   On any cloudy day, the probability that it will rain the next -->
<!--         day is 0.5; the probability that tomorrow will be cloudy is 0.35 -->
<!--         and the probability that tomorrow will be sunny is 0.15. -->
<!--     -   On any sunny day, the probability that it will rain the next day -->
<!--         is 0.1; the probability that tomorrow will be cloudy is 0.4 and -->
<!--         the probability that tomorrow will be sunny is 0.5. -->
<!--     1.  Draw a transition diagram for the chain and write down a -->
<!--         transition matrix. -->
<!--     2.  Find the probability that tomorrow is cloudy and the day after -->
<!--         is rainy, given that it is sunny today. -->
<!--     3.  Given that today is rainy, find the probability that it will be -->
<!--         sunny in two days time. -->
<!-- ## Tutorial 3 -->
<!-- 1.  A Markov chain $X_0, X_1, \ldots$ on states 1, 2, 3 with initial -->
<!--     distribution $\boldsymbol{\mu} = (1/4,1/4,1/2)$. It has the -->
<!--     following transition matrix $$P = \begin{bmatrix} -->
<!--         1/2 & 1/4 & 1/4   \\ -->
<!--         1/3  & 1/3  & 1/3   \\ -->
<!--         1/5  & 2/5  & 2/5    \\ -->
<!--         %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix}.$$ Compute the following probabilities: -->
<!--     1.  $\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1).$ -->
<!--     2.  $\Pr(X_0 = 3, X_1 = 2 , X_2 = 1).$ -->
<!--     3.  $\Pr(X_1 = 3, X_2 = 2 , X_3 = 1).$ -->
<!--     4.  $\Pr(X_{1} = 2, X_{3} = 2, X_{5} = 2).$ -->
<!-- 2.  A Markov chain with state space $S = \{1,2,3,4,5,6\}$ has the -->
<!--     following transition matrix: $$P = \begin{bmatrix} -->
<!--     1/4 & 0 & 3/4 & 0 & 0 & 0  \\ -->
<!--     0 & 0 & 0 & 1 & 0 & 0  \\ -->
<!--     0 & 0 & 1/2 & 0 & 0 & 1/2  \\ -->
<!--     1/5 & 1/5 & 1/5 & 0 & 1/5 & 1/5   \\ -->
<!--     0 & 0 & 0 & 0 & 1 & 0  \\ -->
<!--     1/3 & 0 & 0 & 0 & 0 & 2/3  \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix}.$$ -->
<!--     1.  Draw a transition diagram. -->
<!--     2.  Identify the communication classes and classify them as closed -->
<!--         or non-closed. -->
<!--     3.  Is the Markov chain irreducible? -->
<!-- 3. For each of the Markov chains whose -->
<!--     transition matrix is given below, identify the closed classes and -->
<!--     the vector of absorption probabilities associated with each of these -->
<!--     closed classes. Assume that the states are labelled $1,2,3 \ldots$. -->
<!--     1.  $$\begin{bmatrix} -->
<!--                 1/6 & 0 & 1/3 & 1/2      \\ -->
<!--                 0 & 1/3 & 2/3 & 0   \\ -->
<!--             1/2 & 1/2 & 0 & 0     \\     -->
<!--             0 & 0 & 1/4 & 3/4     \\ -->
<!--         \end{bmatrix}.$$ -->
<!--     2.  $$\begin{bmatrix} -->
<!--                 0 & 1/4 & 3/4 & 0      \\ -->
<!--                 0 & 1/3 & 0 & 2/3   \\ -->
<!--             1/3 & 0 & 1/3 & 1/3     \\   -->
<!--             0 & 0 & 0 & 1     \\ -->
<!--         \end{bmatrix}.$$ -->
<!--     3.   $$\begin{bmatrix} -->
<!--                 1/4 & 1/4 & 1/4 & 1/4      \\ -->
<!--                 0 & 3/4 & 1/4 & 0   \\ -->
<!--                 0 & 3/4 & 1/4 & 0   \\ -->
<!--             0 & 0 & 0 & 1     \\ -->
<!--         \end{bmatrix}.$$ -->
<!--     4.   $$\begin{bmatrix} -->
<!--                 0 & 0 & 0 & 1/2  & 0 & 0 & 1/2   \\ -->
<!--                 1/6 & 0 & 1/6 & 0  & 0 & 1/6 & 1/2 \\ -->
<!--             0 & 0 & 1 & 0 & 0 & 0 & 0    \\  -->
<!--                 1/2 & 0 & 0 & 1/2  & 0 & 0 & 0   \\ -->
<!--             1/4 & 1/4 & 0 & 0  & 0 & 0 & 1/2 \\ -->
<!--             0 & 1 & 0 & 0 & 0 & 0 & 0    \\  -->
<!--                 1/2 & 0 & 0 & 0  & 0 & 0 & 1/2   \\ -->
<!--         \end{bmatrix}.$$ -->
<!-- 4.  If the Markov chain defined in Question 3 is irreducible, -->
<!--     i.e. it has a unique stationary distribution, then find the -->
<!--     stationary distribution of the chain. -->
<!-- 5.  Assume that a Markov chain has more than one closed classes (say $r$ -->
<!--     closed classes). The Markov chain can **have many stationary -->
<!--     distributions**. Assume further that within each of these $r$ closed -->
<!--     classes, the associated Markov chain is aperiodic. The followings -->
<!--     hold: -->
<!--     -   Within a closed class $C_1$, let $P_1$ be a reduction of a -->
<!--         matrix $P$ which is formed by deleting all rows and columns -->
<!--         corresponding to states from other classes. Then there exists a -->
<!--         unique stationary distribution, denoted by -->
<!--         $\{\pi_j^{(1)}\}_{j \in C_1}.$ -->
<!--     -   Similarly, let -->
<!--         $\{\pi_j^{(2)}\}_{j \in C_2}, \ldots, \{\pi_j^{(r)}\}_{j \in C_r}$ -->
<!--         be stationary distributions within other classes. -->
<!--     1.  Show that for any numbers $\gamma_1, \gamma_2, \ldots, \gamma_r$ -->
<!--         such that $\sum_{m=1}^r \gamma_m = 1$, the following -->
<!--         distribution $\{ \pi_j \}$ is stationary, where -->
<!--       \begin{equation}  -->
<!--       (\#eq:limitdist) -->
<!--         \pi_j = -->
<!--          \begin{cases} -->
<!--             \pi_j^{(k)} \gamma_k & \text{for } j \in C_k, \, k= 1,\ldots, r \\ -->
<!--             0 & \text{if } j \text{ is in a nonclosed class.} -->
<!--           \end{cases} -->
<!--         \end{equation} -->
<!--         (In particular, any stationary distribution of the Markov chain is of this form.) -->
<!--     2.  Write down the general form of stationary distributions of the -->
<!--         Markov chain in Questions 3.3 and 3.4. -->
<!--     3.  Now we will focus on limiting distributions. Consider the three -->
<!--         following possible cases. -->
<!--         1.  If $X_0 =  i$ and $i \in C_k$ for some closed class $C_k$, -->
<!--             then verify that the limiting distribution is defined as in Eqn.\@ref(eq:limitdist) where $\gamma_k =1$ and -->
<!--             $\gamma_m = 0,$ for $m \neq k$. -->
<!--         2.  If $X_0 =  i$ and $i$ is in a nonclosed class, then verify -->
<!--             that the limiting distribution is defined as in -->
<!--             Eqn.\@ref(eq:limitdist) where $\gamma_k =  \alpha^{(k)}_i$ -->
<!--             for $k = 1,2,\ldots r$ where $\alpha^{(k)}_i$ is the -->
<!--             probability of absorption in class $C_k$. More precisely, -->
<!--             $$\pi_j = -->
<!--              \begin{cases} -->
<!--                 \pi_j^{(k)} \alpha^{(k)}_i & \text{for } j \in C_k, \, k= 1,\ldots, r \\ -->
<!--                 0 & \text{if } j \text{ is in a nonclosed class.} -->
<!--               \end{cases} -->
<!--                   %\pi_j^{(k)} \gamma_k \text{ for } j \in C_k, \, k= 1,\ldots, r \text { and }$$ -->
<!--         3.  If $X_0$ is random, then this will leave as extra exercise. -->
<!--             (Hint: you may need to apply first step anslysis) -->
<!-- 6.  A no-claims discount system for motor insurance has four levels of -->
<!--     discount: -->
<!--         Level     1     2     3     4 -->
<!--       ---------- ---- ----- ----- ----- -->
<!--        Discount   0%   10%   30%   50% -->
<!--     The rules for moving between these levels are given as follows: -->
<!--     -   Following a claim-free year, move to the next higher level, or -->
<!--         remain at level 4. -->
<!--     -   Following a year with one claim, move to the next lower level, -->
<!--         or remain at level 1. -->
<!--     -   Following a year with two or more claims, move down two levels, -->
<!--         or move to level 1 (from level 2), or remain at level 1. -->
<!--     A portfolio consists of 10,000 policyholders. Suppose also that the -->
<!--     number of claims per year is $\mathcal{Poisson}(0.1)$. -->
<!--     1.  Calculate $\Pr[N = 0]$, $\Pr[N = 1]$, and $\Pr[N \ge 2]$ for -->
<!--         each group. -->
<!--     2.  Write down the transition probability matrix of this no-claims -->
<!--         discount system. -->
<!--     3.  Find the probability that a policyholder who has the 30% -->
<!--         discount has no discount after 2 years. -->
<!--     4.  Calculate the expected number of policyholders at each level at -->
<!--         times 1 and 2, assuming no exits given that all policyholders start at level 1. -->
<!--     5.  Calculate the expected number of policyholders at each level -->
<!--         once stability has been achieved, assuming no exits. -->
<!-- 7.  A no-claims discount system for motor insurance has four levels of -->
<!--     discount: -->
<!--         Level     1     2     3     4 -->
<!--       ---------- ---- ----- ----- ----- -->
<!--        Discount   0%   20%   30%   50% -->
<!--     The rules for moving between these levels are given as follows: -->
<!--     -   For a claim-free year, a policyholder moves to the next higher -->
<!--         level, or remains at level 4. -->
<!--     -   For every claim in a year, the policyholder moves down a -->
<!--         discount level or remains at level 1, for example if the -->
<!--         policyholder is in level 4 and has one accident, he/she moves to -->
<!--         level 3, and 2 accidents, he/she moves to level 2, and 2 or more -->
<!--         accidents to level 1. -->
<!--     For a given policyholder, the number of claims each year, $N$, has a -->
<!--     negative binomial distribution with parameters $k=2$ and $p = 0.5$. -->
<!--     Note that a random variable $N$ has a negative distribution with -->
<!--     parameters $k$ and $p$, denoted by $N \sim \dnb$ if its probability -->
<!--     mass function is given by -->
<!--     $$f_N(n) = \Pr(N = n) = \frac{\Gamma(k+n)}{\Gamma(n+1)\Gamma(k)} p^k (1- p)^n \quad n = 0,1,2,\ldots.$$ -->
<!--     1.  Draw a transition diagram for the chain. -->
<!--     2.  Write down the transition matrix of this no-claims discount -->
<!--         system. -->
<!--     3.  Find the probability that a policyholder who has the maximum -->
<!--         discount level will have 20% discount after two years. -->
</div>
<div id="tutorial-4" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Tutorial 4</h2>
<ol style="list-style-type: decimal">
<li><p>Customers arrive in a shop according to a Poisson process of rate
<span class="math inline">\(\lambda = 2\)</span>. Let <span class="math inline">\(N(t)\)</span> be the number of customers that have
arrived up to time <span class="math inline">\(t\)</span>. Determine the following probabilities,
conditional probabilities and expectations.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\Pr(N(1) = 2).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) = 2 \text{ and } N(3) = 6).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) = 2 | N(3) = 6).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(3) = 6 | N(1) = 2).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) \le 2).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) = 1 \text{ and } N(2) = 3).\)</span></p></li>
<li><p><span class="math inline">\(\Pr(N(1) \ge 2 | N(1) \ge 1).\)</span></p></li>
<li><p><span class="math inline">\(\mathrm{E}[N(2)]\)</span></p></li>
<li><p><span class="math inline">\(\mathrm{E}[N(1)^2]\)</span></p></li>
<li><p><span class="math inline">\(\mathrm{E}[N(1)N(2)]\)</span></p></li>
</ol></li>
<li><p>Customers arrive in a shop according to a Poisson process of rate
<span class="math inline">\(\lambda = 4\)</span> per hour. The shop opens at 9 am. Calculate the
probability that exactly one customer has arrived by 9.30 am and a
total of five customers have arrived by 11.30.</p></li>
<li><p>Defects occur along a cable according to a Poisson process of rate
<span class="math inline">\(\lambda = 0.1\)</span> per kilometre.</p>
<ol style="list-style-type: decimal">
<li><p>Calculate the probability that no defects appear in the first
two kilometres of cable.</p></li>
<li><p>Given that there are no defects in the first two kilometres of
cable, calculate the probability of no defects between two and
three kilometres of cable.</p></li>
</ol></li>
<li><p>Customers arrive at a department store according to a Poisson
process with rate <span class="math inline">\(\lambda = 2\)</span> per minute.</p>
<ol style="list-style-type: decimal">
<li><p>Calculate the probability that in a given 5 minute period there
will be no customers arriving?</p></li>
<li><p>Calculate the probability that the 10th customer after 11 am
will arrive before 11:05 am?</p></li>
<li><p>If a third of customers are men, calculate the probability that
in a 5 minute period more than 3 men arrive given more than 4
women arrive.</p></li>
<li><p>If every 5th customer receives a discount voucher, calculate the
distribution of the times between these vouchers being given
out? What is the probability that a time longer than 5 minutes will pass between one voucher being given out and the next?</p></li>
</ol></li>
<li><p>You have a bird table in your garden which attracts tailorbirds and
pigeons. Tailorbirds arrive according to a Poisson process with rate
<span class="math inline">\(\lambda_1\)</span> and the pigeons arrive according to a Poisson process
with rate <span class="math inline">\(\lambda_2\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>How long does it take for the first bird to arrive after a fixed
point in time?</p></li>
<li><p>Calculate the probability this bird is a tailorbird?</p></li>
<li><p>What is the distribution of the number of birds in the time
interval <span class="math inline">\([t_1, t_2)\)</span>?</p></li>
<li><p>Calculate the probability that exactly 3 tailorbirds arrive
before the first pigeon after a fixed point in time?</p></li>
</ol></li>
<li><p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be independent Poisson distributed random variables
with parameters <span class="math inline">\(\lambda_X\)</span> and <span class="math inline">\(\lambda_Y\)</span>, respectively. Determine
the conditional distribution of <span class="math inline">\(X\)</span>, given that <span class="math inline">\(N = X + Y = n\)</span>.</p></li>
<li><p>Accidents occur on an highway according to a Poisson process at the
rate of 20 accidents per week. One out of four accidents involve
speeding.</p>
<ol style="list-style-type: decimal">
<li><p>What is the probability that ten accidents involving speeding
will occur next week?</p></li>
<li><p>What is the probability that at least one accident occurs
tomorrow?</p></li>
<li><p>If sixty accidents occur in four weeks, what is the probability
that less than half of them involve speeding?</p></li>
</ol></li>
<li><p>Severe floods hit a southern of Thailand according to a Poisson
process with <span class="math inline">\(\lambda = 4\)</span>. The number of insurance claims filed
after any sever flood has a Poisson distribution with mean 60. The
number of server floods is independent of the number of insurance
claims. Find the expectation and standard deviation of the total
number of claims filed by time <span class="math inline">\(t\)</span>.</p></li>
<li><p>Assume that births occur at a hospital at the average rate of 3
births per hour. Assume that the probability that any birth is a boy
is 0.52.</p>
<ol style="list-style-type: decimal">
<li><p>On an 8-hour shift, what is the expectation and standard
deviation of the number of male births?</p></li>
<li><p>Assume that ten babies were born yesterday. Find the probability
that six are boys.</p></li>
<li><p>Find the probability that only boys were born between 6 and 10
a.m.</p></li>
</ol></li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Customers arrive in a shop according to a Poisson process of rate
<span class="math inline">\(\lambda = 2\)</span>. Let <span class="math inline">\(N(t)\)</span> be the number of customers that have
arrived up to time <span class="math inline">\(t\)</span>. It follows that <span class="math inline">\(N(t)\)</span> has a Poisson distribution with parameter <span class="math inline">\(\lambda t\)</span>. In addition, <span class="math inline">\(N(t +s) - N(s)\)</span> is a
Poisson random variable with mean <span class="math inline">\(\lambda \, t\)</span> , independent of
anything that has occurred before time <span class="math inline">\(s\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\Pr(N(1) = 2) = \frac{\exp(-(2)(1))((2)(1))^{2} }{(2!)} = 0.2706706\)</span>.</p></li>
<li></li>
</ol></li>
</ol>
<p><span class="math display">\[\begin{aligned}
    \Pr(N(1) = 2 \text{ and } N(3) = 6) &amp;= 
    \Pr(N(1) = 2 \text{ and } N(3) - N(1) = 4)\\
    &amp;= 
    \Pr(N(1) = 2) \Pr(N(3) - N(1) = 4)\\
    &amp;= \frac{\exp(-(2)(1))((2)(1))^{2}  }{(2!)} \frac{\exp(-(2)(2))((2)(2))^{4}  }{(4!)} = (0.2706706)(0.1953668) \\
    &amp;= 0.05288.
    \end{aligned}\]</span>
Here we have used the fact that <span class="math inline">\(N(3) - N(1)\)</span> and <span class="math inline">\(N(1)\)</span> are independent.</p>
<pre><code>3.  </code></pre>
<p><span class="math display">\[\begin{aligned}
    \Pr(N(1) = 2 | N(3) = 6) &amp;= 
    \frac{\Pr(N(1) = 2 \text{ and } N(3) = 6)}{\Pr(N(3) = 6)} \\ 
    \frac{0.05288}{ \frac{\exp(-(2)(3))((2)(3))^{6}  }{(6!)}  } \\
    &amp;= 0.3292181.
    \end{aligned}\]</span></p>
<pre><code>4.  </code></pre>
<p><span class="math display">\[\begin{aligned}
    \Pr(N(3) = 6 | N(1) = 2) 
    &amp;= \Pr(N(3)-N(1) = 4 | N(1) = 2) \\
    &amp;= \Pr(N(3)-N(1) = 4) 
    \frac{\exp(-(2)(2))((2)(2))^{4}  }{(4!)} = 0.1953668.
    \end{aligned}\]</span>
Here we have used the fact that <span class="math inline">\(N(3) - N(1)\)</span> and <span class="math inline">\(N(1)\)</span> are independent.</p>
<pre><code>5.  </code></pre>
<p><span class="math display">\[\begin{aligned}
    \Pr(N(1) \le 2) &amp;= 0.6766764.
    \end{aligned}\]</span></p>
<pre><code>6.  </code></pre>
<p><span class="math display">\[\begin{aligned}
    \Pr(N(1) = 1 \text{ and } N(2) = 3) &amp;= 
    \Pr(N(1) = 1 \text{ and } N(2) - N(1) = 2)\\
    &amp;= 
    \Pr(N(1) = 1) \Pr(N(2) - N(1) = 2)\\
    &amp;= \frac{\exp(-(2)(1))((2)(1))^{1}  }{(1!)}\frac{\exp(-(2)(1))((2)(1))^{2}  }{(2!)}  = (0.2706706)(0.2706706) \\
    &amp;= 0.0732626.
    \end{aligned}\]</span>
Here we have used the fact that <span class="math inline">\(N(2) - N(1)\)</span> and <span class="math inline">\(N(1)\)</span> are independent.</p>
<pre><code>7.  </code></pre>
<p><span class="math display">\[\begin{aligned}
    \Pr(N(1) \ge 2 | N(1) \ge 1) 
    &amp;= \frac{\Pr(N(1) \ge 2 \text{ and } N(1) \ge 1)}{\Pr(N(1) \ge 1)}  \\
     &amp;= \frac{\Pr(N(1) \ge 2)}{\Pr(N(1) \ge 1)}  \\
     &amp;= \frac{1 - \Pr(N(1) \le 1)}{1- \Pr(N(1) = 0)}  \\
     &amp;= \frac{0.5939942}{0.8646647} \\
     &amp;= 0.5136058.
    \end{aligned}\]</span></p>
<pre><code>8.  </code></pre>
<p><span class="math display">\[\begin{aligned}
    \mathrm{E}[N(2)] = 4.
    \end{aligned}\]</span></p>
<pre><code>9.  </code></pre>
<p><span class="math display">\[\begin{aligned}
    \mathrm{E}[N(1)^2] = 
     \mathrm{Var}[N(1)] +  (\mathrm{E}[N(1)])^2 = 6.
    \end{aligned}\]</span></p>
<pre><code>10. </code></pre>
<p><span class="math display">\[\begin{aligned}
    \mathrm{E}[N(1)N(2)] &amp;=
    \mathrm{E}[N(1)\cdot (N(1) + (N(2) - N(1))] \\
    &amp;=
    \mathrm{E}[N(1)^2] + \mathrm{E}[ (N(1) \cdot (N(2) - N(1))] \\
    &amp;=
    \mathrm{E}[N(1)^2] + \mathrm{E}[ N(1)] \cdot \mathrm{E}[N(2) - N(1)] \\
    &amp;= 6 + (2)(2) = 10.
    \end{aligned}\]</span>
Here we have used the fact that <span class="math inline">\(N(2) - N(1)\)</span> and <span class="math inline">\(N(1)\)</span> are independent.</p>
<ol start="2" style="list-style-type: decimal">
<li>Let <span class="math inline">\(N(t)\)</span> be the number of customers that have arrived up to time <span class="math inline">\(t\)</span>.</li>
</ol>
<p><span class="math display">\[\begin{aligned}
    \Pr(N(1/2) = 1 \text{ and } N(5/2) = 5) &amp;= 
    \Pr(N(1/2) = 1 \text{ and } N(5/2) - N(1/2) = 4)\\
    &amp;= 
    \Pr(N(1/2) = 1) \Pr(N(5/2) - N(1/2) = 4)\\
    &amp;= \frac{\exp(-(4)(0.5))((4)(0.5))^{1}  }{(1!)} \frac{\exp(-(4)(2))((4)(2))^{4}  }{(4!)} = (0.2706706)(0.0572523) \\
    &amp;= 0.0154965.
    \end{aligned}\]</span>
Here we have used the fact that <span class="math inline">\(N(5/2) - N(1/2)\)</span> and <span class="math inline">\(N(1/2)\)</span> are independent.</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(X(t)\)</span> be the number of defects of cable of length <span class="math inline">\(t\)</span>. We have <span class="math inline">\(X(t) \sim \text{Poisson}(\lambda \, t).\)</span></p>
<pre><code> 1. We have </code></pre></li>
</ol>
<p><span class="math display">\[\Pr(X(2) = 0) = \frac{\exp(-(0.1)(2))((0.1)(2))^{0}  }{(0!)} = 0.8187308.\]</span>
2. Using the independent of <span class="math inline">\(X(2)\)</span> and <span class="math inline">\(X(3) - X(2)\)</span>, this implies that the conditional probability is the same as the unconditional probability. Therefore, we have</p>
<p><span class="math display">\[
\begin{aligned}
\Pr(X(3)  - X(2)= 0|X(2)= 0) 
&amp;= \Pr(X(3)  - X(2)= 0)  \\
&amp;= \frac{\exp(-(0.1)(1))((0.1)(1))^{0}  }{(0!)} \\
&amp;= 0.9048374.
\end{aligned}
\]</span>
4. Again, let <span class="math inline">\(N(t)\)</span> be the number of customers that have arrived up to time <span class="math inline">\(t\)</span>. We have <span class="math inline">\(N(t) \sim \text{Poisson}(\lambda \, t)\)</span> with <span class="math inline">\(\lambda = 2\)</span>.</p>
<pre><code>    1.  $\Pr(N(5) = 0) = \frac{\exp(-(2)(5))((2)(5))^{0}  }{(0!)} = 4.539993\times 10^{-5}$.
    
    2. The 10th customer will arrive after 11:00 am but before 11:05 am is the same as saying that at least 10 customers arrive in 5 minutes between 11:00-11:15 am. 
    </code></pre>
<p><span class="math display">\[\begin{aligned}
    \Pr(N(t,t+5) \ge 10) &amp;= 1 - \Pr(N(t,t+5) \le 9) \\
    &amp;= 
    1- 0.4579297 \\
    &amp;= 0.5420703.
    \end{aligned}\]</span></p>
<pre><code>    3.  Given that a third of customers are men, the probability that a customer is male is 1/3, which is indendent of everything else. By splitting theorem, the &quot;male&quot; and the &quot;female&quot; processes are independent Poisson process with rates 
    </code></pre>
<p><span class="math display">\[\lambda_m = (0.3333333)(2) = 0.6666667, \quad \lambda_f = (0.6666667)(2) = 1.3333333. \]</span></p>
<p>It follows that the required probability can be founded as follows:</p>
<p><span class="math display">\[
\begin{aligned}
\Pr(N_m(5) \ge 4 | N_f(5) \ge 5 ) 
&amp;= \Pr(N_m(5) \ge 4) \\
&amp;= 1 - \Pr(N_m(5) \le 3) \\
&amp;= 0.427014.
\end{aligned}
\]</span>
4. Each interarrival time has exponential distribution <span class="math inline">\(\text{Exp}(2)\)</span>. The sum of 5 independent exponentially distribution random variables, denoted by <span class="math inline">\(Z\)</span>, has gamma distribution <span class="math inline">\(\mathcal{G}(5,2)\)</span>
The probability that a time longer than 5 minutes will pass between one voucher being given out and the next is
<span class="math display">\[ \Pr(Z &gt; 5) = \Pr(N(5) \le 4) = 0.0292527.\]</span></p>
<p>Here we use <span class="math inline">\(N(5) \sim \text{Poisson}(5\times 2)\)</span>. Alternatively, the following command in R produces the required result <code>pgamma(5, shape = 5, rate = 2, lower.tail = FALSE)</code>.</p>
<ol start="5" style="list-style-type: decimal">
<li><p>The solutions are given as follows:</p>
<pre><code> 1. The sum of two independent Poisson processes is also a Poisson process with rate </code></pre>
<p><span class="math inline">\(\lambda_1 + \lambda_2\)</span>. Then the first event of this process (i.e. the time that the first bird arrives) occurs at random time having <span class="math inline">\(\text{Exp}(\lambda_1 + \lambda_2)\)</span> distribution.</p>
<pre><code> 2. According to the superposition theorem, the probability that this bird is a tailorbird is </code></pre></li>
</ol>
<p><span class="math display">\[ \frac{\lambda_1}{\lambda_1 + \lambda_2}. \]</span></p>
<pre><code>    3. The process is homogeneous in time, i.e. only the lenght of the  interval matters. So the distribution of the number of birds in the time interval 
    </code></pre>
<p><span class="math inline">\([t_1, t_2)\)</span> is a Poisson distribution with parameter <span class="math inline">\((\lambda_1 + \lambda_2)(t_2 - t_1).\)</span></p>
<pre><code>    4. The required probability is
    </code></pre>
<p><span class="math display">\[\Pr(\text{TB},\text{TB},\text{TB},\text{P}) = p^3(1-p),\]</span>
where <span class="math inline">\(p = \frac{\lambda_1}{\lambda_1 + \lambda_2}\)</span>, which is the probability that a bird is a tailorbird.</p>
<ol start="6" style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent Poisson distributed random variables with paramers <span class="math inline">\(\lambda_X\)</span> and <span class="math inline">\(\lambda_Y\)</span>. The conditional distribution of <span class="math inline">\(X\)</span> given <span class="math inline">\(N = X + Y = n\)</span> is</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\Pr(X = k | N = n)
&amp;= \Pr(X = k | X + Y = n) \\
&amp;= \Pr(X = k, Y = n - k | X + Y = n) \\
&amp;= \frac{\left( \frac{e^{-\lambda_X}\lambda_X^k}{k!} \right) \times \left( \frac{e^{-\lambda_Y}\lambda_Y^{n-k}}{(n - k)!} \right)}{\left( \frac{e^{-(\lambda_X + \lambda_Y)}(\lambda_X + \lambda_Y)^n}{n!} \right)  } \\
&amp;= \frac{n!}{k!(n - k)!} \left(\frac{\lambda_X}{\lambda_X + \lambda_Y}\right)^k \left(\frac{\lambda_Y}{\lambda_X + \lambda_Y}\right)^{n-k}.
\end{aligned}
\]</span>
Hence this conditional distribution is a bionomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(\frac{\lambda_X}{\lambda_X + \lambda_Y}\)</span>.</p>
<ol start="7" style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(N(t)\)</span> be the number of accidents occurring on the highway and <span class="math inline">\(N_S(t)\)</span> be the process of speeding-related accidents.</p>
<pre><code> 1.  </code></pre>
<p><span class="math display">\[\Pr(N_S(1) = 10) = \frac{\exp(-(20)(0.25))((20)(0.25))^{10}  }{(10!)} = 0.0181328.\]</span></p>
<pre><code> 2. The probability that at least one accident occurs tomorrow is </code></pre>
<p><span class="math display">\[ 1 - e^{-20/7} = 0.9425674.\]</span>
3. There are <span class="math inline">\(n = 60\)</span> accidents occurring in four weeks (<span class="math inline">\(t= 4\)</span> weeks). The number of accidents involve speeding <span class="math inline">\(N_S\)</span> in <span class="math inline">\([0,t]\)</span> has a binomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p = 1/4\)</span>.</p>
<pre><code> The required probability is </code></pre>
<p><span class="math display">\[
\begin{aligned} 
\Pr(N_S(4) &lt; 30 | N(4) = 60) &amp;= \sum_{k = 0}^{29} \binom{60}{k} \left(\frac{1}{4} \right)^k \left(\frac{3}{4} \right)^{60-k} \\
&amp;= 0.9999733. 
\end{aligned}
\]</span>
The probability above can be calculated using the following command in R <code>pbinom(29,60,1/4)</code>.</p></li>
<li><p>Let <span class="math inline">\(X_1, X_2, \ldots\)</span>$ be an i.i.d. sequence where <span class="math inline">\(X_i\)</span> is the number of claims filed after the <span class="math inline">\(i\)</span>th flood. Let <span class="math inline">\(T\)</span> denote the total number of claims filed. Then
<span class="math display">\[ T = X_1 + X_2 + \ldots X_{N_t},\]</span>
where <span class="math inline">\(N_t\)</span> is the number of severe floods that occur by time <span class="math inline">\(t\)</span>.
Using results for random sums of random variables,
<span class="math display">\[ \text{E}(T) = \text{E}(N_t)\text{E}(X_1) = (4t)(60) = 240t,\]</span>
and
<span class="math display">\[\begin{aligned} 
\text{Var}(T) &amp;= \text{Var}(X_1)\text{E}(N_t) + [\text{E}(X_1)]^2 \text{Var}(N_t) = (60)(4t)  + (60)^2(4t) \\
&amp;= 14640t,
\end{aligned}
\]</span>
and, hence, <span class="math inline">\(SD(T) = \sqrt{14640t}\)</span>.</p></li>
</ol>
<p>Note that the distribution of <span class="math inline">\(T\)</span> is said to have a compound Poisson distribution. For more details about how to compute <span class="math inline">\(\text{E}(T)\)</span> and <span class="math inline">\(\text{Var}(T)\)</span>, please refer to the following website: <a href="https://pairote-sat.github.io/SCMA470/collective-risk-model.html#compound-poisson-distributions" class="uri">https://pairote-sat.github.io/SCMA470/collective-risk-model.html#compound-poisson-distributions</a>.</p>
<ol start="9" style="list-style-type: decimal">
<li><p>Let <span class="math inline">\((N_t)_{t\ge0}, (M_t)_{t\ge0}\)</span> and <span class="math inline">\((F_t)_{t\ge0}\)</span> denote the overall birth, male, and female processes, respectively.</p>
<pre><code> 1. Male births form a Poisson process with parameter </code></pre></li>
</ol>
<p><span class="math display">\[\lambda \cdot p = 3(0.52) = 1.56.\]</span>
The number of male births on an 8-hour shift <span class="math inline">\(M_8\)</span> has a Poisson distribution with expectation
<span class="math display">\[ E(M_8) = \lambda \cdot p \cdot 8 = 12.48. \]</span>
and standard deviation
<span class="math display">\[ SD(M_8) = \sqrt{12.48} = 3.5327043. \]</span></p>
<pre><code>    2. Conditional on there being five births in a given interval,the number of boys in that interval has a binomial distribution with parameters 
    </code></pre>
<p><span class="math inline">\(n = 10\)</span> and <span class="math inline">\(p = 0.52\)</span>. The desired probability is</p>
<p><span class="math display">\[ \frac{10!}{6!4!}(0.52)^6(1- 0.52)^4 = 0.2203963 \]</span></p>
<pre><code>3. The required probability is </code></pre>
<p><span class="math display">\[ \Pr(M_4 &gt; 0, F_4 &gt; 0).\]</span></p>
<p>By independence,</p>
<p><span class="math display">\[
\begin{aligned}
 \Pr(M_4 &gt; 0, F_4 = 0) &amp;= 
 \Pr(M_4 &gt; 0)\Pr(F_4 = 0) \\
 &amp;= (1 - e^{-3(0.52)(4)})(e^{-3(1-0.52)(4)}) \\
 &amp;= 0.003145.
\end{aligned}
\]</span></p>
</div>
<div id="tutorial-5" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Tutorial 5</h2>
<ol style="list-style-type: decimal">
<li><p>Suppose that we observe life <span class="math inline">\(i\)</span> at exact age 74 years and 3 months.
The observation will continue until the earlier of the life’s 75th
birthday or death. Assume that the force of mortality equal 0.08.</p>
<ol style="list-style-type: decimal">
<li><p>Calculate the probability function of <span class="math inline">\(D_i\)</span>, i.e. calculate
<span class="math inline">\(\Pr(D_i = 0)\)</span> and <span class="math inline">\(\Pr(D_i = 1)\)</span>.</p></li>
<li><p>Calculate <span class="math inline">\(\textrm{E}[D_i]\)</span>.</p></li>
<li><p>Calculate the probability density/mass function of <span class="math inline">\(V_i\)</span> (Hint:
consider two cases (i) when <span class="math inline">\(v_i &lt; 0.75\)</span> and (ii) when
<span class="math inline">\(v_i = 0.75\)</span>).</p></li>
<li><p>Calculate <span class="math inline">\(\textrm{E}[V_i]\)</span>.</p></li>
</ol></li>
<li><p>For life <span class="math inline">\(i\)</span>, recall that</p>
<ul>
<li><p><span class="math inline">\(x+ a_i\)</span> is the age at which observation
begins,<span class="math inline">\(\quad 0 \le a_i &lt; 1\)</span>.</p></li>
<li><p><span class="math inline">\(x+ b_i\)</span> is the age at which observation ends, if life does not
die, <span class="math inline">\(\quad 0 \le b_i &lt; 1\)</span>.</p></li>
</ul>
<p>The terms <span class="math inline">\(a_i\)</span> and <span class="math inline">\(b_i\)</span> are known constants.</p>
<ol style="list-style-type: decimal">
<li><p>Show that
<span class="math inline">\(\displaystyle \textrm{E}[D_i] = \int_0^{b_i - a_i} e^{-\mu t} \mu \, \text{d}t.\)</span></p></li>
<li><p>Show that
<span class="math inline">\(\displaystyle \textrm{E}[V_i] = \int_0^{b_i - a_i}t e^{-\mu t} \mu \, \text{d}t + (b_i - a_i) e^{-\mu(b_i - a_i)}.\)</span></p></li>
</ol></li>
<li><p>In terms of the probability function of <span class="math inline">\((D_i, V_i)\)</span>,</p>
<ol style="list-style-type: decimal">
<li><p>explain why the following expression holds:
<span class="math display">\[\int_0^{b_i - a_i} e^{-\mu v_i} \mu \, \text{d}v_i + e^{-\mu(b_i - a_i)} = 1.\]</span></p></li>
<li><p>Differentiating the above expression with respect to <span class="math inline">\(\mu\)</span>, show
that <span class="math display">\[\textrm{E}[ D_i - \mu V_i] = 0 .\]</span></p></li>
<li><p>Differentiating the above expression twice with respect to
<span class="math inline">\(\mu\)</span>, show that <span class="math display">\[\textrm{Var}[D_i - \mu V_i] = \textrm{E}[D_i].\]</span></p></li>
</ol></li>
<li><p>Show that
<span class="math display">\[\textrm{Var}[\hat{\mu}] \rightarrow  \left. \frac{\mu^2}{\textrm{E}[D]} \right\vert_{ \mu = \mu_0 },\]</span>
and hence
<span class="math display">\[\textrm{Var}[\hat{\mu}] \rightarrow \left. \frac{\mu}{\textrm{E}[V]} \right\vert_{ \mu = \mu_0 }=  \frac{\mu_0}{E[V]}.\]</span></p></li>
<li><p>1300 lives aged between 70 and 71 have been observed. We wish to
calculate the force of mortality over this period.</p>
<p>Suppose the true value of the force of mortality is 0.12 for lives
aged between 70 and 71. Calculate the probability that the observed
force of mortality is greater than 0.15.</p>
<p>Hint: use the fact that the estimate <span class="math inline">\(\hat{\mu}\)</span> is asymptotically
normal
<span class="math display">\[\hat{\mu} \approx \mathcal{N}( \mu_0,   \frac{\mu_0}{E[V]} ).\]</span></p></li>
<li><p>Consider the following mortality data on ten lives all aged between
<span class="math inline">\(75\)</span> and <span class="math inline">\(76\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="center">Life</th>
<th align="center"><span class="math inline">\(a_i\)</span></th>
<th align="center"><span class="math inline">\(b_i\)</span></th>
<th align="center"><span class="math inline">\(d_i\)</span></th>
<th align="center"><span class="math inline">\(t_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.5</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.75</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">0.1</td>
<td align="center">0.6</td>
<td align="center">1</td>
<td align="center">0.5</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">0.2</td>
<td align="center">0.7</td>
<td align="center">1</td>
<td align="center">0.6</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">0.2</td>
<td align="center">0.4</td>
<td align="center">0</td>
<td align="center">0.4</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">0.5</td>
<td align="center">0.8</td>
<td align="center">0</td>
<td align="center">0.8</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">0.5</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li><p>Using the Markov model, estimate the force of mortality
<span class="math inline">\(\mu_{75}\)</span> assuming that it is constant from <span class="math inline">\(75\)</span> to <span class="math inline">\(76\)</span>.</p></li>
<li><p>Estimate the variance of <span class="math inline">\(\hat{\mu}\)</span>.</p></li>
<li><p>Construct the 95% confidence interval for the force of
mortality.</p></li>
<li><p>Estimate <span class="math inline">\(\hat{q}_{75} = {}_{1}\hat{q}_{75}\)</span>, the probability of
a life aged (75) dying within one year.</p></li>
<li><p>Use the <span class="math inline">\(\Delta-\)</span>method to estimate the variance of
<span class="math inline">\(\hat{q}_{75}\)</span>.</p></li>
</ol></li>
</ol>
<p><strong>Solutions</strong></p>
<ol style="list-style-type: decimal">
<li><ol style="list-style-type: decimal">
<li>In this question, <span class="math inline">\(a_i = 0.25, b_i = 1\)</span> and <span class="math inline">\(V_i\)</span> is a random variable taking the values between 0 and 0.75. Moreover, <span class="math inline">\(V_i\)</span> has a mixed distribution with a probability mass at 0.75.</li>
</ol>
We know that</li>
</ol>
<p><span class="math display">\[ {}_{t}p_{x} = \exp\left( - \int_0^t  \mu_{x+s} \, ds \right) = \exp(-\mu t) =  \exp(-0.08 t).\]</span></p>
<p>Now</p>
<p><span class="math display">\[
  \begin{aligned}
\Pr(D_i = 0) &amp;= {}_{0.75}p_{74.25}  \\
&amp;= \exp(-0.08(0.75) ) = 0.9417645 \\
\Pr(D_i = 1) &amp;= 1 - {}_{0.75}p_{74}  \\
&amp;= 1 - \exp(-0.08(0.75) ) = 0.0582355
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li></li>
</ol>
<p><span class="math display">\[\text{E}[D_i] = (0)(0.9417645) + (1)(0.0582355) = 0.0582355.\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>The probability density/mass function of</li>
</ol>
<p><span class="math inline">\(V_i\)</span> is</p>
<p><span class="math display">\[
  \begin{aligned}
f(v_i) &amp;=
  \begin{cases}
{}_{v_i}p_{74.25} \mu_{74.25 + v_i} &amp; ; v_i &lt; 0.75\\
{}_{0.75}p_{74.25} &amp;; v_i = 0.75
\end{cases}
\end{aligned}
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
  \begin{aligned}
f(v_i) &amp;=
  \begin{cases}
\exp(-0.08(0.75) )\times 0.08 &amp; ; v_i &lt; 0.75\\
0.9417645 &amp;; v_i = 0.75
\end{cases}
\end{aligned}
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li></li>
</ol>
<p><span class="math display">\[\text{E}[V_i] = \int_0^{0.75} t \exp(-0.08\,t) \times 0.08 \, dt + (0.9417645)(0.75).\]</span></p>
<p>Using integration by parts, the integral becomes:</p>
<p><span class="math display">\[
  \begin{aligned}
(-t \exp(-0.08 t))|_0^{0.75} + \int_0^{0.75} \exp(-0.08 t) \, dt = 0.0216.
\end{aligned}
\]</span></p>
<p>This gives</p>
<p><span class="math display">\[\text{E}[V_i] = 0.0216 + (0.9417645)(0.75) = 0.7279234.\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Similar to the previous question, we have that <span class="math inline">\(D_i\)</span> is the random varialbe taking two possible values 0 and 1. Hence</li>
</ol>
<p><span class="math display">\[\text{E}[D_i] =  1 \times \int_0^{b_i - a_i}  {}_{t}p_{x + a_i} \mu_{x + a_i + t} \, dt .\]</span></p>
<p>Assuming a constant transtition intensity <span class="math inline">\(\mu\)</span> results in</p>
<p><span class="math display">\[\text{E}[D_i] =  1 \times \int_0^{b_i - a_i}  \exp(-\mu t) \mu \, dt .\]</span></p>
<p>Similarly,</p>
<p><span class="math display">\[
  \begin{aligned}
\text{E}[V_i] &amp;=  \int_0^{b_i - a_i} \Pr(\text{life dies at time } t) \cdot t \, dt + (b_i - a_i)\cdot \Pr(\text{life survives}) \\
&amp;= \int_0^{b_i - a_i}  \left(\exp(-\mu t) \mu \right)  \cdot t \, dt + (b_i - a_i)\cdot \exp(-\mu (b_i - a_i))
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><ol style="list-style-type: decimal">
<li>The expression</li>
</ol></li>
</ol>
<p><span class="math display">\[\int_0^{b_i - a_i} e^{-\mu v_i} \mu \, \text{d}v_i + e^{-\mu(b_i - a_i)} = 1.\]</span></p>
<p>holds because we simply integrate/sum the probability function of</p>
<p><span class="math inline">\((D_i, V_i)\)</span> over all possible events.</p>
<pre><code>2. Differentiating the above expression with respect to </code></pre>
<p><span class="math inline">\(\mu\)</span> results in</p>
<p><span class="math display">\[\begin{aligned}
0 &amp;= \frac{d}{d \mu} \left( \int_0^{b_i - a_i} e^{-\mu v_i} \mu \, \text{d}v_i + e^{-\mu(b_i - a_i)}  \right) \\
&amp;=   \int_0^{b_i - a_i} \frac{d}{d \mu} \left( e^{-\mu v_i} \mu \, \text{d}v_i\right) + \frac{d}{d \mu} e^{-\mu(b_i - a_i)}   \\
&amp;=   - \int_0^{b_i - a_i}   \mu v_i e^{-\mu v_i}  \, \text{d}v_i + \int_0^{b_i - a_i}  e^{-\mu v_i}  \, \text{d}v_i  - (b_i - a_i) e^{-\mu(b_i - a_i)}
\end{aligned}.\]</span></p>
<p>This simplifies to</p>
<p><span class="math display">\[\textrm{E}[ D_i - \mu V_i] = 0 .\]</span>
3. We proceed in the same way as in the previous question.</p>
<ol start="4" style="list-style-type: decimal">
<li>Using the Cramer-Rao lower bound which states as follows:</li>
</ol>
<p><span class="math display">\[\text{Var}[\tilde{\mu}] = -\frac{1}{\text{E}[\frac{d^2}{d\mu^2}\log L(\mu)]},\]</span></p>
<p>where <span class="math inline">\(L(\mu)\)</span> is the likelihood function. In this case,</p>
<p><span class="math display">\[L(\mu) = \mu^d \exp(-\mu v)\]</span>
and hence
<span class="math display">\[\text{Var}[\tilde{\mu}] = -\frac{1}{\text{E}[-\frac{D}{\mu^2}]} = \frac{\mu^2}{\text{E}[D]}.\]</span></p>
<p>Using the previous result:</p>
<p><span class="math display">\[\textrm{E}[ D_i - \mu V_i] = 0 .\]</span></p>
<p>This implies that
<span class="math display">\[\text{Var}[\tilde{\mu}] =  \frac{\mu^2}{\text{E}[D]} = \frac{\mu}{\text{E}[V]}\bigg|_{\mu = \mu_0} = \frac{\mu_0}{\text{E}[V]}.\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>As in Question 2, the expected waiting time for the <span class="math inline">\(i\)</span>th life with the force of mortality of 0.12 is</li>
</ol>
<p><span class="math display">\[
  \begin{aligned}
\text{E}[V_i]
&amp;= \int_0^{b_i - a_i}  \left(\exp(-\mu t) \mu \right)  \cdot t \, dt + (b_i - a_i)\cdot \exp(-\mu (b_i - a_i)) \\
&amp;= \int_0^{b_i - a_i}  \left(0.12 t \exp(-0.12 t)  \right)   \, dt + 1\cdot \exp(-0.12\cdot 1)\\
&amp;= -\exp(-0.12) + \frac{1}{0.12}(1 - \exp(-0.12)) + \exp(-0.12) \\
&amp;=0.9423297.
\end{aligned}
\]</span></p>
<p>Hence, the total waiting time is</p>
<p><span class="math display">\[\text{E}[V] = 1300 \cdot \text{E}[V_i] = 1225.0286022\]</span></p>
<p>From the asymptotic properties of the maximum likelihood estimate,</p>
<p><span class="math display">\[\tilde{\mu} \sim \mathcal{N}(\mu, \frac{\mu}{\text{E}[V]}) = \mathcal{N}(0.12, \frac{0.12}{1225.0286022}) = \mathcal{N}(0.12,0.0098973^2)\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[\begin{aligned}
\Pr(\tilde{\mu} &gt; 0.15) &amp;=
  1 - \Pr(\tilde{\mu} \le 0.15) \\
&amp;= 1 - \Pr(\frac{\tilde{\mu} - 0.12 }{0.0098973} \le \frac{0.15 - 0.12   }{0.0098973}) \\
&amp;= 1 - \Pr(Z \le \frac{0.15 - 0.12   }{0.0098973}) \\
&amp;= 1 - \Phi(\frac{0.15-0.12}{0.0098973}) \\
&amp;= 1 - \Phi(3.0311243) \\
&amp;= 1- 0.9987818 \\
&amp;= 0.0012182,
\end{aligned}
\]</span>
where <span class="math inline">\(\Phi\)</span> is the cumulative density function of the standard normal.</p>
<ol start="6" style="list-style-type: decimal">
<li>Similar to the lecture handout.</li>
</ol>
</div>
<div id="tutorial-6" class="section level2" number="6.6">
<h2><span class="header-section-number">6.6</span> Tutorial 6</h2>
<ol style="list-style-type: decimal">
<li>Consider the 3-state model of terminal illness for healthy, ill and
dead states as shown below.</li>
</ol>
<div class="figure"><span id="fig:tikz-ex0"></span>
<img src="SCMA469Bookdownproj_files/figure-html/tikz-ex0-1.png" alt="The 3-state model of terminal illness" width="672" />
<p class="caption">
Figure 6.1: The 3-state model of terminal illness
</p>
</div>
<pre><code>1.  What can you say about </code></pre>
<p><span class="math inline">\(p_{hh}(t)\)</span> and <span class="math inline">\(p_{\overline{hh}}(t)\)</span>,
and about <span class="math inline">\(p_{ii}(t)\)</span> and <span class="math inline">\(p_{\overline{ii}}(t)\)</span>?</p>
<pre><code>2.  Write down the Kolmogorov forward differential equations (FDE)
    for </code></pre>
<p><span class="math inline">\(\frac{d}{dt}p_{hh}(t)\)</span>, <span class="math inline">\(\frac{d}{dt}p_{ii}(t)\)</span> and solve
these equations.</p>
<pre><code>3.  Write down the Kolmogorov forward differential equations (FDE)
    for 
    </code></pre>
<p><span class="math inline">\(\frac{d}{dt}p_{hi}(t)\)</span>, <span class="math inline">\(\frac{d}{dt}p_{hd}(t)\)</span> and explain
how to solve these equations.</p>
<ol start="2" style="list-style-type: decimal">
<li>Consider a model of the
mortality of two lives (husband and wife) consisting of for states :</li>
</ol>
<ul>
<li><p><span class="math inline">\(b =\)</span> both lives are alive,</p></li>
<li><p><span class="math inline">\(u =\)</span> husband is alive, but wife is dead,</p></li>
<li><p><span class="math inline">\(v =\)</span> wife is alive, but husband is dead, and</p></li>
<li><p><span class="math inline">\(d =\)</span> both are dead.</p></li>
</ul>
<div class="figure"><span id="fig:tikz-ex1"></span>
<img src="SCMA469Bookdownproj_files/figure-html/tikz-ex1-1.png" alt="A model of the mortality of two lives" width="672" />
<p class="caption">
Figure 6.2: A model of the mortality of two lives
</p>
</div>
<pre><code>The model is also referred to as the joint life and last survivor
model. Write down the Kolmogorov equation for</code></pre>
<p><span class="math inline">\(\frac{d}{dt}p_{bu}(t)\)</span>, <span class="math inline">\(\frac{d}{dt}p_{bv}(t)\)</span> and
<span class="math inline">\(\frac{d}{dt}p_{bd}(t)\)</span>.</p>
<ol start="3" style="list-style-type: decimal">
<li>A group of lives who hold health insurance policies can be
classified into able (<span class="math inline">\(a\)</span>), ill (<span class="math inline">\(i\)</span>), dead (<span class="math inline">\(d\)</span>) and withdrawn
(<span class="math inline">\(w\)</span>). The lives can move between state according to the following
diagram:</li>
</ol>
<div class="figure"><span id="fig:tikz-ex2"></span>
<img src="SCMA469Bookdownproj_files/figure-html/tikz-ex2-1.png" alt="A Markov model for health insurance policies" width="672" />
<p class="caption">
Figure 6.3: A Markov model for health insurance policies
</p>
</div>
<pre><code>Assuming that all transition rates are constant, write down the
Kolmogorov forward differential equations (FDE) for</code></pre>
<p><span class="math inline">\(p_{aa}(t), p_{ai}(t)\)</span> and <span class="math inline">\(p_{aw}(t)\)</span>.</p>
<ol start="4" style="list-style-type: decimal">
<li>An actuary wishes to study a model in which states relate to marital
status comprising of five states, single, married, divorced, widowed
and dead. Draw the transition diagram that illustrate the possible
transitions between these five states.</li>
</ol>
<p><strong>Solution:</strong></p>
<ol style="list-style-type: decimal">
<li>The transition rate matrix <span class="math inline">\(Q\)</span> of this Markov model is
<span class="math display">\[
  Q = \begin{bmatrix}
  -(\lambda + \mu) &amp; \lambda &amp; \mu   \\
  0 &amp; -\nu &amp; \nu   \\
  0 &amp; 0 &amp; 0\end{bmatrix}.
\]</span>
1. Return to the healthy state and ill states is impossible. Therefore</li>
</ol>
<p><span class="math display">\[p_{hh}(t) = p_{\overline{hh}}(t) \text{ and }
  p_{ii}(t)  = p_{\overline{ii}}(t).\]</span></p>
<pre><code>2. The Kolmogorov forward differential equations (FDE) for </code></pre>
<p><span class="math inline">\(p_{hh}(t)\)</span> is</p>
<p><span class="math display">\[
    \begin{aligned}
  \frac{d}{dt}p_{hh}(t) &amp;= p_{hh}(t) q_{hh} + p_{hi}(t) q_{ih} + p_{hd}(t) q_{dh}  \\
  &amp;= -(\lambda + \mu) p_{hh}(t)  + (0) p_{hi}(t) + (0) p_{hd}(t)  \\
  &amp;= -(\lambda + \mu) p_{hh}(t).  
  \end{aligned}
\]</span></p>
<pre><code>The solution to the differential equation together with the initial condition $p_{hh}(0) = 1$ is</code></pre>
<p><span class="math display">\[ p_{hh}(t) = e^{-(\lambda + \mu)t}.\]</span></p>
<pre><code>Similarly, we obtain</code></pre>
<p><span class="math display">\[
    \begin{aligned}
  \frac{d}{dt}p_{ii}(t) &amp;= p_{ii}(t) q_{ii} \\
  &amp;= -\nu \, p_{ii}(t).  
  \end{aligned}
\]</span></p>
<pre><code>Solving the differential equation with $p_{ii}(0) = 1$ is</code></pre>
<p><span class="math display">\[ p_{ii}(t) = e^{-\nu \, t}.\]</span></p>
<pre><code>3. The Kolmogorov forward differential equations (FDE) for </code></pre>
<p><span class="math inline">\(p_{hi}(t)\)</span> and <span class="math inline">\(p_{hd}(t)\)</span>are given as follows:</p>
<p><span class="math display">\[\begin{aligned}
  \frac{d}{dt}p_{hi}(t) &amp;= p_{hh}(t) q_{hi} + p_{hi}(t) q_{ii} + p_{hd}(t) q_{di}  \quad (1) \\
  &amp;= \lambda p_{hh}(t)  -\nu p_{hi}(t)  + (0) p_{hd}(t)   \\
  &amp;= \lambda p_{hh}(t)  -\nu p_{hi}(t) \\
  \frac{d}{dt}p_{hd}(t) &amp;= p_{hh}(t) q_{hd} + p_{hi}(t) q_{id} + p_{hd}(t) q_{dd}  \quad (2) \\
  &amp;= \mu p_{hh}(t)  + \nu p_{hi}(t)  + (0) p_{hd}(t)   \\
  &amp;= \mu p_{hh}(t)  +\nu p_{hi}(t). \\
  \end{aligned}
\]</span></p>
<pre><code>To solve the first equation, we substitute </code></pre>
<p><span class="math inline">\(p_{hh}(t)\)</span> by <span class="math inline">\(e^{-(\lambda + \mu)t}\)</span> into the equation, which reduces to</p>
<p><span class="math display">\[ \frac{d}{dt}p_{hi}(t) + \nu p_{hi}(t)  =\lambda e^{-(\lambda + \mu)t}.\]</span>
This differential equation is linear with the initial condition <span class="math inline">\(p_{hi}(0) = 0\)</span> and , hence, can be solved by a general method.</p>
<p>In order to solve for</p>
<p><span class="math inline">\(p_{hd}(t)\)</span> in Eq. (2), we note that both <span class="math inline">\(p_{hh}(t)\)</span> and <span class="math inline">\(p_{hi}(t)\)</span> are known so we can solve the equation for <span class="math inline">\(p_{hd}(t)\)</span> as well.</p>
<ol start="2" style="list-style-type: decimal">
<li>The transition rate matrix <span class="math inline">\(Q\)</span> is</li>
</ol>
<p><span class="math display">\[P = \begin{bmatrix}
  -(\alpha_1 + \beta_1) &amp; \alpha_1 &amp; \beta_1 &amp; 0   \\
  0 &amp; -( \beta_2) &amp; 0 &amp;  \beta_2   \\
  0 &amp; 0 &amp; -\alpha_2  &amp; \alpha_2 \\
  0 &amp; 0 &amp; 0  &amp; 0 \\
\end{bmatrix}.\]</span>
Then, the Kolmogorov forward differential equations (FDE) for <span class="math inline">\(p_{bb}(t), p_{bu}(t), p_{bv}(t)\)</span> and <span class="math inline">\(p_{bd}(t)\)</span> are given as follows:</p>
<p><span class="math display">\[
    \begin{aligned}
  \frac{d}{dt}p_{bb}(t) &amp;= p_{bb}(t) q_{bb} + p_{bu}(t) q_{ub} + p_{bv}(t) q_{vb} + p_{bd}(t) q_{db} \\
  &amp;=  -(\alpha_1 + \beta_1) p_{bb}(t)  + (0) p_{bu}(t)  + (0) p_{bv}(t) + (0) p_{bd}(t)    \\
  &amp;= -(\alpha_1 + \beta_1) p_{bb}(t) \\
  \frac{d}{dt}p_{bu}(t) &amp;= p_{bb}(t) q_{bu} + p_{bu}(t) q_{uu} + p_{bv}(t) q_{vu} + p_{bd}(t) q_{du} \\
  &amp;=  \alpha_1  p_{bb}(t)  - \beta_2 p_{bu}(t)  + (0) p_{bv}(t) + (0) p_{bd}(t)    \\
  &amp;= \alpha_1  p_{bb}(t)  - \beta_2 p_{bu}(t)  \\
  \frac{d}{dt}p_{bv}(t) &amp;= p_{bb}(t) q_{bv} + p_{bu}(t) q_{uv} + p_{bv}(t) q_{vv} + p_{bd}(t) q_{dv} \\
  &amp;=  \beta_1  p_{bb}(t)  + (0) p_{bu}(t)  - \alpha_2 p_{bv}(t) + (0) p_{bd}(t)    \\
  &amp;=  \beta_1  p_{bb}(t)   - \alpha_2 p_{bv}(t)  \\
  \frac{d}{dt}p_{bd}(t) &amp;= p_{bb}(t) q_{bd} + p_{bu}(t) q_{ud} + p_{bv}(t) q_{vd} + p_{bd}(t) q_{dd} \\
  &amp;=  (0)  p_{bb}(t)  + \beta_2 p_{bu}(t)  + \alpha_2 p_{bv}(t) + (0) p_{bd}(t)    \\
  &amp;=   \beta_2 p_{bu}(t)  + \alpha_2 p_{bv}(t).   \\
  \end{aligned}\]</span></p>
<pre><code>Note that </code></pre>
<p><span class="math display">\[ \frac{d}{dt}(p_{bb}(t) + p_{bu}(t) + p_{bv}(t) + p_{bd}(t)) = 0,\]</span>
which implies that
<span class="math display">\[ p_{bb}(t) + p_{bu}(t) + p_{bv}(t) + p_{bd}(t) = \text{constant} = 1.\]</span></p>
<pre><code>3. The transition rate matrix $Q$ is</code></pre>
<p><span class="math display">\[P = \begin{bmatrix}
  -(\sigma + \omega + \mu) &amp; \sigma &amp; \omega &amp; \mu   \\
  \rho &amp; -(\rho + \mu) &amp; 0 &amp; \mu   \\
  0 &amp; 0 &amp; 0  &amp; 0 \\
  0 &amp; 0 &amp; 0  &amp; 0 \\
\end{bmatrix}.\]</span>
Then, the Kolmogorov forward differential equations (FDE) for <span class="math inline">\(p_{aa}(t), p_{ai}(t)\)</span> and <span class="math inline">\(p_{aw}(t)\)</span> are given as follows:</p>
<p><span class="math display">\[\begin{aligned}
  \frac{d}{dt}p_{aa}(t) &amp;= p_{aa}(t) q_{aa} + p_{ai}(t) q_{ia} + p_{aw}(t) q_{wa} + p_{ad}(t) q_{da} \\
  &amp;= -(\sigma + \omega + \mu) p_{aa}(t)  + \rho p_{ai}(t) + (0)p_{aw}(t)  + (0)p_{ad}(t) \\
  &amp;= -(\sigma + \omega + \mu) p_{aa}(t)  + \rho p_{ai}(t) \\
  \frac{d}{dt}p_{ai}(t) 
  &amp;= p_{aa}(t) q_{ai} + p_{ai}(t) q_{ii} + p_{aw}(t) q_{wi} + p_{ad}(t) q_{di} \\
  &amp;= \sigma p_{aa}(t) -(\rho + \mu)  p_{ai}(t) + (0)p_{aw}(t)  + (0) p_{ad}(t)  \\
  &amp;= \sigma p_{aa}(t) -(\rho + \mu)  p_{ai}(t)  \\
  \frac{d}{dt}p_{aw}(t) &amp;= \omega p_{aa}(t).
\end{aligned}\]</span></p>
<pre><code>4. The transition diagram for a model of maritial status is illusrated in the figure below:</code></pre>
<div class="figure"><span id="fig:tikz-ex6"></span>
<img src="SCMA469Bookdownproj_files/figure-html/tikz-ex6-1.png" alt="The 5-state model of maritial status" width="672" />
<p class="caption">
Figure 6.4: The 5-state model of maritial status
</p>
</div>
</div>
<div id="tutorial-7" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> Tutorial 7</h2>
<!-- CT4201004 -->
<p><strong>Questions are modified from the past CT4 exams from IFoA.</strong></p>
<ol style="list-style-type: decimal">
<li>For each of the following processes:</li>
</ol>
<ul>
<li>counting process;</li>
<li>general random walk;</li>
<li>Poisson process;</li>
<li>Markov jump chain;</li>
<li>Geometric Brownian motion.
<ol style="list-style-type: decimal">
<li>State whether the state space is discrete, continuous or can be either.</li>
<li>State whether the time set is discrete, continuous, or can be either.</li>
</ol></li>
</ul>
<p>Here the stochastic process <span class="math inline">\(\{X_n: n = 0, 1, 2, \ldots\}\)</span> is known as a general random walk if it satisfies
<span class="math display">\[X_n = X_0 + \sum_{i=1}^n Z_i, \]</span>
where <span class="math inline">\(X_0\)</span> is independent of i.i.d. random variables <span class="math inline">\(Z_1,Z_2, \ldots\)</span>.</p>
<p><strong>Solution:</strong></p>
<table>
<thead>
<tr class="header">
<th align="center">Process</th>
<th align="center">State Space</th>
<th align="center">Time Set</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">counting process</td>
<td align="center">Discrete</td>
<td align="center">Discrete</td>
</tr>
<tr class="even">
<td align="center">general random walk</td>
<td align="center">Discrete or continuous</td>
<td align="center">Discrete</td>
</tr>
<tr class="odd">
<td align="center">Poisson process</td>
<td align="center">Discrete</td>
<td align="center">continuous</td>
</tr>
<tr class="even">
<td align="center">Markov Jump Chain</td>
<td align="center">Discrete</td>
<td align="center">Discrete</td>
</tr>
<tr class="odd">
<td align="center">Geometric Brownian motion</td>
<td align="center">continuous</td>
<td align="center">continuous</td>
</tr>
</tbody>
</table>
<!-- CT4201004 -->
<ol start="2" style="list-style-type: decimal">
<li>Ten years ago, a food and beverage company launched a new product, Boba Ceylon Milk Tea. The product was successful and consumption increased rapidly from the first sale.</li>
</ol>
<p>In order to plan future investment in production capacity, the manufacturer wants to forecast the future demand for Boba Ceylon Milk Tea. It has data on age-specific consumption rates for the last ten years, as well as population projections by age for the next twenty years. It proposes the following modelling strategy:</p>
<ul>
<li><p>Extrapolate past age-specific consumption rates to forecast age-specific consumption rates for the next 20 years.</p></li>
<li><p>Applying the projected age-specific consumption rates to the projected population by age to obtain the estimated total product consumption by age for each of the next 20 years</p></li>
<li><p>Add the results to get the total demand for each year.</p></li>
</ul>
<p>Describe the advantages and disadvantages of this strategy.</p>
<p><strong>Solution:</strong></p>
<p><strong>Advantages</strong></p>
<ul>
<li><p>The model is easy to understand and to communicate.</p></li>
<li><p>The model takes into account an important source of variation in consumption rates, namely age.</p></li>
<li><p>The model is simple and inexpensive to implement.</p></li>
<li><p>Previous data on consumption by age should be fairly accurate.</p></li>
<li><p>The model can be easily adapted to different population projections OR takes into account future changes in the population.</p></li>
</ul>
<p><strong>Disadvantages</strong></p>
<ul>
<li><p>Past trends in consumption by age may not be a good guide to future trends.</p></li>
<li><p>Extrapolating past age-specific consumption rates can be complex or difficult and can be done in a variety of ways.</p></li>
<li><p>Beverage consumption may be affected by the state of the economy, e.g. whether there is a recession.</p></li>
<li><p>Factors other than age may play a role in determining consumption, e.g. advertising expenditure.</p></li>
<li><p>Consumption may depend on pricing, which may change in the future.</p></li>
<li><p>It is unlikely that a rapid increase in consumption can be sustained over time as there is likely to be a cap on the amount of Boba Ceylon Milk Tea a person can eat.</p></li>
<li><p>Projections of future population by age may not be accurate as they depend on future fertility, mortality and migration rates.</p></li>
<li><p>The proposed strategy does not include a test of the sensitivity of aggregate demand to changes in projected population or deviations in future consumption trends from those used in the model.</p></li>
<li><p>Unforeseen events such as the introduction of new products by competitors or increasing health awareness among the population may affect future consumption.</p></li>
<li><p>Boba Ceylon Milk Tea consumption may vary with cohort rather than age, and the model does not capture cohort effects.</p></li>
</ul>
<!-- CT4_201504 -->
<ol start="3" style="list-style-type: decimal">
<li><ol style="list-style-type: decimal">
<li><p>State the steps you would go through in creating a model.</p></li>
<li><p>For three of these steps, discuss the specific problems that might be encountered in building a model for pricing an COVID -19 insurance product.</p></li>
</ol></li>
</ol>
<p><strong>Solution</strong></p>
<pre><code>1. </code></pre>
<ul>
<li><p>Develop a well-defined set of objectives to be achieved through the modelling process.</p></li>
<li><p>Plan the modelling process and how the model will be validated.</p></li>
<li><p>Collect and analyse the necessary data.</p></li>
<li><p>Define the parameters for the model and consider appropriate parameter values.</p></li>
<li><p>Define the model first by capturing the essence of the real system (refining the level of detail of the model can be done at a later stage).</p></li>
<li><p>Involve experts on the real system you are trying to mimic to get feedback on the validity of the conceptual model.</p></li>
<li><p>Decide whether a simulation package or general-purpose language is appropriate for implementing the model.</p></li>
<li><p>Choose a statistically reliable random number generator that performs adequately in the context of the model’s complexity.</p></li>
<li><p>Write the computer program for the model.</p></li>
<li><p>Debug the program to ensure that it performs the operations specified in the model definition.</p></li>
<li><p>Test the adequacy of the model’s output.</p></li>
<li><p>Check the adequacy of the model with respect to small changes in input parameters and consider them carefully.</p></li>
<li><p>Analyse the output of the model.</p></li>
<li><p>Ensure that all relevant technical guidance has been followed.</p></li>
<li><p>Communicate and document the results of the model.</p>
<ol start="2" style="list-style-type: decimal">
<li></li>
</ol></li>
</ul>
<p><strong>Objective.</strong></p>
<ul>
<li><p>Is a single pricing table needed for a particular coverage/period/type of illness?</p></li>
<li><p>Is a price range needed for different levels of coverage?</p></li>
<li><p>Is a simple price needed or a confidence interval around profitability, etc.?</p></li>
</ul>
<p><strong>Data.</strong></p>
<ul>
<li><p>Look at national industry data and possibly international data on illness and recovery rates.</p></li>
<li><p>Pay attention to the definition of illness.</p></li>
<li><p>Look at trends.</p></li>
<li><p>Are recovery rates affected by reduction in benefits?</p></li>
<li><p>Could future trends change due to medical developments, changes in government policy on government benefits or economic influences?</p></li>
<li><p>What is the expected level of expenses? This will depend on expected sales (and commission levels).</p></li>
<li><p>Since this is a new product, the company may not have experience monitoring claims. Look at industry and internal data for new product launches.</p></li>
</ul>
<p><strong>Modelling Process.</strong></p>
<ul>
<li><p>Start with a simple model that accounts for sickness and recovery rates.</p></li>
<li><p>Add costs and reserving later.</p></li>
</ul>
<p><strong>Define the model.</strong></p>
<ul>
<li>The type of model is determined by the objectives: deterministic for a simple set of premium rates, stochastic if confidence intervals are required.</li>
</ul>
<p><strong>Reasonableness of the result.</strong></p>
<ul>
<li><p>Look at the premium rates generated and compare them to those of competitors in the market.</p></li>
<li><p>Are they roughly where you would expect them to be?</p></li>
<li><p>Sensitivity to changes in input parameters.</p></li>
<li><p>Change each key parameter slightly; sickness rates, recovery rate, and make sure the impact on premium rates is not too great.</p></li>
<li><p>If it is, review the product design.
Can the risk be reduced by, for example, introducing annually reviewable premium rates?</p></li>
</ul>
<p><strong>Comply with professional guidelines and the regulatory environment.</strong></p>
<ul>
<li>Look at professional guidelines and regulatory requirements.</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="poisson-processes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="applications.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-Tutorials.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/pairote-sat/SCMA469/blob/master/05-Tutorials.Rmd",
"text": null
},
"download": ["SCMA469Bookdownproj.pdf", "SCMA469Bookdownproj.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
