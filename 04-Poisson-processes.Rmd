# Poisson processes

## Introduction


In this chapter, we will consider a class of stochastic processes,
namely Poisson processes, that can be used to model the occurrence or
arrival of events over a continuous time interval. Time domains of such
processes are continuous and the state space is the set of whole
numbers.

For instance, consider the number of claims that occur up to time $t$
(denoted by $N(t) = N_t$) from a portfolio of health insurance policies
(or other types of insurance products). Suppose that the average rate of
occurrence of claims per time unit (e.g. day or week ) is given by
$\lambda$.

Here are some questions of interest:

1.  Suppose that on average 20 claims arrive every day (i.e.
    $\lambda = 20$). What is the probability that more than 100 claims
    arrive within a week?

2.  What is the expected time until the next claim?

The model used to model the insurance claims is an example of **Poisson
processes**. The following examples can also be modelled by a Poisson
process:

-   Claims arrivals at an insurance company,

-   Telephone calls to a call center,

-   Accidents occurring on the highway.

## Poisson process


A **Poisson process** is a special type of counting process. It can be
represented by a continuous time stochastic process $\{N(t)\}_{t \ge 0}$
which takes values in the non-negative integers. The state space is
discrete but the time set is continuous. Here $N(t)$ represents the
number of events in the interval $(0,t]$.

### Counting Process {#counting-process}

A counting process $\{N(t)\}_{t \ge 0}$ is a collection of non-negative,
integer-valued random variables such that if $0 \le s \le t$, then
$N(s) \le N(t)$.

FigureÂ [1](#graphPoisson){reference-type="ref" reference="graphPoisson"}
illustrates a trajectory of the Poisson process. The sample path of a
Poisson process is a right-continuous step function. There are jumps
occurring at time $t_1, t_2, t_3, \ldots$.

<!-- ![ **A trajectory of the Poisson process** -->
<!-- ](PlotPoissonProcess.eps){#graphPoisson width="50%"} -->

We will see that there are several ways to describe a Poisson process.
One can define it by the number of claims that occur up to time $t$ or
the times between those claims when they occur. Main properties of
Poisson processes will be discussed.

For $0 \le s < t$, the number of events in the interval $(s, t]$ is
given by $$N(s,t) = N(t) - N(s).$$ For any interval $I = (s,t]$,
$$N(I) = N(t) - N(s).$$ Therefore, $N(t) = N(0,t)$.

Formally, an integer-valued process $\{N(t)\}_{t \ge 0}$ is a **Poisson
process** with rate $\lambda$ (or intensity) if it satisfies the
following two conditions:

1.  For any $t$ and $h> 0$ ($h$ small), $$\begin{aligned}
        \Pr(N(t+h) - N(t) = 1)  &= \lambda h + o(h)\\
        \Pr(N(t+h) - N(t) = 0)  &= 1- \lambda h + o(h)\\    
        \Pr(N(t+h) - N(t) \ge 2)  &=  o(h)  \end{aligned}$$

2.  For disjoint intervals $I_1, I_2, \ldots, I_k$, the number of events
    $N(I_1), \ldots, N(I_k)$ are independent random variables.

**Notes**
The statement that $f(h) = o(h)$ as $h \rightarrow 0$ means
$\displaystyle\lim_{h\rightarrow 0} \frac{f(h)}{h} = 0$. Examples are
$h^2$, $h^3$, etc.

1.  The probability that an event occurs during the short time interval
    from time $t$ to time $t + h$ is approximately equal to
    $\lambda \, h$ for small $h$, i.e.
    $$\Pr[N(t+h) - N(t) = 1] \approx \lambda\, h.$$ The parameter
    $\lambda$ represents the average rate of occurrence of events (e.g.
    20 claims (or events) per day).

2.  The properties essentially require that, in a very small interval of
    length $h$, we have either a single point (or an occurrence) with
    probability $\lambda h$, or no point with probability
    $1 - \lambda h$.

3.  Any two of the three statements necessarily imply the third (since
    the sum of the probability of all possible outcomes is 1).

Properties of Poisson processes
-------------------------------

In the following example, we show that $N(t)$ is a Poisson random
variable with mean $\lambda t$ . In addition, $N(t +s) - N(s)$ is a
Poisson random variable with mean $\lambda \, t$ , independent of
anything that has occurred before time $s$.

::: {.example}
Show that the process $N(t)$ is a Poisson random variable with mean
$\lambda t$, i.e. $N(t) \sim \text{Poisson}(\lambda \, t)$.
:::

**Solution:**

To show that $N(t) \sim \text{Poisson}(\lambda t)$, we let
$$p_j(t) = \Pr(N(t) = j),$$
which is the probability that there have been exactly $j$ events by time $t$.

We simply need to show that
$$ p_j(t) = \frac{e^{-\lambda t}(\lambda t)^j}{j!}$$

**Case 1:** For any $j >0$ and for small positive $h$, consider the following arguments

$$
\begin{aligned}
p_j(t+h) &=  \Pr(N(t+h) = j) \\
&= \Pr(N(t) = j \text{ and } N(t,t+h) = 0)  \\
&+ \Pr(N(t) = j \text{ and } N(t,t+h) = 1)  \\
&+  \Pr(N(t) = j \text{ and } N(t,t+h) \ge 2)  \\
&= p_j(t)(1 - \lambda h) + p_{j-1}(t)(\lambda h) + o(h)
\end{aligned}
$$
Rearranging the equation and letting $h \rightarrow 0$, we obtain
$$ \frac{d p_j(t)}{dt} = -\lambda p_j(t) + \lambda p_{j-1}(t),$$
with initial condition $p_j(0) = 0 = \Pr(N(0) = j)$.

**Case 2:** For $j = 0$, we can also obtain
$$ \frac{d p_0(t)}{dt} = -\lambda p_0(t)\,$$
with initial condition $p_0(0) = 1 = \Pr(N(0) = 0)$.

We can show that the solution to the initial value problem for both cases is
$$ p_j(t) = \frac{e^{-\lambda t}(\lambda t)^j}{j!}.$$


**Note**
This result explains why it is called the Poisson process, since number
of events in an interval has a Poisson distribution.

::: {.example}
Consider a factory where machinery malfunctions happen as a Poisson
process with rate once per 8 hours. The factory owner wants to estimate
the probability of one or more failures in a given hour.
:::

The following definition provides an alternative way to characterise the
Poisson process.

Poisson process : Definition 2
------------------------------

A process $\{N(t)\}_{t \ge 0}$ that satisfies the following properties
is called a **Poisson process** with rate (or intensity) $\lambda > 0$:

1.  $N_0 = 0$.

2.  **Poisson distribution** For all $t \ge 0$, $N(t)$ has as a Poisson
    process with parameter (mean) $\lambda \, t$.

3.  **Independent increments** For $0 \le q < r \le s< t$, $N(t) - N(s)$
    and $N(r) - N(q)$ are independent random variables.

4.  **Stationary increments** For all $s,t >0$, $N(t+s) - N(s)$ has the
    same distribution as $N_t$, i.e.
    $$\Pr(N(t+s) - N(s) = n) = \Pr(N(t) = n) = \frac{e^{-\lambda t} (\lambda t)^n}{n!}, \quad \text{ for }  n = 0,1,2,\ldots.$$

As may be seen from the definition, the increment $N(t +h) - N(t)$ of
the Poisson process is independent of past values of the process and has
a distribution which does not depend on $t$ (only depends on the length
of time interval $h$). It therefore follows that the Poisson process is
a process with **stationary, independent increments** and, in addition,
**satisfies the Markov property**.

::: {.example}
Starting at 9 a.m., customers arrive at a coffee shop according to
Poisson process at the rate of 10 customers per hour.

1.  Find the probability that more than 30 customers arrive between 11
    a.m. and 1 p.m.

2.  Find the probability that 30 customers arrive by noon and 50
    customers by 2 p.m.
:::



## Inter arrival times (Inter event times or holding times)

The Poisson process can take only one-unit upward jumps so it can be
characterised by the time between events. Let $T_i$ denote the time
between the $i$-th and the $i+1$-th events. The times $T_i$ are referred
to as **the time between events, interarrival times or holding times**

**Notes**
1.  We choose the sample paths of $N_t$ to be right continuous so that

    -   $N(t)  = 0$ for $t \in [0, T_0)$

    -   $N(t)  = 1$ for $t \in [T_0, T_0 + T_1)$

    -   $N(t)  = 2$ for $t \in [T_0 + T_1, T_0 + T_1 + T_2)$, etc.

2.  $N(t)$ is constant over intervals of the form $[a,b)$.

Important result {#important-result .unnumbered}
----------------

$\{T_i \}_{i \ge 0}$ is a sequence of independent exponential random
variables, each with parameter $\lambda$.

**Solution:**
For $t \ge 0$, we have
$$\Pr(T_0 > t) = \Pr(N(t) = 0) = e^{-\lambda t}.$$ 

This implies that $T_0$ has an exponential distribution with mean $1/\lambda$.

For $t \ge 0$ and $s \ge 0$, we have
$$
\begin{aligned}
\Pr(T_0 > s, T_1 > t) &= \int_s^\infty \int_t^\infty f(u,v) \, dv \, du \\
&= \int_s^\infty \int_t^\infty f_{T_1|u}(v|u) f_{T_0}(u) \, dv \, du \\
&= \int_s^\infty \left[ \int_t^\infty f_{T_1|u}(v|u)  \, dv  \right] \, f_{T_0}(u) du \\
&= \int_s^\infty \left[ \int_t^\infty f_{T_1|u}(v|u)  \, dv  \right] \, \lambda e^{-\lambda u} du \\
&= \int_s^\infty \Pr(T_1 > t| T_0 = u) \, \lambda e^{-\lambda u} du \\
&= \int_s^\infty \Pr(\text{no events in the interval (u,u+t)}) \, \lambda e^{-\lambda u} du \\
&= \int_s^\infty e^{-\lambda t } \, \lambda e^{-\lambda u} du \\
&= e^{-\lambda t } \, \lambda \int_s^\infty  e^{-\lambda u} du \\
&= e^{-\lambda (t+s) }
\end{aligned}.
$$
Putting $s = 0$, in the last expression, we obtain 
$$\Pr(T_1 > t)  = e^{-\lambda t}.$$ 
Hence, $T_1$ is exponentially distributed with mean $1/\lambda$.

Moreover, 
$$
\begin{aligned}
\Pr(T_0 > s, T_1 > t) &= e^{-\lambda (t+s) } \\
&= e^{-\lambda t } e^{-\lambda s } \\
&= \Pr(T_0 > s) \Pr(T_1 > t)
\end{aligned}.
$$
This implies that $T_1$ and $T_2$ are independent. 

**Note**
A Poisson process is a counting process for which interarrival times are
independent and identically distributed exponential random variables.

::: {.example}
In the previous example, the event of malfunctions can be modelled as a
Poisson process with rate 1/8 failure per hour. Calculate the
probability that a second failure will happen within one hour of the
first failure in a day.
:::

::: {.example}
Consider insurance claims arriving such that they follow a Poisson
process with rate 5 per day.

1.  Calculate the probability that there will be at least 2 claims
    reported on a given day.

2.  Calculate the probability that another claim will be reported during
    the next hour.

3.  Calculate the expected time until the next claim, if there haven't
    been any claims reported in the last two days.
:::

**Solution:**

Following the properties of a Poisson process, the number of reported claims in an interval of $t$ days has a Poisson distribution with parameter $\lambda t$, $\text{Poisson}(\lambda t)$.

1. The probability that there will be at least 2 claims
    reported on a given day is
$$
\begin{aligned}
\Pr(N(t+1) - N(t) \ge 2) &= \Pr(N(1) \ge 2)
&= 1 - \frac{e^{-5} 5^0 }{0!} - \frac{e^{-5} 5^1 }{1!} \\
&= 1 - 6e^{-5} \\
&= 1 - `r round(6*exp(-5),4)`\\
&= `r round(1- 6*exp(-5),4)`
\end{aligned}
$$

2. The probability that another claim will be reported during the next hour is the same as the probability that there is at least one claim in the next hour. Therefore,

$$
\begin{aligned}
\Pr(N(t+1/24) - N(t) \ge 1) &= 1 - \Pr(N(1/24) = 0)
&= 1 - \frac{e^{-5/24} 5^0 }{0!} \\
&= 1 - `r round(exp(-5/24),4)`\\
&= `r round(1- exp(-5/24),4)`
\end{aligned}
$$

Alternatively, the time between claims has an exponential distribution with parameter $\lambda = 5$. The required probability is
$$
\begin{aligned}
\Pr(T_i \le 1/24) &= 1 - e^{-5/24} \\
&= `r round(1- exp(-5/24),4)`
\end{aligned}
$$

3. The waiting time has the lack of memory property, so the time before another claim comes in is independent of the time since the last one (i.e. independent of the fact that there have not been any claims reported in the last two days).

The expected time until the next claim is
$$ \text{E}[T_i] = \frac{1}{5} = 0.2 \text{ days}.$$



## Superposition and thinning properties

In this section, we consider two other important properties of the
Poisson process.

### Superposition property {#superposition-property .unnumbered}

Let $N_1(\cdot),N_2(\cdot) , \ldots, N_k(\cdot)$ be **independent**
Poisson processes with rate parameters
$\lambda_1, \lambda_2, \ldots, \lambda_k$, respectively. Then the
following statements hold:

1.  The sum of the Poisson process
    $N(\cdot) = N_1(\cdot) + N_2(\cdot) + \cdots + N_k(\cdot)$ is also a
    Poisson process with rate
    $\displaystyle \lambda = \sum_{j = 1}^k \lambda_j$.

2.  Given the occurrence of a point of the process $N(\cdot)$ at time
    $t$, it belongs to any given original process $N_i(\cdot)$ with
    probability $p_i = \lambda_i/\lambda$, independent of all others.

The converse of the superposition property is the splitting property. It
can be seen that the Poisson process behaves in an intuitive way when
considering the problem of **splitting** or **sampling**.

### Splitting (Thinning) property {#splitting-thinning-property .unnumbered}

Let $N(\cdot)$ be a Poisson process with rate $\lambda$. Suppose that
each arrival of $N(\cdot)$, which is independent of other arrivals, is
assigned or marked as a type $i$ with probability $p_i$, where
$p_1 + \cdots + p_k = 1$. Let $N_i(\cdot)$ for $1 \le  i \le k$ be the
number of type $i$ events in $[0,t]$. Then

1.  The processes $N_1(\cdot),N_2(\cdot) , \ldots, N_k(\cdot)$ are
    **independent** Poisson processes with rates
    $p_1 \lambda, \ldots, p_k \lambda$.

2.  Each processes is called a **thinned Poisson process**.

To illustrate the splitting property, let us assume (for explanation
purpose) that $k = 2$. Let $N_1(t)$ denote the number of events of type
1 by time $t$ and Let $N_2(t)$ denote the number of events of type 2.
Therefore, $N(t) = N_1(t) + N_2(t)$. The joint probability mass function
of $(N_1(t), N_2(t))$ is

::: {.example}
An insurance company has two types of policy, A and B. Reported claims
under A follow a Poisson process with rate 4 per day. Reported claims
independently under B follow a Poisson process with rate 6 per day. The
probability that a claim from A is at least 5,000 THB is 2/5, while that
from B is 1/3. Calculate the expected number of claims at least 5,000
THB in the next day.
:::

::: {.example}
Claims arriving from male happen as a Poisson process with rate 2 per
day, wile claims arriving from female happen as a Poisson process with
rate 6 per day.

1.  Calculate the probability that in any given period of 1 week,

    1.  no claims occur;

    2.  at least 2 claims occur.

2.  Calculate the probability that 4 claims from female have happened
    before 2 claims from male.
:::

## Memorylessness

The importance of the exponential distribution to the Poisson process
lies in its unique memoryless property, a topic from probability that
merits review. To illustrate the memoryless property, let us consider
the following situation:

-   Assume that John and Taylor each want to take a bus.

-   Buses arrive at a bus stop according to a Poisson process with
    parameter $\lambda = 1/30$. That is, the times between buses have an
    exponential distribution, and buses arrive, on average, once every
    30 minutes.

-   Unlucky John gets to the bus stop just as a bus pulls out of the
    station. His waiting time for the next bus is about 30 minutes.

-   Taylor arrives at the bus stop 10 minutes after John. Remarkably,
    the time that Taylor waits for a bus also has an exponential
    distribution with parameter $\lambda = 1/30$.

Memorylessness means that their waiting time distributions are the same,
and they will both wait, on average, the same amount of time!

To prove it true, observe that Taylor waits more than $t$ minutes if and
only if John waits more than $t + 10$ minutes, given that a bus does not
come in the first 10 minutes. Let $A$ and $B$ denote John and Taylor's
waiting times, respectively. John's waiting time is exponentially
distributed. Hence, $$\begin{aligned}
    \Pr(B > t) &= \Pr( A > t + 10 | A > 10) = \frac{\Pr(A > t + 10)}{\Pr(A > 10)} \\
        &= \frac{e^{-(t+10)/30}}{e^{-10/30}} = e^{-t/30}  \\
        &= \Pr(A > t).\end{aligned}$$ from which it follows that $A$ and
$Z$ have the same distribution.

Of course, there is nothing special about $t = 10$. Memorylessness means
that regardless of how long you have waited, the distribution of the
time you still have to wait is the same as the original waiting time.

The exponential distribution is the only continuous distribution that is
memoryless. (The geometric distribution has the honors for the discrete
case.) Here is the general statement of the property.

More precisely, a random variable $X$ is **memoryless** if, for all
$s, t > 0$, $$\Pr(X > s + t|X > s) = \Pr(X > t).$$

**Notes**
1.  The exponential distribution is the only continuous distribution
    that exhibits this memoryless property, which is also called the
    Markov property.

2.  Furthermore, it may be shown that, if X is a nonnegative continuous
    random variable having this memoryless property, then the
    distribution of X must be exponential.

3.  For a discrete random variable, the geometric distribution is the
    only distribution with this property.

::: {.example}
Assume that the amount of time a patient spends in a dentist's office is
exponentially distributed with mean equal to 40 minutes.

1.  Calculate the probability that a patient spends more than 60 minutes
    in the dentist's office.

2.  Calculate the probability that a patient will spend 60 minutes in
    the dentist's office given that she has already spent 40 minutes
    there.
:::    
