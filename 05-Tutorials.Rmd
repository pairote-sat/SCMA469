# Tutorials

## Tutorial 1

1.  Consider a random walk, $S_n$, with $S_0 = 0$ and where each step is
    normally distributed with mean 0 and variance 10.

    1.  What is the distribution of $S_{10}$?

    2.  Calculate $\Pr(S_{10} < -10)$.

    **Solution:**

    1.  We have $S_{10}$ is a sum of
        $S_0$ and the i.i.d random variables $Z_i$, each distributed
        normal distribution, $Z_i \sim N(0,10)$. Moreover,
        $$\mathrm{E}[S_{10}] = \mathrm{E}[S_0 + \sum_{i=1}^{10} Z_i] = S_0 + \sum_{i=1}^{10} \mathrm{E}[Z_i] = 0$$
        and
        $$\mathrm{Var}[S_{10}] = \mathrm{Var}[S_0 + \sum_{i=1}^{10} Z_i] = \sum_{i=1}^{10} \mathrm{Var}[Z_i] = 100$$
        Therefore, the distribution of $S_{10}$ is normally distributed,
        $S_{10} \sim N(0,100)$.

    2.  From the previous result,
        $$\Pr(S_{10} < -10) = \Pr(Z < -1) = 0.1587.$$

2.  Suppose that the value of a commodity as a random walk, where each
    day the change in price has mean \$0.05 and variance \$0.1. Use the
    central limit theorem to estimate the probability that its value is
    more than \$6 after 100 days if the initial value is \$0.50.

    **Solution:** We have $S_{100}$ is a sum of $S_0$ and the i.i.d
    random variables $Z_i$, each distributed normal distribution,
    $Z_i \sim N(0.05,0.1)$. Moreover,
    $$\mathrm{E}[S_{100}] = \mathrm{E}[S_0 + \sum_{i=1}^{100} Z_i] = S_0 + \sum_{i=1}^{100} \mathrm{E}[Z_i] = 5.5$$
    and
    $$\mathrm{Var}[S_{100}] = \mathrm{Var}[S_0 + \sum_{i=1}^{100} Z_i] = \sum_{i=1}^{100} \mathrm{Var}[Z_i] = 10$$
    Therefore, the distribution of $S_{100}$ is normally distributed,
    $S_{100} \sim N(5.5,10)$.

    The Central Limit Theorem implies that $S_{100}$ is approximately
    normally distributed, $S_{100} \sim N(5.5,10)$.

    $$\Pr(S_{100} > 6) = \Pr(Z > 0.1581) = 1 -  \Pr(Z < 0.1581)  = 1- 0.5628 = 0.4372.$$

3.  For the random walk process as described in the lecture note,

    1.  Calculate $\Pr(X_8 = 96 | X_0 = 100),$

    2.  Calculate $\Pr(X_1 = 99, X_8 = 96 | X_0 = 100),$

    3.  Calculate $\Pr(X_1 = 99,
        X_4 = 98, X_8 = 96 | X_0 = 100),$

    4.  Calculate $\Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100),$

    5.  Given $X_0 = 100$, calculate $\mathrm{E}[X_5]$.

    6.  Write down the joint distribution of $X_1$ and $X_3$ given
        $X_0 = 100$. (Hint: consider all possible sample paths)

    **Solution:**

    1.  Here the price must increase on any 2 day(s) and decrease on any
        6 day(s), not necessarily in that order. There are
        ${ 8 \choose 2} = 28$ different possibilities and each of these
        has probability $p^{2}(1-p)^{6}$. Therefore, the required
        probability is
        $$\Pr(X_8 = 96 | X_0 = 100) =  28  p^{2}(1-p)^{6} .$$

    2.  The problem can be divided into two periods:

        -   The first period of 1 day(s): the price in this period must
            increase on any 0 day(s) and decrease on any 1 day(s), not
            necessarily in that order. There are ${ 1 \choose 0}$
            different possibilities and each of these has probability
            $p^{0}(1-p)^{1}$.

        -   The next period of 7 day(s): the price in this period must
            increase on any 2 day(s) and decrease on any 5 day(s), not
            necessarily in that order. There are ${ 7 \choose 2}$
            different possibilities and each of these has probability
            $p^{2}(1-p)^{5}$.

        The required probability is
        $$\Pr(X_1 = 99, X_8 = 96 | X_0 = 100)  =  21  p^{2}(1-p)^{6} .$$

    3.  Similar to the previous problem, the required probability can be
        calculated as follows:

        The problem can be divided into three periods:

        -   The first period of 1 day(s): the price in this period must
            increase on any 0 day(s) and decrease on any 1 day(s), not
            necessarily in that order. There are ${ 1 \choose 0}$
            different possibilities and each of these has probability
            $p^{0}(1-p)^{1}$.

        -   The next period of 3 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 2 day(s), not
            necessarily in that order. There are ${ 3 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{2}$.

        -   The last period of 4 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 3 day(s), not
            necessarily in that order. There are ${ 4 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{3}$.

        The required probability is $$\Pr(X_1 = 99,
        X_4 = 98, X_8 = 96 | X_0 = 100)  =  12  p^{2}(1-p)^{6} .$$

    4.  By Markov property, we have $$\Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100), 
        = \Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99).$$ Again, the problem can be
        divided into two periods:

        -   The first period of 3 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 2 day(s), not
            necessarily in that order. There are ${ 3 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{2}$.

        -   The next period of 4 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 3 day(s), not
            necessarily in that order. There are ${ 4 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{3}$.

        The required probability is $$\Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100)
        = \Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99)  =  12  p^{2}(1-p)^{5} .$$

    5.  The variable $X_5$ can take the values from
        $95, 97, 99, 101, 103, 105$. In particular, $$\begin{aligned}
            \Pr(X_5 &= 95) = {5 \choose 0} p^0 (1-p)^5 =  1 
        p^0 (1-p)^5    \\
            \Pr(X_5 &= 97) = {5 \choose 1} p^1 (1-p)^4 = 5 
            p^1 (1-p)^4\\
            \Pr(X_5 &= 99) = {5 \choose 2} p^2 (1-p)^3 = 10 
            p^2 (1-p)^3\\
            &\vdots \\
            \Pr(X_5 &= 105) = {5 \choose 5} p^5 (1-p)^0 = 1 
            p^5 (1-p)^0 \end{aligned}$$

        Therefore, $\mathrm{E}[X_5] = 
         95 \cdot \left( 1 
        p^0 (1-p)^5 \right)
        + 97 \cdot \left(5 
        p^1 (1-p)^4 \right)
        + 99 \cdot \left(10 
        p^2 (1-p)^3 \right)
        + \cdots
        + 105 \cdot \left( 1 
            p^5 (1-p)^0 \right) = 95 + 10*x.$
      Alternatively, $$\begin{aligned}
      E\left[X_{5}\right] &=E\left[100+\sum_{i=1}^{5} Z_{i}\right] \\
      &= 100+5 \cdot E\left[Z_{i}\right]  \\
      &=100+ 5 (2 p-1)  \\
      &=95 + 10p\end{aligned}$$
      where $E\left[Z_{i}\right] = p-q  = p - (1 - p) = 2p -1.$

4.  For each event,

    -   Identify a stochastic process $\{ X_t : t \in T\}$ and describe
        $X_t$ in context.

    -   Describe the time domain and state space. State whether the time
        domain and state space are discrete or continuous.

    1.  Sociologists categorise the population of a country into upper-,
        middle- and lower-class groups. One of the government offices
        has monitored the movement of successive generations among these
        three groups.

    2.  The insurer's surplus (an excess of income or assets over
        expenditure or liabilities in a given period) at any future time
        which is defined as the initial surplus plus the premium income
        up to time $t$ minus the aggregate claims up to time $t$.

    3.  In a working day, a coffee shop owner records customer arrival
        times.

    4.  The gambler starts with m and bets per game. The probability of
        winning is $p$ and the probability of losing is $q$ where
        $p + q = 1$. In addition, the gambler is ruined (or goes broke)
        if he reaches state 0, and also stops the game if he reaches
        state $N$.

    5.  In the board game Monopoly, there are 40 squares. A player is
        interested to know the successive board position.

    **Solution:**

    1.  Let $X_{n}$ be the class of $n^{\text {th }}$ generation of a
        family. The state space, $S=\{\text {Upper, Middle, Lower} \}$,
        is discrete. The index set, $I=\{0,1,2, \ldots\}$, is also
        discrete.

    2.  Let $S(t)$ be the insurer's surplus at time $t$.
        $S=\mathbb{R} \text { and }  I=[0, \infty)$.

    3.  Let $X_{n}$ be the amount of money of the gambler after game
        $n$.

        $S=\{0,1,2 \ldots, N\} \text { and } I=\{0,1,2 ,\ldots \}$.

    4.  Suppose that the opening hours of the coffee shop are from 7:00
        am to 6:00 pm (i.e. 11 hours). Let $X_{n}$ be the arrival time
        of customer $n$. State space (continuous)

        $S=[0,11 \times 60]=[0,660]$ (in minutes) and
        $I=\{1,2, \ldots\}$.

    5.  Let $x_{n}$ be a player's board position after $n$ plays.

        $S=\{1,2,3, \ldots, 40\}$ and $I=\{0,1,2, \ldots \}.$

5.  The simple weather pattern can be classified into three types
    including rainy ($R$), cloudy ($C$) and sunny ($S$). The weather is
    observed daily. The following information is provided.

    -   On any given rainy day, the probability that it will rain the
        next day is 0.7; the probability that it will be cloudy the next
        day 0.2.

    -   On any given cloudy day, the probability that it will rain the
        next day is 0.75; the probability that it will be sunny the next
        day 0.1.

    -   On any given sunny day, the probability that it will rain the
        next day is 0.2; the probability that it will be sunny the next
        day 0.4.

    Explain how this may be modelled by a Markov chain.

    **Solution:** The three weather conditions describe the three state of
    the Markov chain. Let $X_{n}$be the weather condition on day $n$.

    -   State 1 (R) rainy day

    -   State 2 (C) cloudy day

    -   State 3 (S) sunny day

    The transition probability matrix $P$ for this Markov chain is

    $$P=\left[\begin{array}{lll}
    0.7 & 0.2 & 0.1 \\
    0.75 & 0.15 & 0.1 \\
    0.2 & 0.4 & 0.4
    \end{array}\right]$$

    This stochastic process has the Morkov property because the weather
    condition on the next day depends only on the condition today.

6.  Explain whether an independent and identically distributed sequence
    of random variables has a Markov property. 
    
    **Solution:** Assume that
    this Markov chain $X_0, X_1, X_2 \ldots,$ takes values in
    $\{1,2, \ldots, k\} \text { with }$

    $$P\left(X_{n}=j\right) = p_{j} \quad \text { for } j=1,2, \ldots, k \quad \text { and } n \geq 0 .$$
    Note that this equality holds for all $n$ because
    $\left\{X_{n} \right\}_{n \ge 0}$ have the same distribution.

    By independence,

    $$P\left(x_{n}=j \mid x_{n-1}=i\right)=P\left(x_{n}=j\right)=p_{j},$$

    This proves our claim that the i.i.d. sequence of random variables
    has a Markov property. Note also that the transition matrix is
    $$P = 
    \begin{bmatrix}
    p_1 & p_2 & \cdots & p_k \\
    p_1 & p_2 & \cdots & p_k \\
    \vdots & \vdots &  & \vdots \\
    p_1 & p_2 & \cdots & p_k \\
    \end{bmatrix}.$$

7.  The random variables $Z_1, Z_2, \ldots$ are independent and with the
    common probability mass function $$Z_i = \begin{cases}
        1, & \text{ with probability }  0.2 \\
        2, & \text{ with probability }  0.3 \\  
        3, & \text{ with probability }  0.4 \\  
        4, & \text{ with probability }  0.1 \\  
     \end{cases}$$ Let $X_0 = 1$ and
    $X_n = \max\{Z_1, Z_2, \ldots, Z_n \}$ be the largest $Z$ observed
    to date. Explain how this may be modelled by a Markov chain.
    **Solution:**

    Given $X_{0}=1$ and
    $X_{n}=\max \left\{Z_{1}, Z_{2}, \ldots, Z_{n}\right\}$ where
    $\left\{Z_{i}\right\}$ are i.i.d. random variables with

      $i$            1     2     3     4
      -------------- ----- ----- ----- -----
      $P(Z_i = i)$   0.2   0.3   0.4   0.1

    We note that $$\begin{aligned}
    X_{n+1} &=\operatorname{max}\left\{Z_{1}, Z_{2}, \ldots, Z_{n+1}\right\} \\
    &=\operatorname{max}\left\{X_{n}, Z_{n+1}\right\}
    \end{aligned}$$ Consider the transition probabilities

    $$\begin{aligned}
    P\left(X_{n+1} = j \mid X_{n}=i \right) &= P\left(\max \left\{X_{n}, Z_{n+1}\right\}=j \mid X_{n}=i\right) \\
    &=P\left(\max \left\{i, Z_{n+1}\right\}=j \mid X_{n}=i\right)
    \end{aligned}$$

    **Case 1:** If $i=1$, then $$\max \left\{1, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0.2 \\
    2 & \text{w.p. } 0.3 \\
    3  & \text{w.p. } 0.4 \\
    4  & \text{w.p. } 0.1 \\
    \end{cases}$$

    **Case 2:** If $i=2$, then $$\max \left\{2, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0 \\
    2 & \text{w.p. } 0.5 \quad (\text{i.e. } z_{n+1} = 1 \text{ or } 2  )\\
    3  & \text{w.p. } 0.4 \\
    4  & \text{w.p. } 0.1 \\
    \end{cases}$$

    **Case 3:** If $i=3$, then $$\max \left\{3, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0 \\
    2 & \text{w.p. } 0 \\
    3  & \text{w.p. } 0.9 \\
    4  & \text{w.p. } 0.1 \\
    \end{cases}$$

    **Case 4:** If $i=4$, then $$\max \left\{4, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0 \\
    2 & \text{w.p. } 0 \\
    3  & \text{w.p. } 0 \\
    4  & \text{w.p. } 1 \\
    \end{cases}$$ The transition probability matrix is then

    $$P = 
    \begin{bmatrix}
    0.2 & 0.3 & 0.4 & 0.1 \\
    0 & 0.5 & 0.4 & 0.1 \\
    0 & 0 & 0.9 & 0.1 \\
    0 & 0 & 0 & 0.1 \\
    \end{bmatrix}.$$ Clearly the sequence $X_0, X_1, X_2,\ldots$ can be
    modelled by the Markov chain with the transition probability matrix
    $P$. Moreover, given the most recent value $X_n$, its future value
    $X_{n+1}$ is independent of the past history
    $X_0, X_1, \ldots, X_{n-1}$.




## Tutorial 2

```{r Q1, echo = FALSE, cache = TRUE}
p11 <- 0.5; p12 <- 0.3
p21 <- 0.2; p22 <- 0.2
p31 <- 0.3; p32 <- 0.2

mu <- c(0.3,0.3,0.4)

stateNames <- c(1,2,3)
row1 <- c(p11,p12,1-p11-p12)
row2 <- c(p21,p22,1-p21-p22)
row3 <- c(p31,p32,1-p31-p32)
transMat <- matrix(c(row1,row2,row3),
             nrow=3, byrow=TRUE)
row.names(transMat) <- stateNames 
colnames(transMat) <- stateNames

dtmcA <- new("markovchain",
             transitionMatrix = transMat,
             states = as.character(stateNames),
             name = "P")
P <- dtmcA
```

1.  A Markov chain $X_0, X_1, \ldots$ on states $`r stateNames`$ has the
    following transition matrix $$P = \begin{bmatrix}
        `r p11` & `r p12` & `r 1 - p11 - p12`    \\
        `r p21` & `r p22` & `r 1 - p21 - p22`  \\
        `r p31` & `r p32` & `r 1 - p31 - p32`    \\
    \end{bmatrix}.$$ The distribution of the initial random variable
    $X_0$ is $\boldsymbol{\mu} =  (`r mu`)$.

    1.  Draw a transition diagram for the chain.

    2.  Determine $\Pr(X_0 = 1, X_1 = 2, X_2 = 3).$

    3.  Determine $\Pr(X_1 = 2, X_2 = 3 | X_0 = 1).$

    4.  Determine $\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1).$

    5.  Determine $\Pr(X_2 = 3 | X_0 = 1).$

    6.  Determine $\Pr(X_3 = 3 | X_1 = 1).$

    7.  Determine $\Pr(X_2 = 3).$

    8.  Determine $\mathrm{E}[X_2]$

**Solutions:**


  1. The transition diagram for the chain is shown in the figure below:
```{r, echo = FALSE}
plot(dtmcA, package="diagram", self.cex = 0.7,  box.prop = 0.5, arr.length=0.2)
```
  2. $\Pr(X_0 = 1, X_1 = 2, X_2 = 3) = \mu_1 p_{12} p_{23} = (`r mu[1]`)(`r transitionProbability(dtmcA,"1","2")`)(`r transitionProbability(dtmcA,"2","3")`) = `r mu[1]*transitionProbability(dtmcA,"1","2")*transitionProbability(dtmcA,"2","3")`.$

  3. $\Pr(X_1 = 2, X_2 = 3 | X_0 = 1) = p_{12} p_{23} = (`r transitionProbability(dtmcA,"1","2")`)(`r transitionProbability(dtmcA,"2","3")`) = `r transitionProbability(dtmcA,"1","2")*transitionProbability(dtmcA,"2","3")`.$

  4. From the time homogeneous assumption, it follows that $$\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1) = \Pr(X_1 = 2, X_2 = 3 | X_0 = 1) = `r transitionProbability(dtmcA,"1","2")*transitionProbability(dtmcA,"2","3")`.$$

  5. $\Pr(X_2 = 3 | X_0 = 1) = (P^2)_{13} = `r transitionProbability(dtmcA^2,"1","3")`.$ 
    
  6. $\Pr(X_3 = 3 | X_1 = 1) = \Pr(X_2 = 3 | X_0 = 1) = (P^2)_{13} = `r transitionProbability(dtmcA^2,"1","3")`.$
    
  7. $\Pr(X_2 = 3)  = (\boldsymbol{\mu}P^2)_3 =  `r (mu*dtmcA^2)[3]`.$
    
  8. $\mathrm{E}[X_2] = \sum_{k=1}^3 k \Pr(X_2 = k) = (`r stateNames`) \cdot (`r mu*dtmcA^2`)  = `r sum(stateNames*(mu*dtmcA^2))`.$
    
    
  Note that 

```{r, echo = FALSE}
P^2
```

2.  A Markov chain $X_0, X_1, \ldots$ on states 1,2,3 has the
    following transition matrix $$P = \begin{bmatrix}
        0 & 1/2 & 1/2   \\
        1/3  & 1/3  & 1/3   \\
        1/2  & 1/2  & 0    \\
        %\vdots & \vdots & \vdots  & \vdots \\
        %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
    \end{bmatrix}.$$ 
    The process starts in states $X_0 = 1$.

    1.  Draw a transition diagram for the chain.

    2.  Determine $\Pr(X_0 = 1, X_1 = 3, X_2 = 2).$

    3.  Determine $\Pr(X_1 = 3, X_2 = 2 | X_0 = 1).$

    4.  Determine $\Pr(X_2 = 2 | X_0 = 1).$

    5.  Determine $\Pr(X_3 = 2 | X_1 = 1).$

    6.  Determine $\Pr(X_2 = 2).$


```{r Q2, echo = FALSE, cache = TRUE}
p11 <- 0; p12 <- 1/2
p21 <- 1/3; p22 <- 1/3
p31 <- 1/2; p32 <- 1/2

mu <- c(1,0,0)

stateNames <- c(1,2,3)
row1 <- c(p11,p12,1-p11-p12)
row2 <- c(p21,p22,1-p21-p22)
row3 <- c(p31,p32,1-p31-p32)
transMat <- matrix(c(row1,row2,row3),
             nrow=3, byrow=TRUE)
row.names(transMat) <- stateNames 
colnames(transMat) <- stateNames

dtmcA <- new("markovchain",
             transitionMatrix = transMat,
             states = as.character(stateNames),
             name = "P")
P <- dtmcA
```

**Solution:**


  1. The transition diagram for the chain is shown in the figure below:
```{r, echo = FALSE}
library(MASS)
plot(dtmcA, package="diagram", self.cex = 0.7,  box.prop = 0.5, arr.length=0.2)
```
  2. $\Pr(X_0 = 1, X_1 = 3, X_2 = 2) = \mu_1 p_{13} p_{32} = (`r mu[1]`)(`r as.character(as.fractions(transitionProbability(dtmcA,"1","3")))`)(`r as.character(as.fractions(transitionProbability(dtmcA,"3","2")))`) = `r as.character(as.fractions(mu[1]*transitionProbability(dtmcA,"1","3")*transitionProbability(dtmcA,"3","2")))`.$

  3. $\Pr(X_1 = 3, X_2 = 2 | X_0 = 1) = p_{13} p_{32} = (`r as.character(as.fractions(transitionProbability(dtmcA,"1","3")))`)(`r as.character(as.fractions(transitionProbability(dtmcA,"3","2")))`) = `r as.character(as.fractions(transitionProbability(dtmcA,"1","3")*transitionProbability(dtmcA,"3","2")))`.$

  4. $\Pr(X_2 = 2 | X_0 = 1) = (P^2)_{12} = `r as.character(as.fractions(transitionProbability(dtmcA^2,"1","2")))`.$ 
    
  5. $\Pr(X_3 = 2 | X_1 = 1) = \Pr(X_2 = 2 | X_0 = 1) = (P^2)_{12} = `r as.character(as.fractions(transitionProbability(dtmcA^2,"1","2")))`.$
    
  6. $\Pr(X_2 = 2)  = (\boldsymbol{\mu}P^2)_2 =  `r as.character(as.fractions((mu*dtmcA^2)[2]))`.$
    
    
  Note that 

```{r, echo = FALSE}
P^2
```

3.  A Markov chain $X_0, X_1, \ldots$ on sates 1,2 has the following
    transition matrix $$P = \begin{bmatrix}
        1-a & a   \\
        b & 1-b   \\
        %\vdots & \vdots & \vdots  & \vdots \\
        %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
    \end{bmatrix},$$ where $0 < a,b < 1.$

    1.  Draw a transition diagram for the chain.

    2.  the distribution of $X_1$.

    3.  Show that $$P^n = \frac{1}{a+b} \begin{bmatrix}
            b & a   \\
            b & a   \\
            %\vdots & \vdots & \vdots  & \vdots \\
            %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
        \end{bmatrix} +
        \frac{(1-a-b)^n}{a+b} \begin{bmatrix}
            a & -a   \\
            -b & b   \\
        \end{bmatrix}.$$

    4.  Given that $X_0 = 1$, what is the probability that in the long
        run the system will be in state 1? (Hint: consider
        $\lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n$)

    5.  Given that $X_0 = 1$, what is the probability that in the long
        run the system will be in state 2?

    6.  Given that $X_0 = 2$, what is the probability that in the long
        run the system will be in state 1?

    7.  Given that $X_0 = 2$, what is the probability that in the long
        run the system will be in state 2?

**Solution:**

  1. Leave it to the reader.
    
  2. Denote $\boldsymbol{\mu} = (\mu_1, \mu_2)$ the initial probability distribution. Then the distribution of $X_1$ is $\boldsymbol{\mu}^{(1)} = \boldsymbol{\mu} P = (\mu_1(1-a) + \mu_2 b,  \mu_1 a + \mu_2(1-b))$
    
  3. We apply eigendecomposition of a matrix. For more details, please follow this link from Wikipedia [link](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix).
    
  The eigenvalues of $P$ are $\lambda_1 = 1$ and $\lambda_2 = 1 - a -b$ and the corresponding eigenvectors are
    $$v_1 = \begin{bmatrix}
            1   \\
            1   \\
         \end{bmatrix}, \quad
         v_2 = \begin{bmatrix}
            -a/b   \\
            1   \\
         \end{bmatrix}.
    $$    
  Then the transition matrix can be factorised as
     $$P = \begin{bmatrix}
            1 & -a/b \\
            1 & 1 \\
         \end{bmatrix}
         \begin{bmatrix}
            1 & 0   \\
            0 & 1 - a - b   \\
        \end{bmatrix}
        \begin{bmatrix}
            1 & -a/b \\
            1 & 1 \\
         \end{bmatrix}^{-1}.
    $$  
  Hence $$\begin{aligned}
      P^n &= \left( \begin{bmatrix}
            1 & -a/b \\
            1 & 1 \\
         \end{bmatrix}
         \begin{bmatrix}
            1 & 0   \\
            0 & (1 - a - b)^n   \\
        \end{bmatrix} \right)
        \begin{bmatrix}
            1 & -a/b \\
            1 & 1 \\
         \end{bmatrix}^{-1}  \\
         &= \begin{bmatrix}
            1 & -\frac{a}{b}(1 - a - b)^n \\
            1 & (1 - a - b)^n \\
         \end{bmatrix} 
         \left(
         \frac{1}{1 + a/b}
         \begin{bmatrix}
            1 & a/b \\
            -1 & 1 \\
         \end{bmatrix}
         \right)  \\
         &= \frac{1}{a+b}
         \begin{bmatrix}
         b + a(1 - a - b)^n & a - a(1 - a - b)^n \\
         b - b(1 - a - b)^n & a + b(1 - a - b)^n
         \end{bmatrix} \\
         &= \frac{1}{a+b}
         \begin{bmatrix}
         b & a \\
         b & a
         \end{bmatrix} +
         \frac{(1 - a - b)^n}{a+b}
         \begin{bmatrix}
         a & -a \\
         -b & b
         \end{bmatrix}
         \end{aligned}.
         $$ 
  Note that $$\lim_{n \rightarrow \infty} P^n = 
         \frac{1}{a+b}
         \begin{bmatrix}
         b & a \\
         b & a
         \end{bmatrix}, $$
  which follows from the facts that $-1 < 1 -a -b < 1$ and $(1- a-b)^n \rightarrow 0$ as $n \rightarrow \infty$.
    
  4. It follows from the above results that in the long run
    $$ \lim_{n \rightarrow \infty} \Pr(X_n = 1| X_0 = 1) = (\lim_{n \rightarrow \infty} P^n)_{11} = \frac{b}{a+b}. $$
    
  5. In the long run, we have
    $$ \lim_{n \rightarrow \infty} \Pr(X_n = 2| X_0 = 1) = (\lim_{n \rightarrow \infty} P^n)_{12} = \frac{a}{a+b}. $$
    
  6. In the long run, we have
    $$ \lim_{n \rightarrow \infty} \Pr(X_n = 1| X_0 = 2) = (\lim_{n \rightarrow \infty} P^n)_{21} = \frac{b}{a+b}. $$
    
  7. In the long run, we have
    $$ \lim_{n \rightarrow \infty} \Pr(X_n = 2| X_0 = 2) = (\lim_{n \rightarrow \infty} P^n)_{22} = \frac{a}{a+b}. $$
    
  Furthermore, for any initial distribution $\boldsymbol{\mu}$, the limiting distribution with this initial distribution is
  $$ \lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n  = (\frac{b}{a+b}, \frac{a}{a+b}).$$
  This gives the long term proportion of the Markov chain, i.e. the probability of finding the process in state 1 is $\frac{b}{a+b}$ and in state 2 is $\frac{a}{a+b}$, irrespective of the stating state. 

    
4.  Let $a$ be a constant and $\xi_1, \xi_2, \ldots$ be a sequence of
    independent and identically distributed (i.i.d.) random variables.
    The stochastic process $\{ X_n\}$ is defined by
    $$X_0 = a, \quad X_n = X_{n-1} + \xi_n, \, n > 1.$$ This process is
    known as a random walk.

    1.  Express the state $X_n$ in terms of $X_0$ and the random
        variables $\xi_i, i = 1,2 \ldots$.

    2.  Find $\mathrm{E}[X_n]$ and $\mathrm{Var}[X_n]$.

    3.  Does the process have the Markov property? Explain.

    4.  Is the process stationary? Explain.

**Solution:**

  1. From the definition, it follows that
$$
\begin{aligned}
X_0 &= a \\
X_1 &= X_0 + \xi_1 = a + \xi_1 \\
X_2 &= X_1 + \xi_2 = a + \xi_1 + \xi_2 \\
    &\vdots \\
X_n &= X_{n-1} + \xi_n = a + \sum_{i=1}^n \xi_i, \quad n \ge 1.
\end{aligned}
$$

  2. Let $\mu = \mathrm{E}[\xi_i]$ and $\sigma^2 = \mathrm{Var}[\xi_i]$ denote the mean and variance of the increments $\xi_i$. Then
$$
\begin{aligned}  
\mathrm{E}[X_n] &= \mathrm{E}\left[a + \sum_{i=1}^n \xi_i\right] = a+ \sum_{i=1}^n \mathrm{E}[\xi_i] = a + n \mu, \\
\mathrm{Var}[X_n] &= \mathrm{Var}\left[a + \sum_{i=1}^n \xi_i\right] =  \sum_{i=1}^n \mathrm{Var}[\xi_i] =  n \sigma^2.
\end{aligned}
$$
  The last equality follows from the assumption that $\xi_1, \xi_2, \ldots$ are independent. 

  3. The process $\{X_n\}_{n\ge0}$ has independent increments and , hence, has the Markov
property. More details can be found from the lecture note [link](https://pairote-sat.github.io/SCMA469/discrete-time-markov-chains.html).

  4. The process is **not** stationary because $\mathrm{E}[X_n]$ is not constant and $\mathrm{Var}[X_n]$ also depends on $n$.

5.  Consider a homogeneous discrete-time Markov chain that describes the
    daily weather pattern. The weather patterns are classified into 3
    conditions: R(rainy), C (cloudy) and S(sunny). Based on the daily
    observations, the following information are given:

    -   On any rainy day, the probability that it will rain the next day
        is 0.7; the probability that tomorrow will be cloudy is 0.2 and
        the probability that tomorrow will be sunny is 0.1.

    -   On any cloudy day, the probability that it will rain the next
        day is 0.5; the probability that tomorrow will be cloudy is 0.35
        and the probability that tomorrow will be sunny is 0.15.

    -   On any sunny day, the probability that it will rain the next day
        is 0.1; the probability that tomorrow will be cloudy is 0.4 and
        the probability that tomorrow will be sunny is 0.5.

    1.  Draw a transition diagram for the chain and write down a
        transition matrix.

    2.  Find the probability that tomorrow is cloudy and the day after
        is rainy, given that it is sunny today.

    3.  Given that today is rainy, find the probability that it will be
        sunny in two days time.



```{r Q5, echo = FALSE}
p11 <- 0.7; p12 <- 0.2
p21 <- 0.5; p22 <- 0.35
p31 <- 0.1; p32 <- 0.4

mu <- c(1,0,0)

stateNames <- c("R","C","S")
row1 <- c(p11,p12,1-p11-p12)
row2 <- c(p21,p22,1-p21-p22)
row3 <- c(p31,p32,1-p31-p32)
transMat <- matrix(c(row1,row2,row3),
             nrow=3, byrow=TRUE)
row.names(transMat) <- stateNames 
colnames(transMat) <- stateNames

dtmcA <- new("markovchain",
             transitionMatrix = transMat,
             states = as.character(stateNames),
             name = "P")
P <- dtmcA
```

**Solution:**

  1. The transition matrix $P$ and the transition diagram are given in the results below :

```{r, echo = FALSE}
P
plot(dtmcA, package="diagram", self.cex = 0.7,  box.prop = 0.5, arr.length=0.2)
```
    
  2. The probability that tomorrow is cloudy and the day after is rainy, given that it is sunny today is
    $$ \Pr(X_1 = C, X_2 = R | X_0 = S) = (`r transitionProbability(dtmcA,"S","C")`)(`r transitionProbability(dtmcA,"C","R")`) = `r transitionProbability(dtmcA,"S","C")*transitionProbability(dtmcA,"C","R") `.$$

  3. Given that today is rainy, the probability that it will be sunny in two days time is 
$$ \Pr(X_2 = S | X_0 = R) = (P^2)_{13} = `r transitionProbability(dtmcA^2,"R","S") `.$$


## Tutorial 3

1.  A Markov chain $X_0, X_1, \ldots$ on states 1, 2, 3 with initial
    distribution $\boldsymbol{\mu} = (1/4,1/4,1/2)$. It has the
    following transition matrix $$P = \begin{bmatrix}
        1/2 & 1/4 & 1/4   \\
        1/3  & 1/3  & 1/3   \\
        1/5  & 2/5  & 2/5    \\
        %\vdots & \vdots & \vdots  & \vdots \\
        %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
    \end{bmatrix}.$$ Compute the following probabilities:

    1.  $\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1).$

    2.  $\Pr(X_0 = 3, X_1 = 2 , X_2 = 1).$

    3.  $\Pr(X_1 = 3, X_2 = 2 , X_3 = 1).$

    4.  $\Pr(X_{1} = 2, X_{3} = 2, X_{5} = 2).$



```{r Q3-1, echo = FALSE}
p11 <- 1/2; p12 <- 1/4
p21 <- 1/3; p22 <- 1/3
p31 <- 1/5; p32 <- 2/5

mu <- c(1/4,1/4,1/2)

stateNames <- c(1,2,3)
row1 <- c(p11,p12,1-p11-p12)
row2 <- c(p21,p22,1-p21-p22)
row3 <- c(p31,p32,1-p31-p32)
transMat <- matrix(c(row1,row2,row3),
             nrow=3, byrow=TRUE)
row.names(transMat) <- stateNames 
colnames(transMat) <- stateNames

dtmcA <- new("markovchain",
             transitionMatrix = transMat,
             states = as.character(stateNames),
             name = "P")
P <- dtmcA
```


**Solution:**

    1.  We have  

$\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1) =  p_{11} p_{12} p_{23} = (`r as.character(as.fractions(transitionProbability(dtmcA,"1","1")))`)(`r as.character(as.fractions(transitionProbability(dtmcA,"1","2")))`)(`r as.character(as.fractions(transitionProbability(dtmcA,"2","3")))`) = `r as.character(as.fractions(transitionProbability(dtmcA,"1","1")*transitionProbability(dtmcA,"1","2")*transitionProbability(dtmcA,"2","3")))`.$

    2.  We have  
    
$\Pr(X_0 = 3, X_1 = 2, X_2 = 1) = \mu_3 p_{32} p_{21} = (`r mu[3]`)(`r as.character(as.fractions(transitionProbability(dtmcA,"3","2")))`)(`r as.character(as.fractions(transitionProbability(dtmcA,"2","1")))`) = `r as.character(as.fractions(mu[3]*transitionProbability(dtmcA,"3","2")*transitionProbability(dtmcA,"2","1")))`.$

    3.  We have 
    
$$\begin{aligned} \Pr(X_1 = 3, X_2 = 2, X_3 = 1) &= 
\sum_{i=1}^{3} \Pr(X_0 = i) \Pr(X_1 = 3, X_2 = 2, X_3 = 1 | X_0 = i) \\ 
&= \sum_{i=1}^{3} \mu_i p_{i3} p_{32} p_{21} \\
&=  \left( \sum_{i=1}^{3} \mu_i p_{i3} \right) p_{32} p_{21}  \\
&= (\boldsymbol{\mu}P)_3 p_{32} p_{21}\\
&= (`r as.character(as.fractions((mu*P)[3]))`)(`r as.character(as.fractions(transitionProbability(dtmcA,"3","2")))`)(`r as.character(as.fractions(transitionProbability(dtmcA,"2","1")))`) \\
&= `r as.character(as.fractions((mu*P)[3]*transitionProbability(dtmcA,"3","2")*transitionProbability(dtmcA,"2","1")))`  =  `r (mu*P)[3]*transitionProbability(dtmcA,"3","2")*transitionProbability(dtmcA,"2","1")`.
\end{aligned}$$
    
    4. We have 
    
$$\begin{aligned} \Pr(X_1 = 2, X_3 = 2, X_5 = 2) &= 
\sum_{i=1}^{3} \Pr(X_0 = i) \Pr(X_1 = 2, X_3 = 2, X_5 = 2 | X_0 = i) \\ 
&= \sum_{i=1}^{3} \mu_i p_{i2} p^{(2)}_{22} p^{(2)}_{22} \\
&=  \left( \sum_{i=1}^{3} \mu_i p_{i2} \right) p^{(2)}_{22} p^{(2)}_{22}  \\
&= (\boldsymbol{\mu}P)_2 p^{(2)}_{22} p^{(2)}_{22}\\
&= (`r as.character(as.fractions((mu*P)[2]))`)(`r as.character(as.fractions(transitionProbability(dtmcA^2,"2","2")))`)(`r as.character(as.fractions(transitionProbability(dtmcA^2,"2","2")))`) \\
&= `r as.character(as.fractions((mu*P)[2]*transitionProbability(dtmcA^2,"2","2")*transitionProbability(dtmcA^2,"2","2")))` = `r (mu*P)[2]*transitionProbability(dtmcA^2,"2","2")*transitionProbability(dtmcA^2,"2","2")`.
\end{aligned}$$
    


2.  A Markov chain with state space $S = \{1,2,3,4,5,6\}$ has the
    following transition matrix: $$P = \begin{bmatrix}
    1/4 & 0 & 3/4 & 0 & 0 & 0  \\
    0 & 0 & 0 & 1 & 0 & 0  \\
    0 & 0 & 1/2 & 0 & 0 & 1/2  \\
    1/5 & 1/5 & 1/5 & 0 & 1/5 & 1/5   \\
    0 & 0 & 0 & 0 & 1 & 0  \\
    1/3 & 0 & 0 & 0 & 0 & 2/3  \\
    \end{bmatrix}.$$

    1.  Draw a transition diagram.

    2.  Identify the communication classes and classify them as closed
        or non-closed.

    3.  Is the Markov chain irreducible?


```{r Q3-2, echo = FALSE}

stateNames <- c(1,2,3,4,5,6)
transMat <- matrix(c(
   1/4 , 0 , 3/4 , 0 , 0 , 0  ,
    0 , 0 , 0 , 1 , 0 , 0  ,
    0 , 0 , 1/2 , 0 , 0 , 1/2  ,
    1/5 , 1/5 , 1/5 , 0 , 1/5 , 1/5   ,
    0 , 0 , 0 , 0 , 1 , 0  ,
    1/3 , 0 , 0 , 0 , 0 , 2/3
  ),
             nrow=6, byrow=TRUE)
row.names(transMat) <- stateNames 
colnames(transMat) <- stateNames

dtmcA <- new("markovchain",
             transitionMatrix = transMat,
             states = as.character(stateNames),
             name = "P")
P <- dtmcA
```


**Solution:**  

    1. The transition diagram is shown in the figure below:

```{r, echo = FALSE}
plot(dtmcA, package="diagram", self.cex = 0.7,  box.prop = 0.5, arr.length=0.2)
```
    
    2. There are two closed classes 
    
$C^1 = \{`r summary(P)$closedClasses[[1]]`\}$ and $C^2 = \{`r summary(P)$closedClasses[[2]]`\}$ because 
    
* $p_{55} = 1$ and 
    
* $1 \rightarrow 3 \rightarrow 6  \rightarrow 1$, and hence $`r summary(P)$closedClasses[[1]]`$ are in the same communication class. In addition, for each $i \in C^1$, $\sum_{j \in C^1} p_{ij} = 1$, which implies that escaping from $C^1$ is impossible. Therefore $C^1$ is a closed class. 

    There is one non-closed class $O = \{`r summary(P)$transientClasses[[1]]`\}$. This is because $2 \leftrightarrow 4$ and $p_{43} >0$.

    3. The Markov chain is reducible because it contains more than one communication classes.


3. For each of the Markov chains whose
    transition matrix is given below, identify the closed classes and
    the vector of absorption probabilities associated with each of these
    closed classes. Assume that the states are labelled $1,2,3 \ldots$.

    1.  $$\begin{bmatrix}
                1/6 & 0 & 1/3 & 1/2      \\
                0 & 1/3 & 2/3 & 0   \\
            1/2 & 1/2 & 0 & 0     \\    
            0 & 0 & 1/4 & 3/4     \\
        \end{bmatrix}.$$

    2.  $$\begin{bmatrix}
                0 & 1/4 & 3/4 & 0      \\
                0 & 1/3 & 0 & 2/3   \\
            1/3 & 0 & 1/3 & 1/3     \\  
            0 & 0 & 0 & 1     \\
        \end{bmatrix}.$$

    3.   $$\begin{bmatrix}
                1/4 & 1/4 & 1/4 & 1/4      \\
                0 & 3/4 & 1/4 & 0   \\
                0 & 3/4 & 1/4 & 0   \\
            0 & 0 & 0 & 1     \\
        \end{bmatrix}.$$

    4.   $$\begin{bmatrix}
                0 & 0 & 0 & 1/2  & 0 & 0 & 1/2   \\
                1/6 & 0 & 1/6 & 0  & 0 & 1/6 & 1/2 \\
            0 & 0 & 1 & 0 & 0 & 0 & 0    \\ 
                1/2 & 0 & 0 & 1/2  & 0 & 0 & 0   \\
            1/4 & 1/4 & 0 & 0  & 0 & 0 & 1/2 \\
            0 & 1 & 0 & 0 & 0 & 0 & 0    \\ 
                1/2 & 0 & 0 & 0  & 0 & 0 & 1/2   \\
        \end{bmatrix}.$$


**Solution:**

    1. Every two states communicate, so 
    
$\{1, 2, 3, 4 \}$ is a single closed class (since $1 \rightarrow 4 \rightarrow 3 \rightarrow 2 \rightarrow 3 \rightarrow 1$). The absorption probabilities are 1, since each state is in this closed class. The transition diagram is shown in the figure below:

```{r Q4-1, echo = FALSE}

stateNames <- c(1,2,3,4)
transMat <- matrix(c(
            1/6 , 0 , 1/3 , 1/2      ,
            0 , 1/3 , 2/3 , 0   ,
            1/2 , 1/2 , 0 , 0     ,    
            0 , 0 , 1/4 , 3/4  
  ),
             nrow=4, byrow=TRUE)
row.names(transMat) <- stateNames 
colnames(transMat) <- stateNames

dtmcA <- new("markovchain",
             transitionMatrix = transMat,
             states = as.character(stateNames),
             name = "P")
P <- dtmcA
```



```{r, echo = FALSE}
plot(dtmcA, package="diagram", self.cex = 0.7,  box.prop = 0.5, arr.length=0.2)
```


```{r Q4-2, echo = FALSE}

stateNames <- c(1,2,3,4)
transMat <- matrix(c(
            0 , 1/4 , 3/4 , 0 ,
            0 , 1/3 , 0 , 2/3 ,
            1/3 , 0 , 1/3 , 1/3 ,  
            0 , 0 , 0 , 1  
  ),
             nrow=4, byrow=TRUE)
row.names(transMat) <- stateNames 
colnames(transMat) <- stateNames

dtmcA <- new("markovchain",
             transitionMatrix = transMat,
             states = as.character(stateNames),
             name = "P")
P <- dtmcA
```


    2. There are two non-closed classes 
    
$O^1 = \{`r summary(P)$transientClasses[[1]]`\}$ and $O^2 = \{`r summary(P)$transientClasses[[2]]`\}$ and a closed class 
$C^1 = \{`r summary(P)$closedClasses[[1]]`\}$. Since we have a single closed class, all absorption probabilities to this closed class $C^1 = \{`r summary(P)$closedClasses[[1]]`\}$ are equal to 1. The transition diagram is shown in the figure below:

```{r, echo = FALSE}
plot(dtmcA, package="diagram", self.cex = 0.7,  box.prop = 0.5, arr.length=0.2)
```







```{r Q4-3, echo = FALSE}

stateNames <- c(1,2,3,4)
transMat <- matrix(c(
            1/4 , 1/4 , 1/4 , 1/4      ,
                0 , 3/4 , 1/4 , 0   ,
                0 , 3/4 , 1/4 , 0   ,
            0 , 0 , 0 , 1 
  ),
             nrow=4, byrow=TRUE)
row.names(transMat) <- stateNames 
colnames(transMat) <- stateNames

dtmcA <- new("markovchain",
             transitionMatrix = transMat,
             states = as.character(stateNames),
             name = "P")
P <- dtmcA
```


    3. There are two closed classes 
    
$C^1 = \{`r summary(P)$closedClasses[[1]]`\}$ and $C^2 = \{`r summary(P)$closedClasses[[2]]`\}$ and a non-closed class 
$O^1 = \{`r summary(P)$transientClasses[[1]]`\}$.  The transition diagram is shown in the figure below:

```{r, echo = FALSE}
plot(dtmcA, package="diagram", self.cex = 0.7,  box.prop = 0.5, arr.length=0.2)
```

Let 
$\mathbf{u}=\mathbf{u}^{C_{2}}$ be the vector of absorption
probabilities in the closed class $C^2 = \{`r summary(P)$closedClasses[[2]]`\}$. Write
$\mathbf{u}= (u_1,u_2,u_3,u_4)^T$ and $u_4 = 1$ and $u_2 =  u_3 =0$,

From $\mathbf{u}=P \cdot \mathbf{u}$,

$$\left(\begin{array}{c}u_{1} \\ u_{2} \\  u_{3} \\ u_{4}\end{array}\right)=\begin{bmatrix}
                1/4 & 1/4 & 1/4 & 1/4      \\
                0 & 3/4 & 1/4 & 0   \\
                0 & 3/4 & 1/4 & 0   \\
            0 & 0 & 0 & 1     \\
        \end{bmatrix} \left(\begin{array}{c}u_{1} \\ u_{2} \\  u_{3} \\ u_{4}\end{array}\right) \text { gives}$$
$$ u_1 = \frac{1}{4} u_1 + \frac{1}{4}$$ Solving the
linear system for $u_1$ yields $u_1 = 1/3$.
Hence, the absorption probabilities in the closed class $C_2$ is
$$\mathbf{u}= (1/3,0,0,1)^T.$$ 
In addition, since there are two closed classes,
$\mathbf{u}^{C_1} = \mathbf{1} - \mathbf{u}^{C_2} = (2/3,1,1,0)^T.$



```{r Q4-4, echo = FALSE}

stateNames <- c(1,2,3,4,5,6,7)
transMat <- matrix(c(
           0 , 0 , 0 , 1/2  , 0 , 0 , 1/2   ,
           1/6 , 0 , 1/6 , 0  , 0 , 1/6 , 1/2 ,
            0 , 0 , 1 , 0 , 0 , 0 , 0    , 
                1/2 , 0 , 0 , 1/2  , 0 , 0 , 0   ,
            1/4 , 1/4 , 0 , 0  , 0 , 0 , 1/2 ,
            0 , 1 , 0 , 0 , 0 , 0 , 0    ,
            1/2 , 0 , 0 , 0  , 0 , 0 , 1/2
  ),
             nrow=7, byrow=TRUE)
row.names(transMat) <- stateNames 
colnames(transMat) <- stateNames

dtmcA <- new("markovchain",
             transitionMatrix = transMat,
             states = as.character(stateNames),
             name = "P")
P <- dtmcA
```


    4. There are two closed classes 
    
$C^1 = \{`r summary(P)$closedClasses[[1]]`\}$ and $C^2 = \{`r summary(P)$closedClasses[[2]]`\}$ and two non-closed classes 
$O^1 = \{`r summary(P)$transientClasses[[1]]`\}$ and $O^2 = \{`r summary(P)$transientClasses[[2]]`\}$.  The transition diagram is shown in the figure below:

```{r, echo = FALSE}
plot(dtmcA, package="diagram", self.cex = 0.7,  box.prop = 0.5, arr.length=0.2)
```


Let 
$\mathbf{u}=\mathbf{u}^{C_{2}}$ be the vector of absorption
probabilities in the closed class $C^2 = \{`r summary(P)$closedClasses[[2]]`\}$. Write
$\mathbf{u}= (u_1,u_2,u_3,\ldots, u_7)^T$ and $u_3 = 1$ and $u_1 = u_4 =  u_7 =0$,

$$\left(\begin{array}{c}u_{1} \\ u_{2} \\ \vdots \\ u_{7}\end{array}\right)=P\left(\begin{array}{c}u_{1} \\ u_{2} \\ \vdots \\ u_{7}\end{array}\right) \text{ gives}$$
$$\begin{aligned}
    u_2 &= \frac{1}{6}  + \frac{1}{6} u_6 \\
    u_5 &=   \frac{1}{4} u_2\\
    u_6 &=   u_2.\\   \end{aligned}$$ 
    Solving the linear system for $u_2, u_5$ and $u_6$ yields $u_2 = 1/5, u_5 = 1/20$ and $u_6 = 1/5$.
Hence, the absorption probabilities in the closed class $C_2$ is
$$\mathbf{u}= (0,1/5,1,0,1/20,1/5,0)^T.$$ 
In addition, since there are two closed classes,
$\mathbf{u}^{C_1} = \mathbf{1} - \mathbf{u}^{C_2} = (1,4/5,0,1,19/20,4/5,1)^T.$



4.  If the Markov chain defined in Question 3 is irreducible,
    i.e. it has a unique stationary distribution, then find the
    stationary distribution of the chain.

5.  Assume that a Markov chain has more than one closed classes (say $r$
    closed classes). The Markov chain can **have many stationary
    distributions**. Assume further that within each of these $r$ closed
    classes, the associated Markov chain is aperiodic. The followings
    hold:

    -   Within a closed class $C_1$, let $P_1$ be a reduction of a
        matrix $P$ which is formed by deleting all rows and columns
        corresponding to states from other classes. Then there exists a
        unique stationary distribution, denoted by
        $\{\pi_j^{(1)}\}_{j \in C_1}.$

    -   Similarly, let
        $\{\pi_j^{(2)}\}_{j \in C_2}, \ldots, \{\pi_j^{(r)}\}_{j \in C_r}$
        be stationary distributions within other classes.

    1.  Show that for any numbers $\gamma_1, \gamma_2, \ldots, \gamma_r$
        such that $\sum_{m=1}^r \gamma_m = 1$, the following
        distribution $\{ \pi_j \}$ is stationary, where
        

      \begin{equation} 
      (\#eq:limitdist)
        \pi_j =
         \begin{cases}
            \pi_j^{(k)} \gamma_k & \text{for } j \in C_k, \, k= 1,\ldots, r \\
            0 & \text{if } j \text{ is in a nonclosed class.}
          \end{cases}
        \end{equation}
        (In particular, any stationary distribution of the Markov chain is of this form.)

    2.  Write down the general form of stationary distributions of the
        Markov chain in Questions 3.3 and 3.4.

    3.  Now we will focus on limiting distributions. Consider the three
        following possible cases.

        1.  If $X_0 =  i$ and $i \in C_k$ for some closed class $C_k$,
            then verify that the limiting distribution is defined as in Eqn.\@ref(eq:limitdist) where $\gamma_k =1$ and
            $\gamma_m = 0,$ for $m \neq k$.

        2.  If $X_0 =  i$ and $i$ is in a nonclosed class, then verify
            that the limiting distribution is defined as in
            Eqn.\@ref(eq:limitdist) where $\gamma_k =  \alpha^{(k)}_i$
            for $k = 1,2,\ldots r$ where $\alpha^{(k)}_i$ is the
            probability of absorption in class $C_k$. More precisely,
            $$\pi_j =
             \begin{cases}
                \pi_j^{(k)} \alpha^{(k)}_i & \text{for } j \in C_k, \, k= 1,\ldots, r \\
                0 & \text{if } j \text{ is in a nonclosed class.}
              \end{cases}
                  %\pi_j^{(k)} \gamma_k \text{ for } j \in C_k, \, k= 1,\ldots, r \text { and }$$

        3.  If $X_0$ is random, then this will leave as extra exercise.
            (Hint: you may need to apply first step anslysis)

6.  A no-claims discount system for motor insurance has four levels of
    discount:

        Level     1     2     3     4
      ---------- ---- ----- ----- -----
       Discount   0%   10%   30%   50%

    The rules for moving between these levels are given as follows:

    -   Following a claim-free year, move to the next higher level, or
        remain at level 4.

    -   Following a year with one claim, move to the next lower level,
        or remain at level 1.

    -   Following a year with two or more claims, move down two levels,
        or move to level 1 (from level 2), or remain at level 1.

    A portfolio consists of 10,000 policyholders. Suppose also that the
    number of claims per year is $\mathcal{Poisson}(0.1)$.

    1.  Calculate $\Pr[N = 0]$, $\Pr[N = 1]$, and $\Pr[N \ge 2]$ for
        each group.

    2.  Write down the transition probability matrix of this no-claims
        discount system.

    3.  Find the probability that a policyholder who has the 30%
        discount has no discount after 2 years.

    4.  Calculate the expected number of policyholders at each level at
        times 1 and 2, assuming no exits.

    5.  Calculate the expected number of policyholders at each level
        once stability has been achieved, assuming no exits.

7.  A no-claims discount system for motor insurance has four levels of
    discount:

        Level     1     2     3     4
      ---------- ---- ----- ----- -----
       Discount   0%   20%   30%   50%

    The rules for moving between these levels are given as follows:

    -   For a claim-free year, a policyholder moves to the next higher
        level, or remains at level 4.

    -   For every claim in a year, the policyholder moves down a
        discount level or remains at level 1, for example if the
        policyholder is in level 4 and has one accident, he/she moves to
        level 3, and 2 accidents, he/she moves to level 2, and 2 or more
        accidents to level 1.

    For a given policyholder, the number of claims each year, $N$, has a
    negative binomial distribution with parameters $k=2$ and $p = 0.5$.

    Note that a random variable $N$ has a negative distribution with
    parameters $k$ and $p$, denoted by $N \sim \dnb$ if its probability
    mass function is given by
    $$f_N(n) = \Pr(N = n) = \frac{\Gamma(k+n)}{\Gamma(n+1)\Gamma(k)} p^k (1- p)^n \quad n = 0,1,2,\ldots.$$

    1.  Draw a transition diagram for the chain.

    2.  Write down the transition matrix of this no-claims discount
        system.

    3.  Find the probability that a policyholder who has the maximum
        discount level will have 20% discount after two years.





<!-- ## Tutorial 2 -->

<!-- 1.  A Markov chain $X_0, X_1, \ldots$ on states 1 ,2 ,3 has the -->
<!--     following transition matrix $$P = \begin{bmatrix} -->
<!--         0.5 & 0.3 & 0.2    \\ -->
<!--         0.2 & 0.2 & 0.6  \\ -->
<!--         0.3 & 0.2 &  0.5    \\ -->
<!--         %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix}.$$ The distribution of the initial random variable -->
<!--     $X_0$ is $\boldsymbol{\mu} = (0.3,0,3,0.4)$. -->

<!--     1.  Draw a transition diagram for the chain. -->

<!--     2.  Determine $\Pr(X_0 = 1, X_1 = 2, X_2 = 3).$ -->

<!--     3.  Determine $\Pr(X_1 = 2, X_2 = 3 | X_0 = 1).$ -->

<!--     4.  Determine $\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1).$ -->

<!--     5.  Determine $\Pr(X_2 = 3 | X_0 = 1).$ -->

<!--     6.  Determine $\Pr(X_3 = 3 | X_1 = 1).$ -->

<!--     7.  Determine $\Pr(X_2 = 3).$ -->

<!--     8.  Determine $\mathrm{E}[X_2]$ -->

<!-- 2.  A Markov chain $X_0, X_1, \ldots$ on states 1 ,2 ,3 has the -->
<!--     following transition matrix $$P = \begin{bmatrix} -->
<!--         0 & 1/2 & 1/2   \\ -->
<!--         1/3  & 1/3  & 1/3   \\ -->
<!--         1/2  & 1/2  & 0    \\ -->
<!--         %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix}.$$ The process starts in states $X_0 = 1$. -->

<!--     1.  Draw a transition diagram for the chain. -->

<!--     2.  Determine $\Pr(X_0 = 1, X_1 = 3, X_2 = 2).$ -->

<!--     3.  Determine $\Pr(X_1 = 3, X_2 = 2 | X_0 = 1).$ -->

<!--     4.  Determine $\Pr(X_2 = 2 | X_0 = 1).$ -->

<!--     5.  Determine $\Pr(X_3 = 2 | X_1 = 1).$ -->

<!--     6.  Determine $\Pr(X_2 = 2).$ -->

<!-- 3.  A Markov chain $X_0, X_1, \ldots$ on sates 1 ,2 has the following -->
<!--     transition matrix $$P = \begin{bmatrix} -->
<!--         1-a & a   \\ -->
<!--         b & 1-b   \\ -->
<!--         %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix},$$ where $0 < a,b < 1.$ -->

<!--     1.  Draw a transition diagram for the chain. -->

<!--     2.  the distribution of $X_1$. -->

<!--     3.  Show that $$P^n = \frac{1}{a+b} \begin{bmatrix} -->
<!--             b & a   \\ -->
<!--             b & a   \\ -->
<!--             %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--             %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--         \end{bmatrix} + -->
<!--         \frac{(1-a-b)^n}{a+b} \begin{bmatrix} -->
<!--             a & -a   \\ -->
<!--             -b & b   \\ -->
<!--             %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--             %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--         \end{bmatrix}.$$ -->

<!--     4.  Given that $X_0 = 1$, what is the probability that in the long -->
<!--         run the system will be in state 1? (Hint: consider -->
<!--         $\lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n$) -->

<!--     5.  Given that $X_0 = 1$, what is the probability that in the long -->
<!--         run the system will be in state 2? -->

<!--     6.  Given that $X_0 = 2$, what is the probability that in the long -->
<!--         run the system will be in state 1? -->

<!--     7.  Given that $X_0 = 2$, what is the probability that in the long -->
<!--         run the system will be in state 2? -->

<!-- 4.  Let $a$ be a constant and $\xi_1, \xi_2, \ldots$ be a sequence of -->
<!--     independent and identically distributed (i.i.d.) random variables. -->
<!--     The stochastic process $\{ X_n\}$ is defined by -->
<!--     $$X_0 = a, \quad X_n = X_{n-1} + \xi_n, \, n > 1.$$ This process is -->
<!--     known as a random walk. -->

<!--     1.  Express the state $X_n$ in terms of $X_0$ and the random -->
<!--         variables $\xi_i, i = 1,2 \ldots$. -->

<!--     2.  Find $\mathrm{E}[X_n]$ and $\mathrm{Var}[X_n]$. -->

<!--     3.  Does the process have the Markov property? Explain. -->

<!--     4.  Is the process stationary? Explain. -->

<!-- 5.  Consider a homogeneous discrete-time Markov chain that describes the -->
<!--     daily weather pattern. The weather patterns are classified into 3 -->
<!--     conditions: R(rainy), C (cloudy) and S(sunny). Based on the daily -->
<!--     observations, the following information are given: -->

<!--     -   On any rainy day, the probability that it will rain the next day -->
<!--         is 0.7; the probability that tomorrow will be cloudy is 0.2 and -->
<!--         the probability that tomorrow will be sunny is 0.1. -->

<!--     -   On any cloudy day, the probability that it will rain the next -->
<!--         day is 0.5; the probability that tomorrow will be cloudy is 0.35 -->
<!--         and the probability that tomorrow will be sunny is 0.15. -->

<!--     -   On any sunny day, the probability that it will rain the next day -->
<!--         is 0.1; the probability that tomorrow will be cloudy is 0.4 and -->
<!--         the probability that tomorrow will be sunny is 0.5. -->

<!--     1.  Draw a transition diagram for the chain and write down a -->
<!--         transition matrix. -->

<!--     2.  Find the probability that tomorrow is cloudy and the day after -->
<!--         is rainy, given that it is sunny today. -->

<!--     3.  Given that today is rainy, find the probability that it will be -->
<!--         sunny in two days time. -->

<!-- ## Tutorial 3 -->

<!-- 1.  A Markov chain $X_0, X_1, \ldots$ on states 1, 2, 3 with initial -->
<!--     distribution $\boldsymbol{\mu} = (1/4,1/4,1/2)$. It has the -->
<!--     following transition matrix $$P = \begin{bmatrix} -->
<!--         1/2 & 1/4 & 1/4   \\ -->
<!--         1/3  & 1/3  & 1/3   \\ -->
<!--         1/5  & 2/5  & 2/5    \\ -->
<!--         %\vdots & \vdots & \vdots  & \vdots \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix}.$$ Compute the following probabilities: -->

<!--     1.  $\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1).$ -->

<!--     2.  $\Pr(X_0 = 3, X_1 = 2 , X_2 = 1).$ -->

<!--     3.  $\Pr(X_1 = 3, X_2 = 2 , X_3 = 1).$ -->

<!--     4.  $\Pr(X_{1} = 2, X_{3} = 2, X_{5} = 2).$ -->

<!-- 2.  A Markov chain with state space $S = \{1,2,3,4,5,6\}$ has the -->
<!--     following transition matrix: $$P = \begin{bmatrix} -->
<!--     1/4 & 0 & 3/4 & 0 & 0 & 0  \\ -->
<!--     0 & 0 & 0 & 1 & 0 & 0  \\ -->
<!--     0 & 0 & 1/2 & 0 & 0 & 1/2  \\ -->
<!--     1/5 & 1/5 & 1/5 & 0 & 1/5 & 1/5   \\ -->
<!--     0 & 0 & 0 & 0 & 1 & 0  \\ -->
<!--     1/3 & 0 & 0 & 0 & 0 & 2/3  \\ -->
<!--         %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn} -->
<!--     \end{bmatrix}.$$ -->

<!--     1.  Draw a transition diagram. -->

<!--     2.  Identify the communication classes and classify them as closed -->
<!--         or non-closed. -->

<!--     3.  Is the Markov chain irreducible? -->

<!-- 3. For each of the Markov chains whose -->
<!--     transition matrix is given below, identify the closed classes and -->
<!--     the vector of absorption probabilities associated with each of these -->
<!--     closed classes. Assume that the states are labelled $1,2,3 \ldots$. -->

<!--     1.  $$\begin{bmatrix} -->
<!--                 1/6 & 0 & 1/3 & 1/2      \\ -->
<!--                 0 & 1/3 & 2/3 & 0   \\ -->
<!--             1/2 & 1/2 & 0 & 0     \\     -->
<!--             0 & 0 & 1/4 & 3/4     \\ -->
<!--         \end{bmatrix}.$$ -->

<!--     2.  $$\begin{bmatrix} -->
<!--                 0 & 1/4 & 3/4 & 0      \\ -->
<!--                 0 & 1/3 & 0 & 2/3   \\ -->
<!--             1/3 & 0 & 1/3 & 1/3     \\   -->
<!--             0 & 0 & 0 & 1     \\ -->
<!--         \end{bmatrix}.$$ -->

<!--     3.   $$\begin{bmatrix} -->
<!--                 1/4 & 1/4 & 1/4 & 1/4      \\ -->
<!--                 0 & 3/4 & 1/4 & 0   \\ -->
<!--                 0 & 3/4 & 1/4 & 0   \\ -->
<!--             0 & 0 & 0 & 1     \\ -->
<!--         \end{bmatrix}.$$ -->

<!--     4.   $$\begin{bmatrix} -->
<!--                 0 & 0 & 0 & 1/2  & 0 & 0 & 1/2   \\ -->
<!--                 1/6 & 0 & 1/6 & 0  & 0 & 1/6 & 1/2 \\ -->
<!--             0 & 0 & 1 & 0 & 0 & 0 & 0    \\  -->
<!--                 1/2 & 0 & 0 & 1/2  & 0 & 0 & 0   \\ -->
<!--             1/4 & 1/4 & 0 & 0  & 0 & 0 & 1/2 \\ -->
<!--             0 & 1 & 0 & 0 & 0 & 0 & 0    \\  -->
<!--                 1/2 & 0 & 0 & 0  & 0 & 0 & 1/2   \\ -->
<!--         \end{bmatrix}.$$ -->

<!-- 4.  If the Markov chain defined in Question 3 is irreducible, -->
<!--     i.e. it has a unique stationary distribution, then find the -->
<!--     stationary distribution of the chain. -->

<!-- 5.  Assume that a Markov chain has more than one closed classes (say $r$ -->
<!--     closed classes). The Markov chain can **have many stationary -->
<!--     distributions**. Assume further that within each of these $r$ closed -->
<!--     classes, the associated Markov chain is aperiodic. The followings -->
<!--     hold: -->

<!--     -   Within a closed class $C_1$, let $P_1$ be a reduction of a -->
<!--         matrix $P$ which is formed by deleting all rows and columns -->
<!--         corresponding to states from other classes. Then there exists a -->
<!--         unique stationary distribution, denoted by -->
<!--         $\{\pi_j^{(1)}\}_{j \in C_1}.$ -->

<!--     -   Similarly, let -->
<!--         $\{\pi_j^{(2)}\}_{j \in C_2}, \ldots, \{\pi_j^{(r)}\}_{j \in C_r}$ -->
<!--         be stationary distributions within other classes. -->

<!--     1.  Show that for any numbers $\gamma_1, \gamma_2, \ldots, \gamma_r$ -->
<!--         such that $\sum_{m=1}^r \gamma_m = 1$, the following -->
<!--         distribution $\{ \pi_j \}$ is stationary, where -->


<!--       \begin{equation}  -->
<!--       (\#eq:limitdist) -->
<!--         \pi_j = -->
<!--          \begin{cases} -->
<!--             \pi_j^{(k)} \gamma_k & \text{for } j \in C_k, \, k= 1,\ldots, r \\ -->
<!--             0 & \text{if } j \text{ is in a nonclosed class.} -->
<!--           \end{cases} -->
<!--         \end{equation} -->
<!--         (In particular, any stationary distribution of the Markov chain is of this form.) -->

<!--     2.  Write down the general form of stationary distributions of the -->
<!--         Markov chain in Questions 3.3 and 3.4. -->

<!--     3.  Now we will focus on limiting distributions. Consider the three -->
<!--         following possible cases. -->

<!--         1.  If $X_0 =  i$ and $i \in C_k$ for some closed class $C_k$, -->
<!--             then verify that the limiting distribution is defined as in Eqn.\@ref(eq:limitdist) where $\gamma_k =1$ and -->
<!--             $\gamma_m = 0,$ for $m \neq k$. -->

<!--         2.  If $X_0 =  i$ and $i$ is in a nonclosed class, then verify -->
<!--             that the limiting distribution is defined as in -->
<!--             Eqn.\@ref(eq:limitdist) where $\gamma_k =  \alpha^{(k)}_i$ -->
<!--             for $k = 1,2,\ldots r$ where $\alpha^{(k)}_i$ is the -->
<!--             probability of absorption in class $C_k$. More precisely, -->
<!--             $$\pi_j = -->
<!--              \begin{cases} -->
<!--                 \pi_j^{(k)} \alpha^{(k)}_i & \text{for } j \in C_k, \, k= 1,\ldots, r \\ -->
<!--                 0 & \text{if } j \text{ is in a nonclosed class.} -->
<!--               \end{cases} -->
<!--                   %\pi_j^{(k)} \gamma_k \text{ for } j \in C_k, \, k= 1,\ldots, r \text { and }$$ -->

<!--         3.  If $X_0$ is random, then this will leave as extra exercise. -->
<!--             (Hint: you may need to apply first step anslysis) -->

<!-- 6.  A no-claims discount system for motor insurance has four levels of -->
<!--     discount: -->

<!--         Level     1     2     3     4 -->
<!--       ---------- ---- ----- ----- ----- -->
<!--        Discount   0%   10%   30%   50% -->

<!--     The rules for moving between these levels are given as follows: -->

<!--     -   Following a claim-free year, move to the next higher level, or -->
<!--         remain at level 4. -->

<!--     -   Following a year with one claim, move to the next lower level, -->
<!--         or remain at level 1. -->

<!--     -   Following a year with two or more claims, move down two levels, -->
<!--         or move to level 1 (from level 2), or remain at level 1. -->

<!--     A portfolio consists of 10,000 policyholders. Suppose also that the -->
<!--     number of claims per year is $\mathcal{Poisson}(0.1)$. -->

<!--     1.  Calculate $\Pr[N = 0]$, $\Pr[N = 1]$, and $\Pr[N \ge 2]$ for -->
<!--         each group. -->

<!--     2.  Write down the transition probability matrix of this no-claims -->
<!--         discount system. -->

<!--     3.  Find the probability that a policyholder who has the 30% -->
<!--         discount has no discount after 2 years. -->

<!--     4.  Calculate the expected number of policyholders at each level at -->
<!--         times 1 and 2, assuming no exits given that all policyholders start at level 1. -->

<!--     5.  Calculate the expected number of policyholders at each level -->
<!--         once stability has been achieved, assuming no exits. -->

<!-- 7.  A no-claims discount system for motor insurance has four levels of -->
<!--     discount: -->

<!--         Level     1     2     3     4 -->
<!--       ---------- ---- ----- ----- ----- -->
<!--        Discount   0%   20%   30%   50% -->

<!--     The rules for moving between these levels are given as follows: -->

<!--     -   For a claim-free year, a policyholder moves to the next higher -->
<!--         level, or remains at level 4. -->

<!--     -   For every claim in a year, the policyholder moves down a -->
<!--         discount level or remains at level 1, for example if the -->
<!--         policyholder is in level 4 and has one accident, he/she moves to -->
<!--         level 3, and 2 accidents, he/she moves to level 2, and 2 or more -->
<!--         accidents to level 1. -->

<!--     For a given policyholder, the number of claims each year, $N$, has a -->
<!--     negative binomial distribution with parameters $k=2$ and $p = 0.5$. -->

<!--     Note that a random variable $N$ has a negative distribution with -->
<!--     parameters $k$ and $p$, denoted by $N \sim \dnb$ if its probability -->
<!--     mass function is given by -->
<!--     $$f_N(n) = \Pr(N = n) = \frac{\Gamma(k+n)}{\Gamma(n+1)\Gamma(k)} p^k (1- p)^n \quad n = 0,1,2,\ldots.$$ -->

<!--     1.  Draw a transition diagram for the chain. -->

<!--     2.  Write down the transition matrix of this no-claims discount -->
<!--         system. -->

<!--     3.  Find the probability that a policyholder who has the maximum -->
<!--         discount level will have 20% discount after two years. -->

## Tutorial 4


1.  Customers arrive in a shop according to a Poisson process of rate
    $\lambda = 2$. Let $N(t)$ be the number of customers that have
    arrived up to time $t$. Determine the following probabilities,
    conditional probabilities and expectations.

    1.  $\Pr(N(1) = 2).$

    2.  $\Pr(N(1) = 2 \text{ and } N(3) = 6).$

    3.  $\Pr(N(1) = 2 | N(3) = 6).$

    4.  $\Pr(N(3) = 6 | N(1) = 2).$

    5.  $\Pr(N(1) \le 2).$

    6.  $\Pr(N(1) = 1 \text{ and } N(2) = 3).$

    7.  $\Pr(N(1) \ge 2 | N(1) \ge 1).$

    8.  $\mathrm{E}[N(2)]$

    9.  $\mathrm{E}[N(1)^2]$

    10. $\mathrm{E}[N(1)N(2)]$

2.  Customers arrive in a shop according to a Poisson process of rate
    $\lambda = 4$ per hour. The shop opens at 9 am. Calculate the
    probability that exactly one customer has arrived by 9.30 am and a
    total of five customers have arrived by 11.30.

3.  Defects occur along a cable according to a Poisson process of rate
    $\lambda = 0.1$ per kilometre.

    1.  Calculate the probability that no defects appear in the first
        two kilometres of cable.

    2.  Given that there are no defects in the first two kilometres of
        cable, calculate the probability of no defects between two and
        three kilometres of cable.

4.  Customers arrive at a department store according to a Poisson
    process with rate $\lambda = 2$ per minute.

    1.  Calculate the probability that in a given 5 minute period there
        will be no customers arriving?

    2.  Calculate the probability that the 10th customer after 11 am
        will arrive before 11:05 am?

    3.  If a third of customers are men, calculate the probability that
        in a 5 minute period more than 3 men arrive given more than 4
        women arrive.

    4.  If every 5th customer receives a discount voucher, calculate the
        distribution of the times between these vouchers being given
        out? What is the probability that a time longer

5.  You have a bird table in your garden which attracts tailorbirds and
    pigeons. Tailorbirds arrive according to a Poisson process with rate
    $\lambda_1$ and the pigeons arrive according to a Poisson process
    with rate $\lambda_2$.

    1.  How long does it take for the first bird to arrive after a fixed
        point in time?

    2.  Calculate the probability this bird is a tailorbird?

    3.  What is the distribution of the number of birds in the time
        interval $[t_1, t_2)$?

    4.  Calculate the probability that exactly 3 tailorbirds arrive
        before the first pigeon after a fixed point in time?

6.  Let $X$ and $Y$ be independent Poisson distributed random variables
    with parameters $\lambda_X$ and $\lambda_Y$, respectively. Determine
    the conditional distribution of $X$, given that $N = X + Y = n$.

7.  Accidents occur on an highway according to a Poisson process at the
    rate of 20 accidents per week. One out of four accidents involve
    speeding.

    1.  What is the probability that ten accidents involving speeding
        will occur next week?

    2.  What is the probability that at least one accident occurs
        tomorrow?

    3.  If sixty accidents occur in four weeks, what is the probability
        that less than half of them involve speeding?

8.  Severe floods hit a southern of Thailand according to a Poisson
    process with $\lambda = 4$. The number of insurance claims filed
    after any sever flood has a Poisson distribution with mean 60. The
    number of server floods is independent of the number of insurance
    claims. Find the expectation and standard deviation of the total
    number of claims filed by time $t$.

9.  Assume that births occur at a hospital at the average rate of 3
    births per hour. Assume that the probability that any birth is a boy
    is 0.52.

    1.  On an 8-hour shift, what is the expectation and standard
        deviation of the number of male births?

    2.  Assume that ten babies were born yesterday. Find the probability
        that six are boys.

    3.  Find the probability that only boys were born between 6 and 10
        a.m.


## Tutorial 5


1.  Suppose that we observe life $i$ at exact age 74 years and 3 months.
    The observation will continue until the earlier of the life's 75th
    birthday or death. Assume that the force of mortality equal 0.08.

    1.  Calculate the probability function of $D_i$, i.e. calculate
        $\Pr(D_i = 0)$ and $\Pr(D_i = 1)$.

    2.  Calculate $\textrm{E}[D_i]$.

    3.  Calculate the probability density/mass function of $V_i$ (Hint:
        consider two cases (i) when $v_i < 0.75$ and (ii) when
        $v_i = 0.75$).

    4.  Calculate $\textrm{E}[V_i]$.

2.  For life $i$, recall that

    -   $x+ a_i$ is the age at which observation
        begins,$\quad 0 \le a_i < 1$.

    -   $x+ b_i$ is the age at which observation ends, if life does not
        die, $\quad 0 \le b_i < 1$.

    The terms $a_i$ and $b_i$ are known constants.

    1.  Show that
        $\displaystyle \textrm{E}[D_i] = \int_0^{b_i - a_i} e^{-\mu t}  \mu \, \text{d}t.$

    2.  Show that
        $\displaystyle \textrm{E}[V_i] = \int_0^{b_i - a_i}t  e^{-\mu t}  \mu \, \text{d}t + (b_i - a_i)  e^{-\mu(b_i - a_i)}.$

3.  In terms of the probability function of $(D_i, V_i)$,

    1.  explain why the following expression holds:
        $$\int_0^{b_i - a_i} e^{-\mu v_i} \mu \, \text{d}v_i + e^{-\mu(b_i - a_i)} = 1.$$

    2.  Differentiating the above expression with respect to $\mu$, show
        that $$\textrm{E}[ D_i - \mu V_i] = 0 .$$

    3.  Differentiating the above expression twice with respect to
        $\mu$, show that $$\textrm{Var}[D_i - \mu V_i] = \textrm{E}[D_i].$$

4.  Show that
    $$\textrm{Var}[\hat{\mu}] \rightarrow  \left. \frac{\mu^2}{\textrm{E}[D]} \right\vert_{ \mu = \mu_0 },$$
    and hence
    $$\textrm{Var}[\hat{\mu}] \rightarrow \left. \frac{\mu}{\textrm{E}[V]} \right\vert_{ \mu = \mu_0 }=  \frac{\mu_0}{E[V]}.$$

5.  1300 lives aged between 70 and 71 have been observed. We wish to
    calculate the force of mortality over this period.

    Suppose the true value of the force of mortality is 0.12 for lives
    aged between 70 and 71. Calculate the probability that the observed
    force of mortality is greater than 0.15.

    Hint: use the fact that the estimate $\hat{\mu}$ is asymptotically
    normal
    $$\hat{\mu} \approx \mathcal{N}( \mu_0,   \frac{\mu_0}{E[V]} ).$$

6.  Consider the following mortality data on ten lives all aged between
    $75$ and $76$.

       Life   $a_i$   $b_i$   $d_i$   $t_i$
      ------ ------- ------- ------- -------
        1       0       1       1      0.5
        2       0       1       1     0.75
        3       0       1       0       1
        4       0       1       0       1
        5       0       1       0       1
        6      0.1     0.6      1      0.5
        7      0.2     0.7      1      0.6
        8      0.2     0.4      0      0.4
        9      0.5     0.8      0      0.8
        10     0.5      1       0       1



    1.  Using the Markov model, estimate the force of mortality
        $\mu_{75}$ assuming that it is constant from $75$ to $76$.

    2.  Estimate the variance of $\hat{\mu}$.

    3.  Construct the 95% confidence interval for the force of
        mortality.

    4.  Estimate $\hat{q}_{75} = {}_{1}\hat{q}_{75}$, the probability of
        a life aged (75) dying within one year.

    5.  Use the $\Delta-$method to estimate the variance of
        $\hat{q}_{75}$.

## Tutorial 6

1.  

    Consider the 3-state model of terminal illness for healthy, ill and
    dead states as shown below.
    
```{tikz, tikz-ex0, fig.cap = "The 3-state model of terminal illness", fig.ext = 'png', cache=TRUE, echo = FALSE, fig.align = 'center'}
\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        

\begin{tikzpicture}
    % place nodes
    \node[draw, minimum height=1cm,minimum width=3cm] at (0, 0)   (a) {Healthy : h};
    \node[draw, minimum height=1cm,minimum width=3cm] at (6, 0)   (b) {Ill : i};

    \node[draw, minimum height=1cm,minimum width=3cm] at (3, -2)  (c)     {Dead : d};
    %\node[draw ] at (5, -2)  (d)     {D};

    % draw edges
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (a) node[xshift =  3cm,yshift=0.3cm] {$\lambda$} -- (b);
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (a) node[xshift =  0.6cm,yshift=-1.2cm] {$\mu$}  -- (c);
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (b) node[xshift =  -0.6cm,yshift=-1.2cm] {$\nu$} -- (c);

    %\draw (0,-3) node[above,near start abs] {Test} -- ++(7,0);
\end{tikzpicture}


```    
    
    

    1.  What can you say about 
    
$p_{hh}(t)$ and $p_{\overline{hh}}(t)$,
        and about $p_{ii}(t)$ and $p_{\overline{ii}}(t)$?

    2.  Write down the Kolmogorov forward differential equations (FDE)
        for 

$\frac{d}{dt}p_{hh}(t)$, $\frac{d}{dt}p_{ii}(t)$ and solve
        these equations.

    3.  Write down the Kolmogorov forward differential equations (FDE)
        for 
        
$\frac{d}{dt}p_{hi}(t)$, $\frac{d}{dt}p_{hd}(t)$ and explain
        how to solve these equations.

2.   Consider a model of the
    mortality of two lives (husband and wife) consisting of for states :
    
  -   $b =$ both lives are alive,

  -   $u =$ husband is alive, but wife is dead,

  -   $v =$ wife is alive, but husband is dead, and

  -   $d =$ both are dead.

```{tikz, tikz-ex1, fig.cap = "A model of the mortality of two lives", fig.ext = 'png', cache=TRUE, echo = FALSE, fig.align = 'center'}
\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt  
\begin{tikzpicture}
    % place nodes
    \node[draw, align = center, text width = 4cm, minimum height=1cm ,minimum width=3cm] at (0, 0)   (a) {State $b$  \\ Both alive};
    \node[draw, align = center , text width = 4cm,  minimum height=1cm,minimum width=3cm] at (8, 0)   (b) {State $u$  \\ Husband alive, wife dead };

    \node[draw, align = center, text width = 4cm, minimum height=1cm,minimum width=3cm] at (0, -3)   (c) {State $v$  \\Husband dead, wife alive};
    
    \node[draw, align = center , text width = 4cm,  minimum height=1cm,minimum width=3cm] at (8, -3)  (d)     {State $d$ \\Both dead};
    %\node[draw ] at (5, -2)  (d)     {D};

    % draw edges
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (a) node[xshift =  4cm,yshift=0.3cm] {$\alpha_1$} -- (b);
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (a) node[xshift =  0.6cm,yshift=-1.4cm] {$\beta1$}  -- (c);
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (b) node[xshift =  -0.6cm,yshift=-1.4cm] {$\beta2$} -- (d);
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (c) node[xshift =  4cm,yshift=-0.3cm] {$\alpha_2$} -- (d);    

    %\draw (0,-3) node[above,near start abs] {Test} -- ++(7,0);
\end{tikzpicture}
```


    The model is also referred to as the joint life and last survivor
    model. Write down the Kolmogorov equation for
    
$\frac{d}{dt}p_{bu}(t)$, $\frac{d}{dt}p_{bv}(t)$ and
    $\frac{d}{dt}p_{bd}(t)$.

3.  A group of lives who hold health insurance policies can be
    classified into able ($a$), ill ($i$), dead ($d$) and withdrawn
    ($w$). The lives can move between state according to the following
    diagram:

```{tikz, tikz-ex2, fig.cap = "A Markov model for health insurance policies", fig.ext = 'png', cache=TRUE, echo = FALSE, fig.align = 'center'}
\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        

\begin{tikzpicture}
    % place nodes
    \node[draw, align = center, text width = 4cm, minimum height=1cm ,minimum width=3cm] at (0, 0)   (a) {Able};
    \node[draw, align = center , text width = 4cm,  minimum height=1cm,minimum width=3cm] at (8, 0)   (b) {Ill };

    \node[draw, align = center, text width = 4cm, minimum height=1cm,minimum width=3cm] at (0, -3)   (c) {Withdrawn};
    
    \node[draw, align = center , text width = 4cm,  minimum height=1cm,minimum width=3cm] at (8, -3)  (d)     {Dead};
    %\node[draw ] at (5, -2)  (d)     {D};

    % draw edges
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (a) node[xshift =  4cm,yshift=0.3cm] {$\sigma$ (from $a$ to $i$)} -- (b);
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (b) node[xshift =  -4cm,yshift=-0.3cm] {$\rho$ (from $i$ to $a$)} -- (a);
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (a) node[xshift =  0.6cm,yshift=-1.4cm] {$\omega$}  -- (c);
    \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (b) node[xshift =  -0.6cm,yshift=-1.4cm] {$\nu$} -- (d);
        \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (a) node[xshift =  4cm,yshift=-1.3cm] {$\mu$} -- (d);
   % \draw[->,shorten <=2pt,shorten >=2pt,>=stealth] (c) node[xshift =  4cm,yshift=-0.3cm] {$\alpha_2$} -- (d);    

    %\draw (0,-3) node[above,near start abs] {Test} -- ++(7,0);
\end{tikzpicture}
```

    Assuming that all transition rates are constant, write down the
    Kolmogorov forward differential equations (FDE) for
    
$p_{aa}(t), p_{ai}(t)$ and $p_{aw}(t)$.

4.  An actuary wishes to study a model in which states relate to marital
    status comprising of five states, single, married, divorced, widowed
    and dead. Draw the transition diagram that illustrate the possible
    transitions between these five states.ß
