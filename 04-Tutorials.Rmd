# Tutorials

## Tutorial 1

1.  Consider a random walk, $S_n$, with $S_0 = 0$ and where each step is
    normally distributed with mean 0 and variance 10.

    1.  What is the distribution of $S_{10}$?

    2.  Calculate $\Pr(S_{10} < -10)$.

    **Solution:**

    1.  We have $S_{10}$ is a sum of
        $S_0$ and the i.i.d random variables $Z_i$, each distributed
        normal distribution, $Z_i \sim N(0,10)$. Moreover,
        $$\mathrm{E}[S_{10}] = \mathrm{E}[S_0 + \sum_{i=1}^{10} Z_i] = S_0 + \sum_{i=1}^{10} \mathrm{E}[Z_i] = 0$$
        and
        $$\mathrm{Var}[S_{10}] = \mathrm{Var}[S_0 + \sum_{i=1}^{10} Z_i] = \sum_{i=1}^{10} \mathrm{Var}[Z_i] = 100$$
        Therefore, the distribution of $S_{10}$ is normally distributed,
        $S_{10} \sim N(0,100)$.

    2.  From the previous result,
        $$\Pr(S_{10} < -10) = \Pr(Z < -1) = 0.1587.$$

2.  Suppose that the value of a commodity as a random walk, where each
    day the change in price has mean \$0.05 and variance \$0.1. Use the
    central limit theorem to estimate the probability that its value is
    more than \$6 after 100 days if the initial value is \$0.50.

    **Solution:** We have $S_{100}$ is a sum of $S_0$ and the i.i.d
    random variables $Z_i$, each distributed normal distribution,
    $Z_i \sim N(0.05,0.1)$. Moreover,
    $$\mathrm{E}[S_{100}] = \mathrm{E}[S_0 + \sum_{i=1}^{100} Z_i] = S_0 + \sum_{i=1}^{100} \mathrm{E}[Z_i] = 5.5$$
    and
    $$\mathrm{Var}[S_{100}] = \mathrm{Var}[S_0 + \sum_{i=1}^{100} Z_i] = \sum_{i=1}^{100} \mathrm{Var}[Z_i] = 10$$
    Therefore, the distribution of $S_{100}$ is normally distributed,
    $S_{100} \sim N(5.5,10)$.

    The Central Limit Theorem implies that $S_{100}$ is approximately
    normally distributed, $S_{100} \sim N(5.5,10)$.

    $$\Pr(S_{100} > 6) = \Pr(Z > 0.1581) = 1 -  \Pr(Z < 0.1581)  = 1- 0.5628 = 0.4372.$$

3.  For the random walk process as described in the lecture note,

    1.  Calculate $\Pr(X_8 = 96 | X_0 = 100),$

    2.  Calculate $\Pr(X_1 = 99, X_8 = 96 | X_0 = 100),$

    3.  Calculate $\Pr(X_1 = 99,
        X_4 = 98, X_8 = 96 | X_0 = 100),$

    4.  Calculate $\Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100),$

    5.  Given $X_0 = 100$, calculate $\mathrm{E}[X_5]$.

    6.  Write down the joint distribution of $X_1$ and $X_3$ given
        $X_0 = 100$. (Hint: consider all possible sample paths)

    **Solution:**

    1.  Here the price must increase on any 2 day(s) and decrease on any
        6 day(s), not necessarily in that order. There are
        ${ 8 \choose 2} = 28$ different possibilities and each of these
        has probability $p^{2}(1-p)^{6}$. Therefore, the required
        probability is
        $$\Pr(X_8 = 96 | X_0 = 100) =  28  p^{2}(1-p)^{6} .$$

    2.  The problem can be divided into two periods:

        -   The first period of 1 day(s): the price in this period must
            increase on any 0 day(s) and decrease on any 1 day(s), not
            necessarily in that order. There are ${ 1 \choose 0}$
            different possibilities and each of these has probability
            $p^{0}(1-p)^{1}$.

        -   The next period of 7 day(s): the price in this period must
            increase on any 2 day(s) and decrease on any 5 day(s), not
            necessarily in that order. There are ${ 7 \choose 2}$
            different possibilities and each of these has probability
            $p^{2}(1-p)^{5}$.

        The required probability is
        $$\Pr(X_1 = 99, X_8 = 96 | X_0 = 100)  =  21  p^{2}(1-p)^{6} .$$

    3.  Similar to the previous problem, the required probability can be
        calculated as follows:

        The problem can be divided into three periods:

        -   The first period of 1 day(s): the price in this period must
            increase on any 0 day(s) and decrease on any 1 day(s), not
            necessarily in that order. There are ${ 1 \choose 0}$
            different possibilities and each of these has probability
            $p^{0}(1-p)^{1}$.

        -   The next period of 3 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 2 day(s), not
            necessarily in that order. There are ${ 3 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{2}$.

        -   The last period of 4 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 3 day(s), not
            necessarily in that order. There are ${ 4 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{3}$.

        The required probability is $$\Pr(X_1 = 99,
        X_4 = 98, X_8 = 96 | X_0 = 100)  =  12  p^{2}(1-p)^{6} .$$

    4.  By Markov property, we have $$\Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100), 
        = \Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99).$$ Again, the problem can be
        divided into two periods:

        -   The first period of 3 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 2 day(s), not
            necessarily in that order. There are ${ 3 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{2}$.

        -   The next period of 4 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 3 day(s), not
            necessarily in that order. There are ${ 4 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{3}$.

        The required probability is $$\Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100)
        = \Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99)  =  12  p^{2}(1-p)^{5} .$$

    5.  The variable $X_5$ can take the values from
        $95, 97, 99, 101, 103, 105$. In particular, $$\begin{aligned}
            \Pr(X_5 &= 95) = {5 \choose 0} p^0 (1-p)^5 =  1 
        p^0 (1-p)^5    \\
            \Pr(X_5 &= 97) = {5 \choose 1} p^1 (1-p)^4 = 5 
            p^1 (1-p)^4\\
            \Pr(X_5 &= 99) = {5 \choose 2} p^2 (1-p)^3 = 10 
            p^2 (1-p)^3\\
            &\vdots \\
            \Pr(X_5 &= 105) = {5 \choose 5} p^5 (1-p)^0 = 1 
            p^5 (1-p)^0 \end{aligned}$$

        Therefore, $\mathrm{E}[X_5] = 
         95 \cdot \left( 1 
        p^0 (1-p)^5 \right)
        + 97 \cdot \left(5 
        p^1 (1-p)^4 \right)
        + 99 \cdot \left(10 
        p^2 (1-p)^3 \right)
        + \cdots
        + 105 \cdot \left( 1 
            p^5 (1-p)^0 \right) = 95 + 10*x.$
      Alternatively, $$\begin{aligned}
      E\left[X_{5}\right] &=E\left[100+\sum_{i=1}^{5} Z_{i}\right] \\
      &= 100+5 \cdot E\left[Z_{i}\right]  \\
      &=100+ 5 (2 p-1)  \\
      &=95 + 10p\end{aligned}$$
      where $E\left[Z_{i}\right] = p-q  = p - (1 - p) = 2p -1.$

4.  For each event,

    -   Identify a stochastic process $\{ X_t : t \in T\}$ and describe
        $X_t$ in context.

    -   Describe the time domain and state space. State whether the time
        domain and state space are discrete or continuous.

    1.  Sociologists categorise the population of a country into upper-,
        middle- and lower-class groups. One of the government offices
        has monitored the movement of successive generations among these
        three groups.

    2.  The insurer's surplus (an excess of income or assets over
        expenditure or liabilities in a given period) at any future time
        which is defined as the initial surplus plus the premium income
        up to time $t$ minus the aggregate claims up to time $t$.

    3.  In a working day, a coffee shop owner records customer arrival
        times.

    4.  The gambler starts with m and bets per game. The probability of
        winning is $p$ and the probability of losing is $q$ where
        $p + q = 1$. In addition, the gambler is ruined (or goes broke)
        if he reaches state 0, and also stops the game if he reaches
        state $N$.

    5.  In the board game Monopoly, there are 40 squares. A player is
        interested to know the successive board position.

    **Solution:**

    1.  Let $X_{n}$ be the class of $n^{\text {th }}$ generation of a
        family. The state space, $S=\{\text {Upper, Middle, Lower} \}$,
        is discrete. The index set, $I=\{0,1,2, \ldots\}$, is also
        discrete.

    2.  Let $S(t)$ be the insurer's surplus at time $t$.
        $S=\mathbb{R} \text { and }  I=[0, \infty)$.

    3.  Let $X_{n}$ be the amount of money of the gambler after game
        $n$.

        $S=\{0,1,2 \ldots, N\} \text { and } I=\{0,1,2 ,\ldots \}$.

    4.  Suppose that the opening hours of the coffee shop are from 7:00
        am to 6:00 pm (i.e. 11 hours). Let $X_{n}$ be the arrival time
        of customer $n$. State space (continuous)

        $S=[0,11 \times 60]=[0,660]$ (in minutes) and
        $I=\{1,2, \ldots\}$.

    5.  Let $x_{n}$ be a player's board position after $n$ plays.

        $S=\{1,2,3, \ldots, 40\}$ and $I=\{0,1,2, \ldots \}.$

5.  The simple weather pattern can be classified into three types
    including rainy ($R$), cloudy ($C$) and sunny ($S$). The weather is
    observed daily. The following information is provided.

    -   On any given rainy day, the probability that it will rain the
        next day is 0.7; the probability that it will be cloudy the next
        day 0.2.

    -   On any given cloudy day, the probability that it will rain the
        next day is 0.75; the probability that it will be sunny the next
        day 0.1.

    -   On any given sunny day, the probability that it will rain the
        next day is 0.2; the probability that it will be sunny the next
        day 0.4.

    Explain how this may be modelled by a Markov chain.

    **Solution:** The three weather conditions describe the three state of
    the Markov chain. Let $X_{n}$be the weather condition on day $n$.

    -   State 1 (R) rainy day

    -   State 2 (C) cloudy day

    -   State 3 (S) sunny day

    The transition probability matrix $P$ for this Markov chain is

    $$P=\left[\begin{array}{lll}
    0.7 & 0.2 & 0.1 \\
    0.75 & 0.15 & 0.1 \\
    0.2 & 0.4 & 0.4
    \end{array}\right]$$

    This stochastic process has the Morkov property because the weather
    condition on the next day depends only on the condition today.

6.  Explain whether an independent and identically distributed sequence
    of random variables has a Markov property. 
    
    **Solution:** Assume that
    this Markov chain $X_0, X_1, X_2 \ldots,$ takes values in
    $\{1,2, \ldots, k\} \text { with }$

    $$P\left(X_{n}=j\right) = p_{j} \quad \text { for } j=1,2, \ldots, k \quad \text { and } n \geq 0 .$$
    Note that this equality holds for all $n$ because
    $\left\{X_{n} \right\}_{n \ge 0}$ have the same distribution.

    By independence,

    $$P\left(x_{n}=j \mid x_{n-1}=i\right)=P\left(x_{n}=j\right)=p_{j},$$

    This proves our claim that the i.i.d. sequence of random variables
    has a Markov property. Note also that the transition matrix is
    $$P = 
    \begin{bmatrix}
    p_1 & p_2 & \cdots & p_k \\
    p_1 & p_2 & \cdots & p_k \\
    \vdots & \vdots &  & \vdots \\
    p_1 & p_2 & \cdots & p_k \\
    \end{bmatrix}.$$

7.  The random variables $Z_1, Z_2, \ldots$ are independent and with the
    common probability mass function $$Z_i = \begin{cases}
        1, & \text{ with probability }  0.2 \\
        2, & \text{ with probability }  0.3 \\  
        3, & \text{ with probability }  0.4 \\  
        4, & \text{ with probability }  0.1 \\  
     \end{cases}$$ Let $X_0 = 1$ and
    $X_n = \max\{Z_1, Z_2, \ldots, Z_n \}$ be the largest $Z$ observed
    to date. Explain how this may be modelled by a Markov chain.
    **Solution:**

    Given $X_{0}=1$ and
    $X_{n}=\max \left\{Z_{1}, Z_{2}, \ldots, Z_{n}\right\}$ where
    $\left\{Z_{i}\right\}$ are i.i.d. random variables with

      $i$            1     2     3     4
      -------------- ----- ----- ----- -----
      $P(Z_i = i)$   0.2   0.3   0.4   0.1

    We note that $$\begin{aligned}
    X_{n+1} &=\operatorname{max}\left\{Z_{1}, Z_{2}, \ldots, Z_{n+1}\right\} \\
    &=\operatorname{max}\left\{X_{n}, Z_{n+1}\right\}
    \end{aligned}$$ Consider the transition probabilities

    $$\begin{aligned}
    P\left(X_{n+1} = j \mid X_{n}=i \right) &= P\left(\max \left\{X_{n}, Z_{n+1}\right\}=j \mid X_{n}=i\right) \\
    &=P\left(\max \left\{i, Z_{n+1}\right\}=j \mid X_{n}=i\right)
    \end{aligned}$$

    **Case 1:** If $i=1$, then $$\max \left\{1, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0.2 \\
    2 & \text{w.p. } 0.3 \\
    3  & \text{w.p. } 0.4 \\
    4  & \text{w.p. } 0.1 \\
    \end{cases}$$

    **Case 2:** If $i=2$, then $$\max \left\{2, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0 \\
    2 & \text{w.p. } 0.5 \quad (\text{i.e. } z_{n+1} = 1 \text{ or } 2  )\\
    3  & \text{w.p. } 0.4 \\
    4  & \text{w.p. } 0.1 \\
    \end{cases}$$

    **Case 3:** If $i=3$, then $$\max \left\{3, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0 \\
    2 & \text{w.p. } 0 \\
    3  & \text{w.p. } 0.9 \\
    4  & \text{w.p. } 0.1 \\
    \end{cases}$$

    **Case 4:** If $i=4$, then $$\max \left\{4, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0 \\
    2 & \text{w.p. } 0 \\
    3  & \text{w.p. } 0 \\
    4  & \text{w.p. } 1 \\
    \end{cases}$$ The transition probability matrix is then

    $$P = 
    \begin{bmatrix}
    0.2 & 0.3 & 0.4 & 0.1 \\
    0 & 0.5 & 0.4 & 0.1 \\
    0 & 0 & 0.9 & 0.1 \\
    0 & 0 & 0 & 0.1 \\
    \end{bmatrix}.$$ Clearly the sequence $X_0, X_1, X_2,\ldots$ can be
    modelled by the Markov chain with the transition probability matrix
    $P$. Moreover, given the most recent value $X_n$, its future value
    $X_{n+1}$ is independent of the past history
    $X_0, X_1, \ldots, X_{n-1}$.



## Tutorial 2

1.  A Markov chain $X_0, X_1, \ldots$ on states 1 ,2 ,3 has the
    following transition matrix $$P = \begin{bmatrix}
        0.5 & 0.3 & 0.2    \\
        0.2 & 0.2 & 0.6  \\
        0.3 & 0.2 &  0.5    \\
        %\vdots & \vdots & \vdots  & \vdots \\
        %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
    \end{bmatrix}.$$ The distribution of the initial random variable
    $X_0$ is $\boldsymbol{\mu} = (0.3,0,3,0.4)$.

    1.  Draw a transition diagram for the chain.

    2.  Determine $\Pr(X_0 = 1, X_1 = 2, X_2 = 3).$

    3.  Determine $\Pr(X_1 = 2, X_2 = 3 | X_0 = 1).$

    4.  Determine $\Pr(X_{11} = 2, X_{12} = 3 | X_{10} = 1).$

    5.  Determine $\Pr(X_2 = 3 | X_0 = 1).$

    6.  Determine $\Pr(X_3 = 3 | X_1 = 1).$

    7.  Determine $\Pr(X_2 = 3).$

    8.  Determine $\mathrm{E}[X_2]$

2.  A Markov chain $X_0, X_1, \ldots$ on states 1 ,2 ,3 has the
    following transition matrix $$P = \begin{bmatrix}
        0 & 1/2 & 1/2   \\
        1/3  & 1/3  & 1/3   \\
        1/2  & 1/2  & 0    \\
        %\vdots & \vdots & \vdots  & \vdots \\
        %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
    \end{bmatrix}.$$ The process starts in states $X_0 = 1$.

    1.  Draw a transition diagram for the chain.

    2.  Determine $\Pr(X_0 = 1, X_1 = 3, X_2 = 2).$

    3.  Determine $\Pr(X_1 = 3, X_2 = 2 | X_0 = 1).$

    4.  Determine $\Pr(X_2 = 2 | X_0 = 1).$

    5.  Determine $\Pr(X_3 = 2 | X_1 = 1).$

    6.  Determine $\Pr(X_2 = 2).$

3.  A Markov chain $X_0, X_1, \ldots$ on sates 1 ,2 has the following
    transition matrix $$P = \begin{bmatrix}
        1-a & a   \\
        b & 1-b   \\
        %\vdots & \vdots & \vdots  & \vdots \\
        %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
    \end{bmatrix},$$ where $0 < a,b < 1.$

    1.  Draw a transition diagram for the chain.

    2.  the distribution of $X_1$.

    3.  Show that $$P^n = \frac{1}{a+b} \begin{bmatrix}
            b & a   \\
            b & a   \\
            %\vdots & \vdots & \vdots  & \vdots \\
            %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
        \end{bmatrix} +
        \frac{(1-a-b)^n}{a+b} \begin{bmatrix}
            a & -a   \\
            -b & b   \\
            %\vdots & \vdots & \vdots  & \vdots \\
            %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
        \end{bmatrix}.$$

    4.  Given that $X_0 = 1$, what is the probability that in the long
        run the system will be in state 1? (Hint: consider
        $\lim_{n \rightarrow \infty} \boldsymbol{\mu} P^n$)

    5.  Given that $X_0 = 1$, what is the probability that in the long
        run the system will be in state 2?

    6.  Given that $X_0 = 2$, what is the probability that in the long
        run the system will be in state 1?

    7.  Given that $X_0 = 2$, what is the probability that in the long
        run the system will be in state 2?

4.  Let $a$ be a constant and $\xi_1, \xi_2, \ldots$ be a sequence of
    independent and identically distributed (i.i.d.) random variables.
    The stochastic process $\{ X_n\}$ is defined by
    $$X_0 = a, \quad X_n = X_{n-1} + \xi_n, \, n > 1.$$ This process is
    known as a random walk.

    1.  Express the state $X_n$ in terms of $X_0$ and the random
        variables $\xi_i, i = 1,2 \ldots$.

    2.  Find $\mathrm{E}[X_n]$ and $\mathrm{Var}[X_n]$.

    3.  Does the process have the Markov property? Explain.

    4.  Is the process stationary? Explain.

5.  Consider a homogeneous discrete-time Markov chain that describes the
    daily weather pattern. The weather patterns are classified into 3
    conditions: R(rainy), C (cloudy) and S(sunny). Based on the daily
    observations, the following information are given:

    -   On any rainy day, the probability that it will rain the next day
        is 0.7; the probability that tomorrow will be cloudy is 0.2 and
        the probability that tomorrow will be sunny is 0.1.

    -   On any cloudy day, the probability that it will rain the next
        day is 0.5; the probability that tomorrow will be cloudy is 0.35
        and the probability that tomorrow will be sunny is 0.15.

    -   On any sunny day, the probability that it will rain the next day
        is 0.1; the probability that tomorrow will be cloudy is 0.4 and
        the probability that tomorrow will be sunny is 0.5.

    1.  Draw a transition diagram for the chain and write down a
        transition matrix.

    2.  Find the probability that tomorrow is cloudy and the day after
        is rainy, given that it is sunny today.

    3.  Given that today is rainy, find the probability that it will be
        sunny in two days time.

## Tutorial 3

1.  A Markov chain $X_0, X_1, \ldots$ on states 1, 2, 3 with initial
    distribution $\boldsymbol{\mu} = (1/4,1/4,1/2)$. It has the
    following transition matrix $$P = \begin{bmatrix}
        1/2 & 1/4 & 1/4   \\
        1/3  & 1/3  & 1/3   \\
        1/5  & 2/5  & 2/5    \\
        %\vdots & \vdots & \vdots  & \vdots \\
        %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
    \end{bmatrix}.$$ Compute the following probabilities:

    1.  $\Pr(X_{11} = 1, X_{12} = 2, X_{13} = 3 | X_{10} = 1).$

    2.  $\Pr(X_0 = 3, X_1 = 2 , X_2 = 1).$

    3.  $\Pr(X_1 = 3, X_2 = 2 , X_3 = 1).$

    4.  $\Pr(X_{1} = 2, X_{3} = 2, X_{5} = 2).$

2.  A Markov chain with state space $S = \{1,2,3,4,5,6\}$ has the
    following transition matrix: $$P = \begin{bmatrix}
    1/4 & 0 & 3/4 & 0 & 0 & 0  \\
    0 & 0 & 0 & 1 & 0 & 0  \\
    0 & 0 & 1/2 & 0 & 0 & 1/2  \\
    1/5 & 1/5 & 1/5 & 0 & 1/5 & 1/5   \\
    0 & 0 & 0 & 0 & 1 & 0  \\
    1/3 & 0 & 0 & 0 & 0 & 2/3  \\
        %p_{d1} & p_{d2} & p_{d3} & \dots  & p_{dn}
    \end{bmatrix}.$$

    1.  Draw a transition diagram.

    2.  Identify the communication classes and classify them as closed
        or non-closed.

    3.  Is the Markov chain irreducible?

3. For each of the Markov chains whose
    transition matrix is given below, identify the closed classes and
    the vector of absorption probabilities associated with each of these
    closed classes. Assume that the states are labelled $1,2,3 \ldots$.

    1.  $$\begin{bmatrix}
                1/6 & 0 & 1/3 & 1/2      \\
                0 & 1/3 & 2/3 & 0   \\
            1/2 & 1/2 & 0 & 0     \\    
            0 & 0 & 1/4 & 3/4     \\
        \end{bmatrix}.$$

    2.  $$\begin{bmatrix}
                0 & 1/4 & 3/4 & 0      \\
                0 & 1/3 & 0 & 2/3   \\
            1/3 & 0 & 1/3 & 1/3     \\  
            0 & 0 & 0 & 1     \\
        \end{bmatrix}.$$

    3.   $$\begin{bmatrix}
                1/4 & 1/4 & 1/4 & 1/4      \\
                0 & 3/4 & 1/4 & 0   \\
                0 & 3/4 & 1/4 & 0   \\
            0 & 0 & 0 & 1     \\
        \end{bmatrix}.$$

    4.   $$\begin{bmatrix}
                0 & 0 & 0 & 1/2  & 0 & 0 & 1/2   \\
                1/6 & 0 & 1/6 & 0  & 0 & 1/6 & 1/2 \\
            0 & 0 & 1 & 0 & 0 & 0 & 0    \\ 
                1/2 & 0 & 0 & 1/2  & 0 & 0 & 0   \\
            1/4 & 1/4 & 0 & 0  & 0 & 0 & 1/2 \\
            0 & 1 & 0 & 0 & 0 & 0 & 0    \\ 
                1/2 & 0 & 0 & 0  & 0 & 0 & 1/2   \\
        \end{bmatrix}.$$

4.  If the Markov chain defined in Question 3 is irreducible,
    i.e. it has a unique stationary distribution, then find the
    stationary distribution of the chain.

5.  Assume that a Markov chain has more than one closed classes (say $r$
    closed classes). The Markov chain can **have many stationary
    distributions**. Assume further that within each of these $r$ closed
    classes, the associated Markov chain is aperiodic. The followings
    hold:

    -   Within a closed class $C_1$, let $P_1$ be a reduction of a
        matrix $P$ which is formed by deleting all rows and columns
        corresponding to states from other classes. Then there exists a
        unique stationary distribution, denoted by
        $\{\pi_j^{(1)}\}_{j \in C_1}.$

    -   Similarly, let
        $\{\pi_j^{(2)}\}_{j \in C_2}, \ldots, \{\pi_j^{(r)}\}_{j \in C_r}$
        be stationary distributions within other classes.

    1.  Show that for any numbers $\gamma_1, \gamma_2, \ldots, \gamma_r$
        such that $\sum_{m=1}^r \gamma_m = 1$, the following
        distribution $\{ \pi_j \}$ is stationary, where
        

      \begin{equation} 
      (\#eq:limitdist)
        \pi_j =
         \begin{cases}
            \pi_j^{(k)} \gamma_k & \text{for } j \in C_k, \, k= 1,\ldots, r \\
            0 & \text{if } j \text{ is in a nonclosed class.}
          \end{cases}
        \end{equation}
        (In particular, any stationary distribution of the Markov chain is of this form.)

    2.  Write down the general form of stationary distributions of the
        Markov chain in Questions 3.3 and 3.4.

    3.  Now we will focus on limiting distributions. Consider the three
        following possible cases.

        1.  If $X_0 =  i$ and $i \in C_k$ for some closed class $C_k$,
            then verify that the limiting distribution is defined as in Eqn.\@ref(eq:limitdist) where $\gamma_k =1$ and
            $\gamma_m = 0,$ for $m \neq k$.

        2.  If $X_0 =  i$ and $i$ is in a nonclosed class, then verify
            that the limiting distribution is defined as in
            Eqn.\@ref(eq:limitdist) where $\gamma_k =  \alpha^{(k)}_i$
            for $k = 1,2,\ldots r$ where $\alpha^{(k)}_i$ is the
            probability of absorption in class $C_k$. More precisely,
            $$\pi_j =
             \begin{cases}
                \pi_j^{(k)} \alpha^{(k)}_i & \text{for } j \in C_k, \, k= 1,\ldots, r \\
                0 & \text{if } j \text{ is in a nonclosed class.}
              \end{cases}
                  %\pi_j^{(k)} \gamma_k \text{ for } j \in C_k, \, k= 1,\ldots, r \text { and }$$

        3.  If $X_0$ is random, then this will leave as extra exercise.
            (Hint: you may need to apply first step anslysis)

6.  A no-claims discount system for motor insurance has four levels of
    discount:

        Level     1     2     3     4
      ---------- ---- ----- ----- -----
       Discount   0%   10%   30%   50%

    The rules for moving between these levels are given as follows:

    -   Following a claim-free year, move to the next higher level, or
        remain at level 4.

    -   Following a year with one claim, move to the next lower level,
        or remain at level 1.

    -   Following a year with two or more claims, move down two levels,
        or move to level 1 (from level 2), or remain at level 1.

    A portfolio consists of 10,000 policyholders. Suppose also that the
    number of claims per year is $\vpoisson{0.1}$.

    1.  Calculate $\Pr[N = 0]$, $\Pr[N = 1]$, and $\Pr[N \ge 2]$ for
        each group.

    2.  Write down the transition probability matrix of this no-claims
        discount system.

    3.  Find the probability that a policyholder who has the 30%
        discount has no discount after 2 years.

    4.  Calculate the expected number of policyholders at each level at
        times 1 and 2, assuming no exits.

    5.  Calculate the expected number of policyholders at each level
        once stability has been achieved, assuming no exits.

7.  A no-claims discount system for motor insurance has four levels of
    discount:

        Level     1     2     3     4
      ---------- ---- ----- ----- -----
       Discount   0%   20%   30%   50%

    The rules for moving between these levels are given as follows:

    -   For a claim-free year, a policyholder moves to the next higher
        level, or remains at level 4.

    -   For every claim in a year, the policyholder moves down a
        discount level or remains at level 1, for example if the
        policyholder is in level 4 and has one accident, he/she moves to
        level 3, and 2 accidents, he/she moves to level 2, and 2 or more
        accidents to level 1.

    For a given policyholder, the number of claims each year, $N$, has a
    negative binomial distribution with parameters $k=2$ and $p = 0.5$.

    Note that a random variable $N$ has a negative distribution with
    parameters $k$ and $p$, denoted by $N \sim \dnb$ if its probability
    mass function is given by
    $$f_N(n) = \Pr(N = n) = \frac{\Gamma(k+n)}{\Gamma(n+1)\Gamma(k)} p^k (1- p)^n \quad n = 0,1,2,\ldots.$$

    1.  Draw a transition diagram for the chain.

    2.  Write down the transition matrix of this no-claims discount
        system.

    3.  Find the probability that a policyholder who has the maximum
        discount level will have 20% discount after two years.

## Tutorial 4


1.  Customers arrive in a shop according to a Poisson process of rate
    $\lambda = 4$. Let $N(t)$ be the number of customers that have
    arrived up to time $t$. Determine the following probabilities,
    conditional probabilities and expectations.

    1.  $\Pr(N(1) = 2).$

    2.  $\Pr(N(1) = 2 \text{ and } N(3) = 6).$

    3.  $\Pr(N(1) = 2 | N(3) = 6).$

    4.  $\Pr(N(3) = 6 | N(1) = 2).$

    5.  $\Pr(N(1) \le 2).$

    6.  $\Pr(N(1) = 1 \text{ and } N(2) = 3).$

    7.  $\Pr(N(1) \ge 2 | N(1) \ge 1).$

    8.  $\mathrm{E}[N(2)]$

    9.  $\mathrm{E}[N(1)^2]$

    10. $\mathrm{E}[N(1)N(2)]$

2.  Customers arrive in a shop according to a Poisson process of rate
    $\lambda = 4$ per hour. The shop opens at 9 am. Calculate the
    probability that exactly one customer has arrived by 9.30 am and a
    total of five customers have arrived by 11.30.

3.  Defects occur along a cable according to a Poisson process of rate
    $\lambda = 0.1$ per kilometre.

    1.  Calculate the probability that no defects appear in the first
        two kilometres of cable.

    2.  Given that there are no defects in the first two kilometres of
        cable, calculate the probability of no defects between two and
        three kilometres of cable.

4.  Customers arrive at a department store according to a Poisson
    process with rate $\lambda = 2$ per minute.

    1.  Calculate the probability that in a given 5 minute period there
        will be no customers arriving?

    2.  Calculate the probability that the 10th customer after 11 am
        will arrive before 11:05 am?

    3.  If a third of customers are men, calculate the probability that
        in a 5 minute period more than 3 men arrive given more than 4
        women arrive.

    4.  If every 5th customer receives a discount voucher, calculate the
        distribution of the times between these vouchers being given
        out? What is the probability that a time longer

5.  You have a bird table in your garden which attracts tailorbirds and
    pigeons. Tailorbirds arrive according to a Poisson process with rate
    $\lambda_1$ and the pigeons arrive according to a Poisson process
    with rate $\lambda_2$.

    1.  How long does it take for the first bird to arrive after a fixed
        point in time?

    2.  Calculate the probability this bird is a tailorbird?

    3.  What is the distribution of the number of birds in the time
        interval $[t_1, t_2)$?

    4.  Calculate the probability that exactly 3 tailorbirds arrive
        before the first pigeon after a fixed point in time?

6.  Let $X$ and $Y$ be independent Poisson distributed random variables
    with parameters $\lambda_X$ and $\lambda_Y$, respectively. Determine
    the conditional distribution of $X$, given that $N = X + Y = n$.

7.  Accidents occur on an highway according to a Poisson process at the
    rate of 20 accidents per week. One out of four accidents involve
    speeding.

    1.  What is the probability that ten accidents involving speeding
        will occur next week?

    2.  What is the probability that at least one accident occurs
        tomorrow?

    3.  If sixty accidents occur in four weeks, what is the probability
        that less than half of them involve speeding?

8.  Severe floods hit a southern of Thailand according to a Poisson
    process with $\lambda = 4$. The number of insurance claims filed
    after any sever flood has a Poisson distribution with mean 60. The
    number of server floods is independent of the number of insurance
    claims. Find the expectation and standard deviation of the total
    number of claims filed by time $t$.

9.  Assume that births occur at a hospital at the average rate of 3
    births per hour. Assume that the probability that any birth is a boy
    is 0.52.

    1.  On an 8-hour shift, what is the expectation and standard
        deviation of the number of male births?

    2.  Assume that ten babies were born yesterday. Find the probability
        that six are boys.

    3.  Find the probability that only boys were born between 6 and 10
        a.m.

