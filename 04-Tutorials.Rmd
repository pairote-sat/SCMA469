# Tutorials

## Tutorial 1

1.  Consider a random walk, $S_n$, with $S_0 = 0$ and where each step is
    normally distributed with mean 0 and variance 10.

    1.  What is the distribution of $S_{10}$?

    2.  Calculate $\Pr(S_{10} < -10)$.

    **Solution:**

    1.  We have $S_{10}$ is a sum of
        $S_0$ and the i.i.d random variables $Z_i$, each distributed
        normal distribution, $Z_i \sim N(0,10)$. Moreover,
        $$\mathrm{E}[S_{10}] = \mathrm{E}[S_0 + \sum_{i=1}^{10} Z_i] = S_0 + \sum_{i=1}^{10} \mathrm{E}[Z_i] = 0$$
        and
        $$\mathrm{Var}[S_{10}] = \mathrm{Var}[S_0 + \sum_{i=1}^{10} Z_i] = \sum_{i=1}^{10} \mathrm{Var}[Z_i] = 100$$
        Therefore, the distribution of $S_{10}$ is normally distributed,
        $S_{10} \sim N(0,100)$.

    2.  From the previous result,
        $$\Pr(S_{10} < -10) = \Pr(Z < -1) = 0.1587.$$

2.  Suppose that the value of a commodity as a random walk, where each
    day the change in price has mean \$0.05 and variance \$0.1. Use the
    central limit theorem to estimate the probability that its value is
    more than \$6 after 100 days if the initial value is \$0.50.

    **Solution:** We have $S_{100}$ is a sum of $S_0$ and the i.i.d
    random variables $Z_i$, each distributed normal distribution,
    $Z_i \sim N(0.05,0.1)$. Moreover,
    $$\mathrm{E}[S_{100}] = \mathrm{E}[S_0 + \sum_{i=1}^{100} Z_i] = S_0 + \sum_{i=1}^{100} \mathrm{E}[Z_i] = 5.5$$
    and
    $$\mathrm{Var}[S_{100}] = \mathrm{Var}[S_0 + \sum_{i=1}^{100} Z_i] = \sum_{i=1}^{100} \mathrm{Var}[Z_i] = 10$$
    Therefore, the distribution of $S_{100}$ is normally distributed,
    $S_{100} \sim N(5.5,10)$.

    The Central Limit Theorem implies that $S_{100}$ is approximately
    normally distributed, $S_{100} \sim N(5.5,10)$.

    $$\Pr(S_{100} > 6) = \Pr(Z > 0.1581) = 1 -  \Pr(Z < 0.1581)  = 1- 0.5628 = 0.4372.$$

3.  For the random walk process as described in the lecture note,

    1.  Calculate $\Pr(X_8 = 96 | X_0 = 100),$

    2.  Calculate $\Pr(X_1 = 99, X_8 = 96 | X_0 = 100),$

    3.  Calculate $\Pr(X_1 = 99,
        X_4 = 98, X_8 = 96 | X_0 = 100),$

    4.  Calculate $\Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100),$

    5.  Given $X_0 = 100$, calculate $\mathrm{E}[X_5]$.

    6.  Write down the joint distribution of $X_1$ and $X_3$ given
        $X_0 = 100$. (Hint: consider all possible sample paths)

    **Solution:**

    1.  Here the price must increase on any 2 day(s) and decrease on any
        6 day(s), not necessarily in that order. There are
        ${ 8 \choose 2} = 28$ different possibilities and each of these
        has probability $p^{2}(1-p)^{6}$. Therefore, the required
        probability is
        $$\Pr(X_8 = 96 | X_0 = 100) =  28  p^{2}(1-p)^{6} .$$

    2.  The problem can be divided into two periods:

        -   The first period of 1 day(s): the price in this period must
            increase on any 0 day(s) and decrease on any 1 day(s), not
            necessarily in that order. There are ${ 1 \choose 0}$
            different possibilities and each of these has probability
            $p^{0}(1-p)^{1}$.

        -   The next period of 7 day(s): the price in this period must
            increase on any 2 day(s) and decrease on any 5 day(s), not
            necessarily in that order. There are ${ 7 \choose 2}$
            different possibilities and each of these has probability
            $p^{2}(1-p)^{5}$.

        The required probability is
        $$\Pr(X_1 = 99, X_8 = 96 | X_0 = 100)  =  21  p^{2}(1-p)^{6} .$$

    3.  Similar to the previous problem, the required probability can be
        calculated as follows:

        The problem can be divided into three periods:

        -   The first period of 1 day(s): the price in this period must
            increase on any 0 day(s) and decrease on any 1 day(s), not
            necessarily in that order. There are ${ 1 \choose 0}$
            different possibilities and each of these has probability
            $p^{0}(1-p)^{1}$.

        -   The next period of 3 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 2 day(s), not
            necessarily in that order. There are ${ 3 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{2}$.

        -   The last period of 4 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 3 day(s), not
            necessarily in that order. There are ${ 4 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{3}$.

        The required probability is $$\Pr(X_1 = 99,
        X_4 = 98, X_8 = 96 | X_0 = 100)  =  12  p^{2}(1-p)^{6} .$$

    4.  By Markov property, we have $$\Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100), 
        = \Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99).$$ Again, the problem can be
        divided into two periods:

        -   The first period of 3 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 2 day(s), not
            necessarily in that order. There are ${ 3 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{2}$.

        -   The next period of 4 day(s): the price in this period must
            increase on any 1 day(s) and decrease on any 3 day(s), not
            necessarily in that order. There are ${ 4 \choose 1}$
            different possibilities and each of these has probability
            $p^{1}(1-p)^{3}$.

        The required probability is $$\Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99, X_0 = 100)
        = \Pr(
        X_4 = 98, X_8 = 96 |X_1 = 99)  =  12  p^{2}(1-p)^{5} .$$

    5.  The variable $X_5$ can take the values from
        $95, 97, 99, 101, 103, 105$. In particular, $$\begin{aligned}
            \Pr(X_5 &= 95) = {5 \choose 0} p^0 (1-p)^5 =  1 
        p^0 (1-p)^5    \\
            \Pr(X_5 &= 97) = {5 \choose 1} p^1 (1-p)^4 = 5 
            p^1 (1-p)^4\\
            \Pr(X_5 &= 99) = {5 \choose 2} p^2 (1-p)^3 = 10 
            p^2 (1-p)^3\\
            &\vdots \\
            \Pr(X_5 &= 105) = {5 \choose 5} p^5 (1-p)^0 = 1 
            p^5 (1-p)^0 \end{aligned}$$

        Therefore, $\mathrm{E}[X_5] = 
         95 \cdot \left( 1 
        p^0 (1-p)^5 \right)
        + 97 \cdot \left(5 
        p^1 (1-p)^4 \right)
        + 99 \cdot \left(10 
        p^2 (1-p)^3 \right)
        + \cdots
        + 105 \cdot \left( 1 
            p^5 (1-p)^0 \right) = 95 + 10*x.$
      Alternatively, $$\begin{aligned}
      E\left[X_{5}\right] &=E\left[100+\sum_{i=1}^{5} Z_{i}\right] \\
      &= 100+5 \cdot E\left[Z_{i}\right]  \\
      &=100+ 5 (2 p-1)  \\
      &=95 + 10p\end{aligned}$$
      where $E\left[Z_{i}\right] = p-q  = p - (1 - p) = 2p -1.$

4.  For each event,

    -   Identify a stochastic process $\{ X_t : t \in T\}$ and describe
        $X_t$ in context.

    -   Describe the time domain and state space. State whether the time
        domain and state space are discrete or continuous.

    1.  Sociologists categorise the population of a country into upper-,
        middle- and lower-class groups. One of the government offices
        has monitored the movement of successive generations among these
        three groups.

    2.  The insurer's surplus (an excess of income or assets over
        expenditure or liabilities in a given period) at any future time
        which is defined as the initial surplus plus the premium income
        up to time $t$ minus the aggregate claims up to time $t$.

    3.  In a working day, a coffee shop owner records customer arrival
        times.

    4.  The gambler starts with m and bets per game. The probability of
        winning is $p$ and the probability of losing is $q$ where
        $p + q = 1$. In addition, the gambler is ruined (or goes broke)
        if he reaches state 0, and also stops the game if he reaches
        state $N$.

    5.  In the board game Monopoly, there are 40 squares. A player is
        interested to know the successive board position.

    **Solution:**

    1.  Let $X_{n}$ be the class of $n^{\text {th }}$ generation of a
        family. The state space, $S=\{\text {Upper, Middle, Lower} \}$,
        is discrete. The index set, $I=\{0,1,2, \ldots\}$, is also
        discrete.

    2.  Let $S(t)$ be the insurer's surplus at time $t$.
        $S=\mathbb{R} \text { and }  I=[0, \infty)$.

    3.  Let $X_{n}$ be the amount of money of the gambler after game
        $n$.

        $S=\{0,1,2 \ldots, N\} \text { and } I=\{0,1,2 ,\ldots \}$.

    4.  Suppose that the opening hours of the coffee shop are from 7:00
        am to 6:00 pm (i.e. 11 hours). Let $X_{n}$ be the arrival time
        of customer $n$. State space (continuous)

        $S=[0,11 \times 60]=[0,660]$ (in minutes) and
        $I=\{1,2, \ldots\}$.

    5.  Let $x_{n}$ be a player's board position after $n$ plays.

        $S=\{1,2,3, \ldots, 40\}$ and $I=\{0,1,2, \ldots \}.$

5.  The simple weather pattern can be classified into three types
    including rainy ($R$), cloudy ($C$) and sunny ($S$). The weather is
    observed daily. The following information is provided.

    -   On any given rainy day, the probability that it will rain the
        next day is 0.7; the probability that it will be cloudy the next
        day 0.2.

    -   On any given cloudy day, the probability that it will rain the
        next day is 0.75; the probability that it will be sunny the next
        day 0.1.

    -   On any given sunny day, the probability that it will rain the
        next day is 0.2; the probability that it will be sunny the next
        day 0.4.

    Explain how this may be modelled by a Markov chain.

    **Solution:** The three weather conditions describe the three state of
    the Markov chain. Let $X_{n}$be the weather condition on day $n$.

    -   State 1 (R) rainy day

    -   State 2 (C) cloudy day

    -   State 3 (S) sunny day

    The transition probability matrix $P$ for this Markov chain is

    $$P=\left[\begin{array}{lll}
    0.7 & 0.2 & 0.1 \\
    0.75 & 0.15 & 0.1 \\
    0.2 & 0.4 & 0.4
    \end{array}\right]$$

    This stochastic process has the Morkov property because the weather
    condition on the next day depends only on the condition today.

6.  Explain whether an independent and identically distributed sequence
    of random variables has a Markov property. 
    
    **Solution:** Assume that
    this Markov chain $X_0, X_1, X_2 \ldots,$ takes values in
    $\{1,2, \ldots, k\} \text { with }$

    $$P\left(X_{n}=j\right) = p_{j} \quad \text { for } j=1,2, \ldots, k \quad \text { and } n \geq 0 .$$
    Note that this equality holds for all $n$ because
    $\left\{X_{n} \right\}_{n \ge 0}$ have the same distribution.

    By independence,

    $$P\left(x_{n}=j \mid x_{n-1}=i\right)=P\left(x_{n}=j\right)=p_{j},$$

    This proves our claim that the i.i.d. sequence of random variables
    has a Markov property. Note also that the transition matrix is
    $$P = 
    \begin{bmatrix}
    p_1 & p_2 & \cdots & p_k \\
    p_1 & p_2 & \cdots & p_k \\
    \vdots & \vdots &  & \vdots \\
    p_1 & p_2 & \cdots & p_k \\
    \end{bmatrix}.$$

7.  The random variables $Z_1, Z_2, \ldots$ are independent and with the
    common probability mass function $$Z_i = \begin{cases}
        1, & \text{ with probability }  0.2 \\
        2, & \text{ with probability }  0.3 \\  
        3, & \text{ with probability }  0.4 \\  
        4, & \text{ with probability }  0.1 \\  
     \end{cases}$$ Let $X_0 = 1$ and
    $X_n = \max\{Z_1, Z_2, \ldots, Z_n \}$ be the largest $Z$ observed
    to date. Explain how this may be modelled by a Markov chain.
    **Solution:**

    Given $X_{0}=1$ and
    $X_{n}=\max \left\{Z_{1}, Z_{2}, \ldots, Z_{n}\right\}$ where
    $\left\{Z_{i}\right\}$ are i.i.d. random variables with

      $i$            1     2     3     4
      -------------- ----- ----- ----- -----
      $P(Z_i = i)$   0.2   0.3   0.4   0.1

    We note that $$\begin{aligned}
    X_{n+1} &=\operatorname{max}\left\{Z_{1}, Z_{2}, \ldots, Z_{n+1}\right\} \\
    &=\operatorname{max}\left\{X_{n}, Z_{n+1}\right\}
    \end{aligned}$$ Consider the transition probabilities

    $$\begin{aligned}
    P\left(X_{n+1} = j \mid X_{n}=i \right) &= P\left(\max \left\{X_{n}, Z_{n+1}\right\}=j \mid X_{n}=i\right) \\
    &=P\left(\max \left\{i, Z_{n+1}\right\}=j \mid X_{n}=i\right)
    \end{aligned}$$

    **Case 1:** If $i=1$, then $$\max \left\{1, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0.2 \\
    2 & \text{w.p. } 0.3 \\
    3  & \text{w.p. } 0.4 \\
    4  & \text{w.p. } 0.1 \\
    \end{cases}$$

    **Case 2:** If $i=2$, then $$\max \left\{2, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0 \\
    2 & \text{w.p. } 0.5 \quad (\text{i.e. } z_{n+1} = 1 \text{ or } 2  )\\
    3  & \text{w.p. } 0.4 \\
    4  & \text{w.p. } 0.1 \\
    \end{cases}$$

    **Case 3:** If $i=3$, then $$\max \left\{3, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0 \\
    2 & \text{w.p. } 0 \\
    3  & \text{w.p. } 0.9 \\
    4  & \text{w.p. } 0.1 \\
    \end{cases}$$

    **Case 4:** If $i=4$, then $$\max \left\{4, Z_{n+1}\right\}= 
    \begin{cases}
    1  & \text{w.p. } 0 \\
    2 & \text{w.p. } 0 \\
    3  & \text{w.p. } 0 \\
    4  & \text{w.p. } 1 \\
    \end{cases}$$ The transition probability matrix is then

    $$P = 
    \begin{bmatrix}
    0.2 & 0.3 & 0.4 & 0.1 \\
    0 & 0.5 & 0.4 & 0.1 \\
    0 & 0 & 0.9 & 0.1 \\
    0 & 0 & 0 & 0.1 \\
    \end{bmatrix}.$$ Clearly the sequence $X_0, X_1, X_2,\ldots$ can be
    modelled by the Markov chain with the transition probability matrix
    $P$. Moreover, given the most recent value $X_n$, its future value
    $X_{n+1}$ is independent of the past history
    $X_0, X_1, \ldots, X_{n-1}$.
